package kmsg

import "github.com/twmb/kgo/kbin"

// Code generated by kgo/generate. DO NOT EDIT.

// MaxKey is the maximum key used for any messages in this package.
// Note that this value will change as Kafka adds more messages.
const MaxKey = 46

// MessageV0 is the message format Kafka used prior to 0.10.
//
// To produce or fetch messages, Kafka would write many messages contiguously
// as an array without specifying the array length.
type MessageV0 struct {
	// Offset is the offset of this record.
	//
	// If this is the outer message of a recursive message set (i.e. a
	// message set has been compressed and this is the outer message),
	// then the offset should be the offset of the last inner value.
	Offset int64

	// MessageSize is the size of everything that follows in this message.
	MessageSize int32

	// CRC is the crc of everything that follows this field (NOT using the
	// Castagnoli polynomial, as is the case in the 0.11+ RecordBatch).
	CRC int32

	// Magic is 0.
	Magic int8

	// Attributes describe the attributes of this message.
	//
	// Bits 0 thru 2 correspond to compression:
	//   - 00 is no compression
	//   - 01 is gzip compression
	//   - 10 is snappy compression
	//
	// The remaining bits are unused and must be 0.
	Attributes int8

	// Key is an blob of data for a record.
	//
	// Key's are usually used for hashing the record to specific Kafka partitions.
	Key []byte

	// Value is  a blob of data. This field is the main "message" portion of a
	// record.
	Value []byte
}

func (v *MessageV0) AppendTo(dst []byte) []byte {
	{
		v := v.Offset
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.MessageSize
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.CRC
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Magic
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Attributes
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Key
		dst = kbin.AppendNullableBytes(dst, v)
	}
	{
		v := v.Value
		dst = kbin.AppendNullableBytes(dst, v)
	}
	return dst
}
func (v *MessageV0) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int64()
			s.Offset = v
		}
		{
			v := b.Int32()
			s.MessageSize = v
		}
		{
			v := b.Int32()
			s.CRC = v
		}
		{
			v := b.Int8()
			s.Magic = v
		}
		{
			v := b.Int8()
			s.Attributes = v
		}
		{
			v := b.NullableBytes()
			s.Key = v
		}
		{
			v := b.NullableBytes()
			s.Value = v
		}
	}
	return b.Complete()
}

// MessageV0 is the message format Kafka used prior to 0.11.
//
// To produce or fetch messages, Kafka would write many messages contiguously
// as an array without specifying the array length.
//
// To support compression, an entire message set would be compressed and used
// as the Value in another message set (thus being "recursive"). The key for
// this outer message set must be null.
type MessageV1 struct {
	// Offset is the offset of this record.
	//
	// Different from v0, if this message set is a recursive message set
	// (that is, compressed and inside another message set), the offset
	// on the inner set is relative to the offset of the outer set.
	Offset int64

	// MessageSize is the size of everything that follows in this message.
	MessageSize int32

	// CRC is the crc of everything that follows this field (NOT using the
	// Castagnoli polynomial, as is the case in the 0.11+ RecordBatch).
	CRC int32

	// Magic is 1.
	Magic int8

	// Attributes describe the attributes of this message.
	//
	// Bits 0 thru 2 correspond to compression:
	//   - 00 is no compression
	//   - 01 is gzip compression
	//   - 10 is snappy compression
	//
	// Bit 3 is the timestamp type, with 0 meaning CreateTime corresponding
	// to the timestamp being from the producer, and 1 meaning LogAppendTime
	// corresponding to the timestamp being from the broker.
	// Setting this to LogAppendTime will cause batches to be rejected.
	//
	// The remaining bits are unused and must be 0.
	Attributes int8

	// Timestamp is the millisecond timestamp of this message.
	Timestamp int64

	// Key is an blob of data for a record.
	//
	// Key's are usually used for hashing the record to specific Kafka partitions.
	Key []byte

	// Value is  a blob of data. This field is the main "message" portion of a
	// record.
	Value []byte
}

func (v *MessageV1) AppendTo(dst []byte) []byte {
	{
		v := v.Offset
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.MessageSize
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.CRC
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Magic
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Attributes
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Timestamp
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.Key
		dst = kbin.AppendNullableBytes(dst, v)
	}
	{
		v := v.Value
		dst = kbin.AppendNullableBytes(dst, v)
	}
	return dst
}
func (v *MessageV1) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int64()
			s.Offset = v
		}
		{
			v := b.Int32()
			s.MessageSize = v
		}
		{
			v := b.Int32()
			s.CRC = v
		}
		{
			v := b.Int8()
			s.Magic = v
		}
		{
			v := b.Int8()
			s.Attributes = v
		}
		{
			v := b.Int64()
			s.Timestamp = v
		}
		{
			v := b.NullableBytes()
			s.Key = v
		}
		{
			v := b.NullableBytes()
			s.Value = v
		}
	}
	return b.Complete()
}

// Header is user provided metadata for a record. Kafka does not look at
// headers at all; they are solely for producers and consumers.
type Header struct {
	Key string

	Value []byte
}

func (v *Header) AppendTo(dst []byte) []byte {
	{
		v := v.Key
		dst = kbin.AppendVarintString(dst, v)
	}
	{
		v := v.Value
		dst = kbin.AppendVarintBytes(dst, v)
	}
	return dst
}
func (v *Header) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.VarintString()
			s.Key = v
		}
		{
			v := b.VarintBytes()
			s.Value = v
		}
	}
	return b.Complete()
}

// A Record is a Kafka v0.11.0.0 record. It corresponds to an individual
// message as it is written on the wire.
type Record struct {
	// Length is the length of this record on the wire of everything that
	// follows this field. It is an int32 encoded as a varint.
	Length int32

	// Attributes are record level attributes. This field currently is unused.
	Attributes int8

	// TimestampDelta is the millisecond delta of this record's timestamp
	// from the record's RecordBatch's FirstTimestamp.
	TimestampDelta int32

	// OffsetDelta is the delta of this record's offset from the record's
	// RecordBatch's FirstOffset.
	//
	// For producing, this is usually equal to the index of the record in
	// the record batch.
	OffsetDelta int32

	// Key is an blob of data for a record.
	//
	// Key's are usually used for hashing the record to specific Kafka partitions.
	Key []byte

	// Value is  a blob of data. This field is the main "message" portion of a
	// record.
	Value []byte

	// Headers are optional user provided metadata for records. Unlike normal
	// arrays, the number of headers is encoded as a varint.
	Headers []Header
}

func (v *Record) AppendTo(dst []byte) []byte {
	{
		v := v.Length
		dst = kbin.AppendVarint(dst, v)
	}
	{
		v := v.Attributes
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.TimestampDelta
		dst = kbin.AppendVarint(dst, v)
	}
	{
		v := v.OffsetDelta
		dst = kbin.AppendVarint(dst, v)
	}
	{
		v := v.Key
		dst = kbin.AppendVarintBytes(dst, v)
	}
	{
		v := v.Value
		dst = kbin.AppendVarintBytes(dst, v)
	}
	{
		v := v.Headers
		dst = kbin.AppendVarint(dst, int32(len(v)))
		for i := range v {
			v := &v[i]
			{
				v := v.Key
				dst = kbin.AppendVarintString(dst, v)
			}
			{
				v := v.Value
				dst = kbin.AppendVarintBytes(dst, v)
			}
		}
	}
	return dst
}
func (v *Record) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Varint()
			s.Length = v
		}
		{
			v := b.Int8()
			s.Attributes = v
		}
		{
			v := b.Varint()
			s.TimestampDelta = v
		}
		{
			v := b.Varint()
			s.OffsetDelta = v
		}
		{
			v := b.VarintBytes()
			s.Key = v
		}
		{
			v := b.VarintBytes()
			s.Value = v
		}
		{
			v := s.Headers
			a := v
			for i := b.Varint(); i > 0; i-- {
				a = append(a, Header{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.VarintString()
						s.Key = v
					}
					{
						v := b.VarintBytes()
						s.Value = v
					}
				}
			}
			v = a
			s.Headers = v
		}
	}
	return b.Complete()
}

// RecordBatch is a Kafka concept that groups many individual records together
// in a more optimized format.
type RecordBatch struct {
	// FirstOffset is the first offset in a record batch.
	//
	// For producing, this is usually 0.
	FirstOffset int64

	// Length is the wire length of everything that follows this field.
	Length int32

	// PartitionLeaderEpoch is a number that Kafka uses for cluster
	// communication. Clients generally do not need to worry about this
	// field and producers should set it to -1.
	PartitionLeaderEpoch int32

	// Magic is the current "magic" number of this message format.
	// The current magic number is 2.
	Magic int8

	// CRC is the crc of everything that follows this field using the
	// Castagnoli polynomial.
	CRC int32

	// Attributes describe the records array of this batch.
	//
	// Bits 0 thru 3 correspond to compression:
	//   - 000 is no compression
	//   - 001 is snappy compression
	//   - 010 is lz4 compression
	//   - 011 is zstd compression (produce request version 7+)
	//
	// Bit 4 is the timestamp type, with 0 meaning CreateTime corresponding
	// to the timestamp being from the producer, and 1 meaning LogAppendTime
	// corresponding to the timestamp being from the broker.
	// Setting this to LogAppendTime will cause batches to be rejected.
	//
	// Bit 5 indicates whether the batch is part of a transaction (1 is yes).
	//
	// Bit 6 indicates if the batch includes a control message (1 is yes).
	// Control messages are used to enable transactions and are generated from
	// the broker. Clients should not return control batches to applications.
	Attributes int16

	// LastOffsetDelta is the offset of the last message in a batch. This is
	// by the broker to ensure correct behavior even with batch compaction.
	LastOffsetDelta int32

	// FirstTimestamp is the timestamp (in milliseconds) of the first record
	// in a batch.
	FirstTimestamp int64

	// MaxTimestamp is the timestamp (in milliseconds) of the last record
	// in a batch. Similar to LastOffsetDelta, this is used to ensure correct
	// behavior with compacting.
	MaxTimestamp int64

	// ProducerID is the broker assigned producerID from an InitProducerID
	// request.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	ProducerID int64

	// ProducerEpoch is the broker assigned producerEpoch from an InitProducerID
	// request.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	ProducerEpoch int16

	// FirstSequence is the producer assigned sequence number used by the
	// broker to deduplicate messages.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	//
	// The sequence number for each record in a batch is OffsetDelta + FirstSequence.
	FirstSequence int32

	// NumRecords is the number of records in the array below.
	//
	// This is separate from Records due to the potential for records to be
	// compressed.
	NumRecords int32

	// Records contains records, either compressed or uncompressed.
	//
	// For uncompressed records, this is an array of records ([Record]).
	//
	// For compressed records, the length of the uncompressed array is kept
	// but everything that follows is compressed.
	//
	// The number of bytes is expected to be the Length field minus 49.
	Records []byte
}

func (v *RecordBatch) AppendTo(dst []byte) []byte {
	{
		v := v.FirstOffset
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.Length
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.PartitionLeaderEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Magic
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.CRC
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Attributes
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.LastOffsetDelta
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.FirstTimestamp
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.MaxTimestamp
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerID
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerEpoch
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.FirstSequence
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.NumRecords
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Records
		dst = append(dst, v...)
	}
	return dst
}
func (v *RecordBatch) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int64()
			s.FirstOffset = v
		}
		{
			v := b.Int32()
			s.Length = v
		}
		{
			v := b.Int32()
			s.PartitionLeaderEpoch = v
		}
		{
			v := b.Int8()
			s.Magic = v
		}
		{
			v := b.Int32()
			s.CRC = v
		}
		{
			v := b.Int16()
			s.Attributes = v
		}
		{
			v := b.Int32()
			s.LastOffsetDelta = v
		}
		{
			v := b.Int64()
			s.FirstTimestamp = v
		}
		{
			v := b.Int64()
			s.MaxTimestamp = v
		}
		{
			v := b.Int64()
			s.ProducerID = v
		}
		{
			v := b.Int16()
			s.ProducerEpoch = v
		}
		{
			v := b.Int32()
			s.FirstSequence = v
		}
		{
			v := b.Int32()
			s.NumRecords = v
		}
		{
			v := b.Span(int(s.Length) - 49)
			s.Records = v
		}
	}
	return b.Complete()
}

type ProduceRequestTopicDataData struct {
	// Partition is a partition to send a record batch to.
	Partition int32

	// Records is a batch of records to write to a topic's partition.
	//
	// For Kafka pre 0.11.0, the contents of the byte array is a serialized
	// message set. At or after 0.11.0, the contents of the byte array is a
	// serialized RecordBatch.
	Records []byte
}
type ProduceRequestTopicData struct {
	// Topic is a topic to send record batches to.
	Topic string

	// Data is an array of partitions to send record batches to.
	Data []ProduceRequestTopicDataData
}

// ProduceRequest issues records to be created to Kafka.
//
// Kafka 0.9.0 (v1) changed Records from MessageSet v0 to MessageSet v1.
// Kafka 0.11.0 (v3) again changed Records to RecordBatch.
//
// Note that the special client ID "__admin_client" will allow you to produce
// records to internal topics. This is generally recommended if you want to
// break your Kafka cluster.
type ProduceRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionID *string // v3+

	// Acks specifies the number of acks that the partition leaders must receive
	// from in sync replicas before considering a record batch fully written.
	//
	// Valid values are -1, 0, or 1 corresponding to all, none, or one.
	//
	// Note that if no acks are requested, Kafka will close the connection
	// if any topic or partition errors to trigger a client metadata refresh.
	Acks int16

	// Timeout is the millisecond timeout of this request.
	Timeout int32

	// TopicData is an array of topics to send record batches to.
	TopicData []ProduceRequestTopicData
}

func (*ProduceRequest) Key() int16                 { return 0 }
func (*ProduceRequest) MaxVersion() int16          { return 7 }
func (v *ProduceRequest) SetVersion(version int16) { v.Version = version }
func (v *ProduceRequest) GetVersion() int16        { return v.Version }
func (v *ProduceRequest) ResponseKind() Response   { return &ProduceResponse{Version: v.Version} }

func (v *ProduceRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	if version >= 3 {
		v := v.TransactionID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Acks
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.TopicData
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Data
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Records
						dst = kbin.AppendNullableBytes(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type ProduceResponseResponsePartitionResponse struct {
	// Partition is the partition this response pertains to.
	Partition int32

	// ErrorCode is any error for a topic/partition in the request.
	// There are many error codes for produce requests.
	//
	// TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for all topics and
	// partitions if the request had a transactional ID but the client
	// is not authorized for transactions.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned for all topics and partitions
	// if the request was idempotent but the client is not authorized
	// for idempotent requests.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned for all topics the client
	// is not authorized to talk to.
	//
	// INVALID_REQUIRED_ACKS is returned if the request contained an invalid
	// number for "acks".
	//
	// CORRUPT_MESSAGE is returned for many reasons, generally related to
	// problems with messages (invalid magic, size mismatch, etc.).
	//
	// MESSAGE_TOO_LARGE is returned if a record batch is larger than the
	// broker's configured max.message.size.
	//
	// RECORD_LIST_TOO_LARGE is returned if the record batch is larger than
	// the broker's segment.bytes.
	//
	// INVALID_TIMESTAMP is returned if the record batch uses LogAppendTime
	// or if the timestamp delta from when the broker receives the message
	// is more than the broker's log.message.timestamp.difference.max.ms.
	//
	// UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if using a Kafka v2 message
	// format (i.e. RecordBatch) feature (idempotence) while sending v1
	// messages (i.e. a MessageSet).
	//
	// KAFKA_STORAGE_ERROR is returned if the log directory for a partition
	// is offline.
	//
	// NOT_ENOUGH_REPLICAS is returned if all acks are required, but there
	// are not enough in sync replicas yet.
	//
	// NOT_ENOUGH_REPLICAS_AFTER_APPEND is returned on old Kafka versions
	// (pre 0.11.0.0) when a message was written to disk and then Kafka
	// noticed not enough replicas existed to replicate the message.
	//
	// DUPLICATE_SEQUENCE_NUMBER is returned for Kafka <1.1.0 when a
	// sequence number is detected as a duplicate. After, out of order
	// is returned.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
	// is unknown.
	//
	// NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
	// for this partition. This means that the client has stale metadata.
	//
	// INVALID_PRODUCER_EPOCH is returned if the produce request was
	// attempted with an old epoch. Either there is a newer producer using
	// the same transaction ID, or the transaction ID used has expired.
	//
	// UNKNOWN_PRODUCER_ID, added in Kafka 1.0.0 (message format v5+) is
	// returned if the producer used an ID that Kafka does not know about.
	// The LogStartOffset must be checked in this case. If the offset is
	// greater than the last acknowledged offset, then no data loss has
	// occurred; the client just sent data so long ago that Kafka rotated
	// the partition out of existence and no longer knows of this producer
	// ID. In this case, initialize a new ID. If the log start offset is
	// equal to or less than what the client sent prior, then data loss
	// has occurred. This See KAFKA-5793 for more details.
	//
	// OUT_OF_ORDER_SEQUENCE_NUMBER is sent if the batch's FirstSequence was
	// not what it should be (the last FirstSequence, plus the number of
	// records in the last batch, plus one). After 1.0.0, this generally
	// means data loss. Before, there could be confusion on if the broker
	// actually rotated the partition out of existence (this is why
	// UNKNOWN_PRODUCER_ID was introduced).
	ErrorCode int16

	// BaseOffset is the offset that the records in the produce request began
	// at in the partition.
	BaseOffset int64

	// LogAppendTime is the time that records were appended to the partition
	// inside Kafka. This is only not -1 if records were written with the log
	// append time flag (which producers cannot do).
	LogAppendTime int64 // v2+

	// LogStartOffset, introduced in Kafka 1.0.0,  can be used to see if an
	// UNKNOWN_PRODUCER_ID means Kafka rotated records containing the used
	// producer ID out of existence, or if Kafka lost data.
	LogStartOffset int64 // v5+
}
type ProduceResponseResponse struct {
	// Topic is the topic this response pertains to.
	Topic string

	// PartitionResponses is an array of responses for the partition's that
	// batches were sent to.
	PartitionResponses []ProduceResponseResponsePartitionResponse
}

// ProduceResponse is returned from a ProduceRequest.
type ProduceResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Responses is an array of responses for the topic's that batches were sent
	// to.
	Responses []ProduceResponseResponse

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+
}

func (v *ProduceResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ProduceResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ProduceResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int64()
									s.BaseOffset = v
								}
								if version >= 2 {
									v := b.Int64()
									s.LogAppendTime = v
								}
								if version >= 5 {
									v := b.Int64()
									s.LogStartOffset = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type FetchRequestTopicPartition struct {
	// Partition is a partition in a topic to try to fetch records for.
	Partition int32

	// CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// allows brokers to check if the client is fenced (has an out of date
	// leader) or is using an unknown leader.
	//
	// The initial leader epoch can be gleaned from a MetadataResponse.
	// To skip log truncation checking, use -1.
	CurrentLeaderEpoch int32 // v9+

	// FetchOffset is the offset to begin the fetch from. Kafka will
	// return records at and after this offset.
	FetchOffset int64

	// LogStartOffset is a broker-follower only field added for KIP-107.
	// This is the start offset of the partition in a follower.
	LogStartOffset int64 // v5+

	// PartitionMaxBytes is the maximum bytes to return for this partition.
	// This can be used to limit how many bytes an individual partition in
	// a request is allotted so that it does not dominate all of MaxBytes.
	PartitionMaxBytes int32
}
type FetchRequestTopic struct {
	// Topic is a topic to try to fetch records for.
	Topic string

	// Partitions contains partitions in a topic to try to fetch records for.
	Partitions []FetchRequestTopicPartition
}
type FetchRequestForgottenTopicsData struct {
	// Topic is a topic to remove from being tracked (with the partitions below).
	Topic string

	// Partitions are partitions to remove from tracking for a topic.
	Partitions []int32
}

// FetchRequest is a long-poll request of records from Kafka.
//
// Kafka 0.11.0.0 released v4 and changed the returned RecordBatches to contain
// the RecordBatch type. Prior, Kafka used the MessageSet type (and, for v0 and
// v1, Kafka used a different type).
//
// Note that starting in v3, Kafka began processing partitions in order,
// meaning the order of partitions in the fetch request is important due to
// potential size constraints.
type FetchRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ReplicaID is the broker ID of performing the fetch request. Standard
	// clients should use -1. To be a "debug" replica, use -2. The debug
	// replica can be used to fetch messages from non-leaders.
	ReplicaID int32

	// MaxWaitTime is how long to wait for MinBytes to be hit before a broker
	// responds to a fetch request.
	MaxWaitTime int32

	// MinBytes is the minimum amount of bytes to attempt to read before a broker
	// responds to a fetch request.
	MinBytes int32

	// MaxBytes is the maximum amount of bytes to read in a fetch request. The
	// response can exceed MaxBytes if the first record in the first non-empty
	// partition is larger than MaxBytes.
	MaxBytes int32 // v3+

	// IsolationLevel changes which messages are fetched. Follower replica ID's
	// (non-negative, non-standard-client) fetch from the end.
	//
	// Standard clients fetch from the high watermark, which corresponds to
	// IsolationLevel 0, READ_UNCOMMITTED.
	//
	// To only read committed records, use IsolationLevel 1, corresponding to
	// READ_COMMITTED.
	IsolationLevel int8 // v4+

	// SessionID is used for broker-to-broker communication.
	//
	// Because this is not needed in general clients, documentation is elided.
	// Read KIP-227 for more details. Use -1 as a general client.
	SessionID int32 // v7+

	// SessionEpoch is used for broker-to-broker communication.
	//
	// Because this is not needed in general clients, documentation is elided.
	// Read KIP-227 for more details. Use -1 as a general client.
	SessionEpoch int32 // v7+

	// Topic contains topics to try to fetch records for.
	Topics []FetchRequestTopic

	// ForgottenTopicsData contains topics and partitions that a fetch session
	// wants to remove from its session. This is generally only needed for
	// brokers; see KIP-227 for more details.
	ForgottenTopicsData []FetchRequestForgottenTopicsData // v7+

	// Rack ID of the consumer making this request (see KIP-392; introduced in
	// Kafka 2.2.0).
	RackID string // v11+
}

func (*FetchRequest) Key() int16                 { return 1 }
func (*FetchRequest) MaxVersion() int16          { return 11 }
func (v *FetchRequest) SetVersion(version int16) { v.Version = version }
func (v *FetchRequest) GetVersion() int16        { return v.Version }
func (v *FetchRequest) ResponseKind() Response   { return &FetchResponse{Version: v.Version} }

func (v *FetchRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ReplicaID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MaxWaitTime
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MinBytes
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 3 {
		v := v.MaxBytes
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 4 {
		v := v.IsolationLevel
		dst = kbin.AppendInt8(dst, v)
	}
	if version >= 7 {
		v := v.SessionID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 7 {
		v := v.SessionEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					if version >= 9 {
						v := v.CurrentLeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.FetchOffset
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 5 {
						v := v.LogStartOffset
						dst = kbin.AppendInt64(dst, v)
					}
					{
						v := v.PartitionMaxBytes
						dst = kbin.AppendInt32(dst, v)
					}
				}
			}
		}
	}
	if version >= 7 {
		v := v.ForgottenTopicsData
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	if version >= 11 {
		v := v.RackID
		dst = kbin.AppendString(dst, v)
	}
	return dst
}

type FetchResponseResponsePartitionResponseAbortedTransaction struct {
	// ProducerID is the producer ID that caused this aborted transaction.
	ProducerID int64

	// FirstOffset is the offset where this aborted transaction began.
	FirstOffset int64
}
type FetchResponseResponsePartitionResponse struct {
	// Partition is a partition in a topic that records may have been
	// received for.
	Partition int32

	// ErrorCode is an error returned for an individual partition in a
	// fetch request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to read the partition.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
	// does not exist on this broker.
	//
	// UNSUPPORTED_COMPRESSION_TYPE is returned if the request version was
	// under 10 and the batch is compressed with zstd.
	//
	// UNSUPPORTED_VERSION is returned if the broker has records newer than
	// the client can support (magic value) and the broker has disabled
	// message downconversion.
	//
	// NOT_LEADER_FOR_PARTITION is returned if requesting data for this
	// partition as a follower (non-negative ReplicaID) and the broker
	// is not the leader for this partition.
	//
	// REPLICA_NOT_AVAILABLE is returned if the partition exists but
	// the requested broker is not the leader for it.
	//
	// KAFKA_STORAGE_EXCEPTION is returned if the requested partition is
	// offline.
	//
	// UNKNOWN_LEADER_EPOCH is returned if the request used a larger leader
	// epoch than the broker knows of.
	//
	// FENCED_LEADER_EPOCH is returned if the request used a smaller leader
	// epoch than the broker is at (see KIP-320).
	//
	// OFFSET_OUT_OF_RANGE is returned if requesting an offset past the
	// current end offset or before the beginning offset.
	ErrorCode int16

	// HighWatermark is the current high watermark for this partition,
	// that is, the current offset that is on all in sync replicas.
	HighWatermark int64

	// LastStableOffset is the offset at which all prior offsets have
	// been "decided". Non transactional records are always decided
	// immediately, but transactional records are only decided once
	// they are commited or aborted.
	//
	// The LastStableOffset will always be at or under the HighWatermark.
	LastStableOffset int64 // v4+

	// LogStartOffset is the beginning offset for this partition.
	// This field was added for KIP-107.
	LogStartOffset int64 // v5+

	// AbortedTransactions is an array of aborted transactions within the
	// returned offset range. This is only returned if the requested
	// isolation level was READ_COMMITTED.
	AbortedTransactions []FetchResponseResponsePartitionResponseAbortedTransaction // v4+

	// PreferredReadReplica is the preferred replica for the consumer
	// to use on its next fetch request. See KIP-392.
	PreferredReadReplica int32 // v11+

	// RecordBatches is an array of record batches for a topic partition.
	//
	// This is encoded as a raw byte array, with the standard int32 size
	// prefix. One important catch to note is that the final element of the
	// array may be **partial**. This is an optimization in Kafka that
	// clients must deal with by discarding a partial trailing batch.
	//
	// Starting v2, this transitioned to the MessageSet v1 format (and this
	// would contain many MessageV1 structs).
	//
	// Starting v4, this transitioned to the RecordBatch format (thus this
	// contains many RecordBatch structs).
	RecordBatches []byte
}
type FetchResponseResponse struct {
	// Topic is a topic that records may have been received for.
	Topic string

	// PartitionResponses contains partitions in a topic that records may have
	// been received for.
	PartitionResponses []FetchResponseResponsePartitionResponse
}

// FetchResponse is returned from a FetchRequest.
type FetchResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is a full-response error code for a fetch request. This was
	// added in support of KIP-227. This error is only non-zero if using fetch
	// sessions (clients should not).
	//
	// FETCH_SESSION_ID_NOT_FOUND is returned if the request used a
	// session ID that the broker does not know of.
	//
	// INVALID_FETCH_SESSION_EPOCH is returned if the request used an
	// invalid session epoch.
	ErrorCode int16 // v7+

	// SessionID is for broker to broker communication. See KIP-227 for more details.
	SessionID int32 // v7+

	// Responses contains an array of topic partitions and the records received
	// for them.
	Responses []FetchResponseResponse
}

func (v *FetchResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		if version >= 7 {
			v := b.Int16()
			s.ErrorCode = v
		}
		if version >= 7 {
			v := b.Int32()
			s.SessionID = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, FetchResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, FetchResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int64()
									s.HighWatermark = v
								}
								if version >= 4 {
									v := b.Int64()
									s.LastStableOffset = v
								}
								if version >= 5 {
									v := b.Int64()
									s.LogStartOffset = v
								}
								if version >= 4 {
									v := s.AbortedTransactions
									a := v
									i := b.ArrayLen()
									if version < 0 || i == 0 {
										a = []FetchResponseResponsePartitionResponseAbortedTransaction{}
									}
									for ; i > 0; i-- {
										a = append(a, FetchResponseResponsePartitionResponseAbortedTransaction{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.Int64()
												s.ProducerID = v
											}
											{
												v := b.Int64()
												s.FirstOffset = v
											}
										}
									}
									v = a
									s.AbortedTransactions = v
								}
								if version >= 11 {
									v := b.Int32()
									s.PreferredReadReplica = v
								}
								{
									v := b.NullableBytes()
									s.RecordBatches = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

type ListOffsetsRequestTopicPartition struct {
	// Partition is a partition of a topic to get offsets for.
	Partition int32

	// CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// allows brokers to check if the client is fenced (has an out of date
	// leader) or is using an unknown leader.
	//
	// The initial leader epoch can be gleaned from a MetadataResponse.
	// To skip log truncation checking, use -1.
	CurrentLeaderEpoch int32 // v4+

	// Timestamp controls which offset to return in a response for this
	// partition.
	//
	// The offset returned will be the one of the message whose timestamp is
	// the first timestamp greater than or equal to this requested timestamp.
	//
	// If no such message is found, the log end offset is returned.
	//
	// There exist two special timestamps: -2 corresponds to the earliest
	// timestamp, and -1 corresponds to the latest.
	Timestamp int64

	// MaxNumOffsets is the maximum number of offsets to report.
	// This was removed after v0.
	MaxNumOffsets int32
}
type ListOffsetsRequestTopic struct {
	// Topic is a topic to get offsets for.
	Topic string

	// Partitions is an array of partitions in a topic to get offsets for.
	Partitions []ListOffsetsRequestTopicPartition
}

// ListOffsetsRequest requests partition offsets from Kafka for use in
// consuming records.
//
// Version 5, introduced in Kafka 2.2.0, is the same as version 4. Using
// version 5 implies you support Kafka's OffsetNotAvailableException
// See KIP-207 for details.
type ListOffsetsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ReplicaID is the broker ID to get offsets from. As a Kafka client, use -1.
	// The consumer replica ID (-1) causes requests to only succeed if issued
	// against the leader broker.
	ReplicaID int32

	// IsolationLevel configures which record offsets are visible in the
	// response. READ_UNCOMMITTED (0) makes all records visible. READ_COMMITTED
	// (1) makes non-transactional and committed transactional records visible.
	// READ_COMMITTED means all offsets smaller than the last stable offset and
	// includes aborted transactions (allowing consumers to discard aborted
	// records).
	IsolationLevel int8 // v2+

	// Topics is an array of topics to get offsets for.
	Topics []ListOffsetsRequestTopic
}

func (*ListOffsetsRequest) Key() int16                 { return 2 }
func (*ListOffsetsRequest) MaxVersion() int16          { return 5 }
func (v *ListOffsetsRequest) SetVersion(version int16) { v.Version = version }
func (v *ListOffsetsRequest) GetVersion() int16        { return v.Version }
func (v *ListOffsetsRequest) IsAdminRequest()          {}
func (v *ListOffsetsRequest) ResponseKind() Response   { return &ListOffsetsResponse{Version: v.Version} }

func (v *ListOffsetsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ReplicaID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 2 {
		v := v.IsolationLevel
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					if version >= 4 {
						v := v.CurrentLeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Timestamp
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 0 && version <= 0 {
						v := v.MaxNumOffsets
						dst = kbin.AppendInt32(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type ListOffsetsResponseResponsePartitionResponse struct {
	// Partition is the partition this array slot is for.
	Partition int32

	// ErrorCode is any error for a topic partition in a ListOffsets request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the topic.
	//
	// INVALID_REQUEST is returned if the requested topic partitions had
	// contained duplicates.
	//
	// KAFKA_STORAGE_EXCEPTION is returned if the topic / partition is in
	// an offline log directory.
	//
	// UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if the broker is using
	// Kafka 0.10.0 messages and the requested timestamp was not -1 nor -2.
	//
	// NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
	// for this partition. This means that the client has stale metadata.
	// If the request used the debug replica ID, the returned error will
	// be REPLICA_NOT_AVAILABLE.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know
	// of the requested topic or partition.
	//
	// FENCED_LEADER_EPOCH is returned if the broker has a higher leader
	// epoch than what the request sent.
	//
	// UNKNOWN_LEADER_EPOCH is returned if the request used a leader epoch
	// that the broker does not know about.
	//
	// OFFSET_NOT_AVAILABLE, introduced in Kafka 2.2.0 with produce request
	// v5+, is returned when talking to a broker that is a new leader while
	// that broker's high water mark catches up. This avoids situations where
	// the old broker returned higher offsets than the new broker would. Note
	// that if unclean leader election is allowed, you could still run into
	// the situation where offsets returned from list offsets requests are
	// not monotonically increasing. This error is only returned if the
	// request used the consumer replica ID (-1). If the client did not use
	// a v5+ list offsets request, LEADER_NOT_AVAILABLE is returned.
	// See KIP-207 for more details.
	ErrorCode int16

	// OldStyleOffsets is a list of offsets. This was removed after
	// version 0 and, since it is so historic, is undocumented.
	OldStyleOffsets []int64

	// If the request was for the earliest or latest timestamp (-2 or -1), or
	// if an offset could not be found after the requested one, this will be -1.
	Timestamp int64

	// Offset is the offset corresponding to the record on or after the
	// requested timestamp. If one could not be found, this will be -1.
	Offset int64 // v1+

	// LeaderEpoch is the leader epoch of the record at this offset,
	// or -1 if there was no leader epoch.
	LeaderEpoch int32 // v4+
}
type ListOffsetsResponseResponse struct {
	// Topic is the topic this array slot is for.
	Topic string

	// PartitionResponses is an array of partition responses corresponding to
	// the requested partitions for a topic.
	PartitionResponses []ListOffsetsResponseResponsePartitionResponse
}

// ListOffsetsResponse is returned from a ListOffsetsRequest.
type ListOffsetsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v2+

	// Responses is an array of topic / partition responses corresponding to
	// the requested topics and partitions.
	Responses []ListOffsetsResponseResponse
}

func (v *ListOffsetsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 2 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ListOffsetsResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ListOffsetsResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								if version >= 0 && version <= 0 {
									v := s.OldStyleOffsets
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int64()
										a = append(a, v)
									}
									v = a
									s.OldStyleOffsets = v
								}
								{
									v := b.Int64()
									s.Timestamp = v
								}
								if version >= 1 {
									v := b.Int64()
									s.Offset = v
								}
								if version >= 4 {
									v := b.Int32()
									s.LeaderEpoch = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

// MetadataRequest requests metadata from Kafka.
type MetadataRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is a list of topics to return metadata about. If this is null
	// in v1+, all topics are included. If this is empty, no topics are.
	// For v0 (<Kafka 0.10.0.0), if this is empty, all topics are included.
	Topics []string

	// AllowAutoTopicCreation, introduced in Kafka 0.11.0.0, allows topic
	// auto creation of the topics in this request if they do not exist.
	AllowAutoTopicCreation bool // v4+

	// IncludeClusterAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
	// whether to return a bitfield of AclOperations that this client can perform
	// on the cluster. See KIP-430 for more details.
	IncludeClusterAuthorizedOperations bool // v8+

	// IncludeTopicAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
	// whether to return a bitfield of AclOperations that this client can perform
	// on individual topics. See KIP-430 for more details.
	IncludeTopicAuthorizedOperations bool // v8+
}

func (*MetadataRequest) Key() int16                 { return 3 }
func (*MetadataRequest) MaxVersion() int16          { return 8 }
func (v *MetadataRequest) SetVersion(version int16) { v.Version = version }
func (v *MetadataRequest) GetVersion() int16        { return v.Version }
func (v *MetadataRequest) ResponseKind() Response   { return &MetadataResponse{Version: v.Version} }

func (v *MetadataRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		if version > 1 {
			dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		} else {
			dst = kbin.AppendArrayLen(dst, len(v))
		}
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	if version >= 4 {
		v := v.AllowAutoTopicCreation
		dst = kbin.AppendBool(dst, v)
	}
	if version >= 8 {
		v := v.IncludeClusterAuthorizedOperations
		dst = kbin.AppendBool(dst, v)
	}
	if version >= 8 {
		v := v.IncludeTopicAuthorizedOperations
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type MetadataResponseBroker struct {
	// NodeID is the node ID of a Kafka broker.
	NodeID int32

	// Host is the hostname of a Kafka broker.
	Host string

	// Port is the port of a Kafka broker.
	Port int32

	// Rack is the rack this Kafka broker is in.
	Rack *string // v1+
}
type MetadataResponseTopicMetadataPartitionMetadata struct {
	// ErrorCode is any error for a partition in topic metadata.
	//
	// LEADER_NOT_AVAILABLE is returned if a leader is unavailable for this
	// partition. For v0 metadata responses, this is also returned if a
	// partition leader's listener does not exist.
	//
	// LISTENER_NOT_FOUND is returned if a leader ID is known but the
	// listener for it is not (v1+).
	//
	// REPLICA_NOT_AVAILABLE is returned in v0 responses if any replica is
	// unavailable.
	ErrorCode int16

	// Partition is a partition number for a topic.
	Partition int32

	// Leader is the broker leader for this partition. This will be -1
	// on leader / listener error.
	Leader int32

	// LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0 is the
	// epoch of the broker leader.
	LeaderEpoch int32 // v7+

	// Replicas returns all broker IDs containing replicas of this partition.
	Replicas []int32

	// ISR returns all broker IDs of in-sync replicas of this partition.
	ISR []int32

	// OfflineReplicas, proposed in KIP-112 and introduced in Kafka 1.0,
	// returns all offline broker IDs that should be replicating this partition.
	OfflineReplicas []int32 // v5+
}
type MetadataResponseTopicMetadata struct {
	// ErrorCode is any error for a topic in a metadata request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the topic, or if the metadata request specified topic auto
	// creation, the topic did not exist, and the user lacks permission to create.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if a topic does not exist and
	// the request did not specify autocreation.
	//
	// LEADER_NOT_AVAILABLE is returned if a new topic is created successfully
	// (since there is no leader on an immediately new topic).
	//
	// There can be a myriad of other errors for unsuccessful topic creation.
	ErrorCode int16

	// Topic is the topic this metadata corresponds to.
	Topic string

	// IsInternal signifies whether this topic is a Kafka internal topic.
	IsInternal bool // v1+

	// PartitionMetadata contains metadata about partitions for a topic.
	PartitionMetadata []MetadataResponseTopicMetadataPartitionMetadata

	// AuthorizedOperations, proposed in KIP-430 and introduced in Kafka 2.3.0,
	// is a bitfield (corresponding to AclOperation) containing which operations
	// the client is allowed to perform on this topic.
	// This is only returned if requested.
	AuthorizedOperations int32 // v8+
}

// MetadataResponse is returned from a MetdataRequest.
type MetadataResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v3+

	// Brokers is a set of alive Kafka brokers.
	Brokers []MetadataResponseBroker

	// ClusterID, proposed in KIP-78 and introduced in Kafka 0.10.1.0, is a
	// unique string specifying the cluster that the replying Kafka belongs to.
	ClusterID *string // v2+

	// ControllerID is the ID of the controller broker (the admin broker).
	ControllerID int32 // v1+

	// TopicMetadata contains metadata about each topic requested in the
	// MetadataRequest.
	TopicMetadata []MetadataResponseTopicMetadata

	// AuthorizedOperations is a bitfield containing which operations the client
	// is allowed to perform on this cluster.
	AuthorizedOperations int32 // v8+
}

func (v *MetadataResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 3 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Brokers
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, MetadataResponseBroker{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int32()
						s.NodeID = v
					}
					{
						v := b.String()
						s.Host = v
					}
					{
						v := b.Int32()
						s.Port = v
					}
					if version >= 1 {
						v := b.NullableString()
						s.Rack = v
					}
				}
			}
			v = a
			s.Brokers = v
		}
		if version >= 2 {
			v := b.NullableString()
			s.ClusterID = v
		}
		if version >= 1 {
			v := b.Int32()
			s.ControllerID = v
		}
		{
			v := s.TopicMetadata
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, MetadataResponseTopicMetadata{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.Topic = v
					}
					if version >= 1 {
						v := b.Bool()
						s.IsInternal = v
					}
					{
						v := s.PartitionMetadata
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, MetadataResponseTopicMetadataPartitionMetadata{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int32()
									s.Leader = v
								}
								if version >= 7 {
									v := b.Int32()
									s.LeaderEpoch = v
								}
								{
									v := s.Replicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.Replicas = v
								}
								{
									v := s.ISR
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.ISR = v
								}
								if version >= 5 {
									v := s.OfflineReplicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.OfflineReplicas = v
								}
							}
						}
						v = a
						s.PartitionMetadata = v
					}
					if version >= 8 {
						v := b.Int32()
						s.AuthorizedOperations = v
					}
				}
			}
			v = a
			s.TopicMetadata = v
		}
		if version >= 8 {
			v := b.Int32()
			s.AuthorizedOperations = v
		}
	}
	return b.Complete()
}

type LeaderAndISRRequestPartitionState struct {
	Topic string

	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	IsNew bool // v1+
}
type LeaderAndISRRequestTopicStatePartitionState struct {
	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	AddingReplicas []int32 // v3+

	RemovingReplicas []int32 // v3+

	IsNew bool
}
type LeaderAndISRRequestTopicState struct {
	Topic string

	PartitionStates []LeaderAndISRRequestTopicStatePartitionState
}
type LeaderAndISRRequestLiveLeader struct {
	ID int32

	Host string

	Port int32
}

// LeaderAndISRRequest is an advanced request that controller brokers use
// to broadcast state to other brokers. Manually using this request is a
// great way to break your cluster.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 1.0.0 introduced version 1. Kafka 2.2.0 introduced version 2, proposed
// in KIP-380, which changed the layout of the struct to be more memory
// efficient. Kafka 2.4.0 introduced version 3 with KIP-455.
type LeaderAndISRRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	BrokerEpoch int64 // v2+

	PartitionStates []LeaderAndISRRequestPartitionState

	TopicStates []LeaderAndISRRequestTopicState // v2+

	LiveLeaders []LeaderAndISRRequestLiveLeader
}

func (*LeaderAndISRRequest) Key() int16                 { return 4 }
func (*LeaderAndISRRequest) MaxVersion() int16          { return 3 }
func (v *LeaderAndISRRequest) SetVersion(version int16) { v.Version = version }
func (v *LeaderAndISRRequest) GetVersion() int16        { return v.Version }
func (v *LeaderAndISRRequest) IsAdminRequest()          {}
func (v *LeaderAndISRRequest) ResponseKind() Response {
	return &LeaderAndISRResponse{Version: v.Version}
}

func (v *LeaderAndISRRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 2 {
		v := v.BrokerEpoch
		dst = kbin.AppendInt64(dst, v)
	}
	if version >= 0 && version <= 1 {
		v := v.PartitionStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ControllerEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Leader
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.LeaderEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ISR
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.ZKVersion
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Replicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			if version >= 1 {
				v := v.IsNew
				dst = kbin.AppendBool(dst, v)
			}
		}
	}
	if version >= 2 {
		v := v.TopicStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.PartitionStates
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.ControllerEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Leader
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.ISR
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					{
						v := v.ZKVersion
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Replicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					if version >= 3 {
						v := v.AddingReplicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					if version >= 3 {
						v := v.RemovingReplicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					{
						v := v.IsNew
						dst = kbin.AppendBool(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.LiveLeaders
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ID
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Host
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Port
				dst = kbin.AppendInt32(dst, v)
			}
		}
	}
	return dst
}

type LeaderAndISRResponsePartition struct {
	Topic string

	Partition int32

	ErrorCode int16
}

// LeaderAndISRResponse is returned from a LeaderAndISRRequest.
type LeaderAndISRResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	Partitions []LeaderAndISRResponsePartition
}

func (v *LeaderAndISRResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.Partitions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, LeaderAndISRResponsePartition{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.Partitions = v
		}
	}
	return b.Complete()
}

type StopReplicaRequestPartition struct {
	Topic string

	Partition int32

	PartitionIDs []int32 // v1+
}

// StopReplicaRequest is an advanced request that brokers use to stop replicas.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 2.2.0 introduced version 1, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
type StopReplicaRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	BrokerEpoch int64 // v1+

	DeletePartitions bool

	Partitions []StopReplicaRequestPartition
}

func (*StopReplicaRequest) Key() int16                 { return 5 }
func (*StopReplicaRequest) MaxVersion() int16          { return 1 }
func (v *StopReplicaRequest) SetVersion(version int16) { v.Version = version }
func (v *StopReplicaRequest) GetVersion() int16        { return v.Version }
func (v *StopReplicaRequest) IsAdminRequest()          {}
func (v *StopReplicaRequest) ResponseKind() Response   { return &StopReplicaResponse{Version: v.Version} }

func (v *StopReplicaRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.BrokerEpoch
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.DeletePartitions
		dst = kbin.AppendBool(dst, v)
	}
	{
		v := v.Partitions
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			if version >= 0 && version <= 0 {
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
			if version >= 1 {
				v := v.PartitionIDs
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type StopReplicaResponsePartition struct {
	Topic string

	Partition int32

	ErrorCode int16
}

// StopReplicasResponse is returned from a StopReplicasRequest.
type StopReplicaResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	Partitions []StopReplicaResponsePartition
}

func (v *StopReplicaResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.Partitions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, StopReplicaResponsePartition{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.Partitions = v
		}
	}
	return b.Complete()
}

type UpdateMetadataRequestPartitionState struct {
	Topic string

	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	OfflineReplicas []int32
}
type UpdateMetadataRequestTopicStatePartitionState struct {
	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	OfflineReplicas []int32
}
type UpdateMetadataRequestTopicState struct {
	Topic string

	PartitionStates []UpdateMetadataRequestTopicStatePartitionState
}
type UpdateMetadataRequestLiveBrokerEndpoint struct {
	Port int32

	Host string

	ListenerName string // v3+

	SecurityProtocolType int16
}
type UpdateMetadataRequestLiveBroker struct {
	ID int32

	Host string

	Port int32

	Endpoints []UpdateMetadataRequestLiveBrokerEndpoint // v1+

	Rack *string // v2+
}

// UpdateMetadataRequest is an advanced request that brokers use to
// issue metadata updates to each other.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Version 1 changed the layout of the live brokers.
//
// Kafka 2.2.0 introduced version 5, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
type UpdateMetadataRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	BrokerEpoch int64 // v5+

	PartitionStates []UpdateMetadataRequestPartitionState

	TopicStates []UpdateMetadataRequestTopicState // v5+

	LiveBrokers []UpdateMetadataRequestLiveBroker
}

func (*UpdateMetadataRequest) Key() int16                 { return 6 }
func (*UpdateMetadataRequest) MaxVersion() int16          { return 5 }
func (v *UpdateMetadataRequest) SetVersion(version int16) { v.Version = version }
func (v *UpdateMetadataRequest) GetVersion() int16        { return v.Version }
func (v *UpdateMetadataRequest) IsAdminRequest()          {}
func (v *UpdateMetadataRequest) ResponseKind() Response {
	return &UpdateMetadataResponse{Version: v.Version}
}

func (v *UpdateMetadataRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 5 {
		v := v.BrokerEpoch
		dst = kbin.AppendInt64(dst, v)
	}
	if version >= 0 && version <= 4 {
		v := v.PartitionStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ControllerEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Leader
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.LeaderEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ISR
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.ZKVersion
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Replicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.OfflineReplicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	if version >= 5 {
		v := v.TopicStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.PartitionStates
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.ControllerEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Leader
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.ISR
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					{
						v := v.ZKVersion
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Replicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
					{
						v := v.OfflineReplicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
		}
	}
	{
		v := v.LiveBrokers
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ID
				dst = kbin.AppendInt32(dst, v)
			}
			if version >= 0 && version <= 0 {
				v := v.Host
				dst = kbin.AppendString(dst, v)
			}
			if version >= 0 && version <= 0 {
				v := v.Port
				dst = kbin.AppendInt32(dst, v)
			}
			if version >= 1 {
				v := v.Endpoints
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Port
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Host
						dst = kbin.AppendString(dst, v)
					}
					if version >= 3 {
						v := v.ListenerName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.SecurityProtocolType
						dst = kbin.AppendInt16(dst, v)
					}
				}
			}
			if version >= 2 {
				v := v.Rack
				dst = kbin.AppendNullableString(dst, v)
			}
		}
	}
	return dst
}

// UpdateMetadataResponses is returned from an UpdateMetadataRequest.
type UpdateMetadataResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16
}

func (v *UpdateMetadataResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

// ControlledShutdownRequest is an advanced request that can be used to
// sthudown a broker in a controlled manner.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented. However, the minimal amount of fields
// here makes the usage rather obvious.
//
// Kafka 2.2.0 introduced version 2, proposed in KIP-380.
type ControlledShutdownRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	BrokerID int32

	BrokerEpoch int64 // v2+
}

func (*ControlledShutdownRequest) Key() int16                 { return 7 }
func (*ControlledShutdownRequest) MaxVersion() int16          { return 2 }
func (v *ControlledShutdownRequest) SetVersion(version int16) { v.Version = version }
func (v *ControlledShutdownRequest) GetVersion() int16        { return v.Version }
func (v *ControlledShutdownRequest) IsAdminRequest()          {}
func (v *ControlledShutdownRequest) ResponseKind() Response {
	return &ControlledShutdownResponse{Version: v.Version}
}

func (v *ControlledShutdownRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.BrokerID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 2 {
		v := v.BrokerEpoch
		dst = kbin.AppendInt64(dst, v)
	}
	return dst
}

type ControlledShutdownResponsePartitionsRemaining struct {
	Topic string

	Partition int32
}

// ControlledShutdownResponse is returned from a ControlledShutdownRequest.
type ControlledShutdownResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	PartitionsRemaining []ControlledShutdownResponsePartitionsRemaining
}

func (v *ControlledShutdownResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.PartitionsRemaining
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ControlledShutdownResponsePartitionsRemaining{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
				}
			}
			v = a
			s.PartitionsRemaining = v
		}
	}
	return b.Complete()
}

type OffsetCommitRequestTopicPartition struct {
	// Partition if a partition to commit offsets for.
	Partition int32

	// Offset is an offset to commit.
	Offset int64

	// Timestamp is the first iteration of tracking how long offset commits
	// should persist in Kafka. This field only existed for v1.
	// The expiration would be timestamp + offset.retention.minutes, or, if
	// timestamp was zero, current time + offset.retention.minutes.
	Timestamp int64 // v1+

	// LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// is the leader epoch of the record this request is committing.
	//
	// The initial leader epoch can be gleaned from a MetadataResponse.
	// To skip log truncation checking, use -1.
	LeaderEpoch int32 // v6+

	// Metadata is optional data to include with committing the offset. This
	// can contain information such as which node is doing the committing, etc.
	Metadata *string
}
type OffsetCommitRequestTopic struct {
	// Topic is a topic to commit offsets for.
	Topic string

	// Partitions contains partitions in a topic for which to commit offsets.
	Partitions []OffsetCommitRequestTopicPartition
}

// OffsetCommitRequest commits offsets for consumed topics / partitions in
// a group.
type OffsetCommitRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group this request is committing offsets to.
	GroupID string

	// GenerationID being -1 and group being empty means the group is being used
	// to store offsets only. No generation validation, no rebalancing.
	GenerationID int32 // v1+

	// MemberID is the ID of the client issuing this request in the group.
	MemberID string // v1+

	// GroupInstanceID is the instance ID of this member in the group (KIP-345).
	GroupInstanceID *string // v7+

	// RetentionTime is how long this commit will persist in Kafka.
	//
	// This was introduced in v2, replacing an individual topic/partition's
	// Timestamp from v1, and was removed in v5 with Kafka 2.1.0.
	//
	// This was removed because rarely committing consumers could have their
	// offsets expired before committing, even though the consumer was still
	// active. After restarting or rebalancing, the consumer would now not know
	// the last committed offset and would have to start at the beginning or end,
	// leading to duplicates or log loss.
	//
	// Post 2.1.0, if this field is empty, offsets are only deleted once the
	// group is empty. Read KIP-211 for more details.
	RetentionTime int64 // v2+

	// Topics is contains topics and partitions for which to commit offsets.
	Topics []OffsetCommitRequestTopic
}

func (*OffsetCommitRequest) Key() int16                   { return 8 }
func (*OffsetCommitRequest) MaxVersion() int16            { return 7 }
func (v *OffsetCommitRequest) SetVersion(version int16)   { v.Version = version }
func (v *OffsetCommitRequest) GetVersion() int16          { return v.Version }
func (v *OffsetCommitRequest) IsGroupCoordinatorRequest() {}
func (v *OffsetCommitRequest) ResponseKind() Response {
	return &OffsetCommitResponse{Version: v.Version}
}

func (v *OffsetCommitRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 1 {
		v := v.GenerationID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 7 {
		v := v.GroupInstanceID
		dst = kbin.AppendNullableString(dst, v)
	}
	if version >= 2 && version <= 4 {
		v := v.RetentionTime
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Offset
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 1 && version <= 1 {
						v := v.Timestamp
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 6 {
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Metadata
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type OffsetCommitResponseResponsePartitionResponse struct {
	// Partition is the partition in a topic this array slot corresponds to.
	Partition int32

	// ErrorCode is the error for this partition response.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// for the group.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// for the topic / partition.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the topic / partition does
	// not exist.
	//
	// OFFSET_METADATA_TOO_LARGE is returned if the request metadata is
	// larger than the brokers offset.metadata.max.bytes.
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// (due to the requested broker shutting down or it has not completed startup).
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
	//
	// UNKNOWN_MEMBER_ID is returned if the group is dead or the group does not
	// know of the request's member ID.
	//
	// REBALANCE_IN_PROGRESS is returned if the group is finishing a rebalance.
	//
	// INVALID_COMMIT_OFFSET_SIZE is returned if the offset commit results in
	// a record batch that is too large (likely due to large metadata).
	ErrorCode int16
}
type OffsetCommitResponseResponse struct {
	// Topic is the topic this offset commit response corresponds to.
	Topic string

	// PartitionResponses contains responses for each requested partition in
	// a topic.
	PartitionResponses []OffsetCommitResponseResponsePartitionResponse
}

// OffsetCommitResponse is returned from an OffsetCommitRequest.
type OffsetCommitResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v3+

	// Responses contains responses for each topic / partition in the commit request.
	Responses []OffsetCommitResponseResponse
}

func (v *OffsetCommitResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 3 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, OffsetCommitResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, OffsetCommitResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

type OffsetFetchRequestTopic struct {
	// Topic is a topic to fetch offsets for.
	Topic string

	// Partitions in a list of partitions in a group to fetch offsets for.
	Partitions []int32
}

// OffsetFetchRequest requests the most recent committed offsets for topic
// partitions in a group.
type OffsetFetchRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group to fetch offsets for.
	GroupID string

	// Topics contains topics to fetch offets for. Version 2+ allows this to be
	// null to return all topics the client is authorized to describe in the group.
	Topics []OffsetFetchRequestTopic
}

func (*OffsetFetchRequest) Key() int16                   { return 9 }
func (*OffsetFetchRequest) MaxVersion() int16            { return 5 }
func (v *OffsetFetchRequest) SetVersion(version int16)   { v.Version = version }
func (v *OffsetFetchRequest) GetVersion() int16          { return v.Version }
func (v *OffsetFetchRequest) IsGroupCoordinatorRequest() {}
func (v *OffsetFetchRequest) ResponseKind() Response     { return &OffsetFetchResponse{Version: v.Version} }

func (v *OffsetFetchRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.Topics
		if version > 2 {
			dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		} else {
			dst = kbin.AppendArrayLen(dst, len(v))
		}
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type OffsetFetchResponseResponsePartitionResponse struct {
	// Partition is the partition in a topic this array slot corresponds to.
	Partition int32

	// Offset is the most recently committed offset for this topic partition
	// in a group.
	Offset int64

	// LeaderEpoch is the leader epoch of the last consumed record.
	//
	// This was proposed in KIP-320 and introduced in Kafka 2.1.0 and allows
	// clients to detect log truncation. See the KIP for more details.
	LeaderEpoch int32 // v5+

	// Metadata is client provided metadata corresponding to the offset commit.
	// This can be useful for adding who made the commit, etc.
	Metadata *string

	// ErrorCode is the error for this partition response.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to the group.
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// (due to the requested broker shutting down or it has not completed startup).
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the requested topic or partition
	// is unknown.
	ErrorCode int16
}
type OffsetFetchResponseResponse struct {
	// Topic is the topic this offset fetch response corresponds to.
	Topic string

	// PartitionResponses contains responses for each requested partition in
	// a topic.
	PartitionResponses []OffsetFetchResponseResponsePartitionResponse
}

// OffsetFetchResponse is returned from an OffsetFetchRequest.
type OffsetFetchResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v3+

	// Responses contains responses for each requested topic/partition.
	Responses []OffsetFetchResponseResponse

	// ErrorCode is a top level error code that applies to all topic/partitions.
	// This will be any group error.
	ErrorCode int16 // v2+
}

func (v *OffsetFetchResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 3 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, OffsetFetchResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, OffsetFetchResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int64()
									s.Offset = v
								}
								if version >= 5 {
									v := b.Int32()
									s.LeaderEpoch = v
								}
								{
									v := b.NullableString()
									s.Metadata = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
		if version >= 2 {
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

// FindCoordinatorRequest requests the coordinator for a group or transaction.
//
// This coordinator is different from the broker leader coordinator. This
// coordinator is the partition leader for the partition that is storing
// the group or transaction ID.
type FindCoordinatorRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// CoordinatorKey is the ID to use for finding the coordinator. For groups,
	// this is the group ID, for transactional producer, this is the
	// transactional ID.
	//
	// In v0 this was called GroupID.
	CoordinatorKey string

	// CoordinatorType is the type that key is. GroupIDs are type 0,
	// transactional IDs are type 1.
	CoordinatorType int8 // v1+
}

func (*FindCoordinatorRequest) Key() int16                 { return 10 }
func (*FindCoordinatorRequest) MaxVersion() int16          { return 2 }
func (v *FindCoordinatorRequest) SetVersion(version int16) { v.Version = version }
func (v *FindCoordinatorRequest) GetVersion() int16        { return v.Version }
func (v *FindCoordinatorRequest) ResponseKind() Response {
	return &FindCoordinatorResponse{Version: v.Version}
}

func (v *FindCoordinatorRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.CoordinatorKey
		dst = kbin.AppendString(dst, v)
	}
	if version >= 1 {
		v := v.CoordinatorType
		dst = kbin.AppendInt8(dst, v)
	}
	return dst
}

// FindCoordinatorResponse is returned from a FindCoordinatorRequest.
type FindCoordinatorResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is the error returned for the request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if for a group ID request and the
	// client is not authorized to describe groups.
	//
	// TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for a transactional ID
	// request and the client is not authorized to describe transactional IDs.
	//
	// INVALID_REQUEST is returned if not asking for a known type (group,
	// or transaction).
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// for the requested ID, or if the requested ID does not exist.
	ErrorCode int16

	// ErrorMessage is an informative message if the request errored.
	ErrorMessage *string // v1+

	// NodeID is the broker ID of the coordinator.
	NodeID int32

	// Host is the host of the coordinator.
	Host string

	// Port is the port of the coordinator.
	Port int32
}

func (v *FindCoordinatorResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		if version >= 1 {
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := b.Int32()
			s.NodeID = v
		}
		{
			v := b.String()
			s.Host = v
		}
		{
			v := b.Int32()
			s.Port = v
		}
	}
	return b.Complete()
}

type StickyMemberMetadataV0CurrentAssignment struct {
	// Topic is a topic the group member is currently assigned.
	Topic string

	// Partitions are the partitions within a topic that a group member is
	// currently assigned.
	Partitions []int32
}

// StickyMemberMetadataV0 is version 0 of what was encoded in UserData for
// GroupMemberMetadata in group join requests.
type StickyMemberMetadataV0 struct {
	// CurrentAssignment is the assignment that a group member has when
	// issuing a join.
	CurrentAssignment []StickyMemberMetadataV0CurrentAssignment
}

func (v *StickyMemberMetadataV0) AppendTo(dst []byte) []byte {
	{
		v := v.CurrentAssignment
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}
func (v *StickyMemberMetadataV0) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := s.CurrentAssignment
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, StickyMemberMetadataV0CurrentAssignment{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							v := b.Int32()
							a = append(a, v)
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.CurrentAssignment = v
		}
	}
	return b.Complete()
}

type StickyMemberMetadataV1CurrentAssignment struct {
	// Topic is a topic the group member is currently assigned.
	Topic string

	// Partitions are the partitions within a topic that a group member is
	// currently assigned.
	Partitions []int32
}

// StickyMemberMetadataV1 is version 1 of what was encoded in UserData for
// GroupMemberMetadata in group join requests.
//
// V1 added generation, which fixed a bug with flaky group members joining
// repeatedly. See KIP-341 for more details.
type StickyMemberMetadataV1 struct {
	// CurrentAssignment is the assignment that a group member has when
	// issuing a join.
	CurrentAssignment []StickyMemberMetadataV1CurrentAssignment

	// Generation is the generation of this join. This is incremented every join.
	Generation int32
}

func (v *StickyMemberMetadataV1) AppendTo(dst []byte) []byte {
	{
		v := v.CurrentAssignment
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	{
		v := v.Generation
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}
func (v *StickyMemberMetadataV1) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := s.CurrentAssignment
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, StickyMemberMetadataV1CurrentAssignment{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							v := b.Int32()
							a = append(a, v)
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.CurrentAssignment = v
		}
		{
			v := b.Int32()
			s.Generation = v
		}
	}
	return b.Complete()
}

// GroupMemberMetadata is the metadata that is usually sent with a join group
// request.
type GroupMemberMetadata struct {
	// Version is either version 0 or version 1.
	Version int16

	// Topics is the list of topics in the group.
	Topics []string

	// UserData is arbitrary client data for a given client in the group.
	// For sticky assignment with version 0, this is StickyMemberMetadataV0.
	// For sticky assignment with version 1, this is StickyMemberMetadataV1.
	UserData []byte
}

func (v *GroupMemberMetadata) AppendTo(dst []byte) []byte {
	{
		v := v.Version
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	{
		v := v.UserData
		dst = kbin.AppendBytes(dst, v)
	}
	return dst
}
func (v *GroupMemberMetadata) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.Version = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				v := b.String()
				a = append(a, v)
			}
			v = a
			s.Topics = v
		}
		{
			v := b.Bytes()
			s.UserData = v
		}
	}
	return b.Complete()
}

type GroupMemberAssignmentTopic struct {
	// Topic is a topic in the assignment.
	Topic string

	// Partitions contains partitions in the assignment.
	Partitions []int32
}

// GroupMemberAssignment is the assignment data that is usually sent with a
// sync group request.
type GroupMemberAssignment struct {
	// Verson is currently version 0.
	Version int16

	// Topics contains topics in the assignment.
	Topics []GroupMemberAssignmentTopic

	// UserData is arbitrary client data for a given client in the group. This
	// was added for the sticky assignment with KIP-341.
	UserData []byte
}

func (v *GroupMemberAssignment) AppendTo(dst []byte) []byte {
	{
		v := v.Version
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	{
		v := v.UserData
		dst = kbin.AppendBytes(dst, v)
	}
	return dst
}
func (v *GroupMemberAssignment) ReadFrom(src []byte) error {
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.Version = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, GroupMemberAssignmentTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							v := b.Int32()
							a = append(a, v)
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
		{
			v := b.Bytes()
			s.UserData = v
		}
	}
	return b.Complete()
}

type JoinGroupRequestGroupProtocol struct {
	// ProtocolName is a name of a protocol. This is arbitrary, but is used
	// in the official client to agree on a partition balancing strategy.
	//
	// The official client uses range, roundrobin, or sticky (which was
	// introduced in KIP-54).
	ProtocolName string

	// ProtocolMetadata is arbitrary information to pass along with this
	// protocol name for this member.
	//
	// Note that while this is not documented in any protocol page,
	// this is usually a serialized GroupMemberMetadata as described in
	// https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal.
	//
	// The protocol metadata is where group members will communicate which
	// topics they collectively as a group want to consume.
	ProtocolMetadata []byte
}

// JoinGroupRequest issues a request to join a Kafka group. This will create a
// group if one does not exist. If joining an existing group, this may trigger
// a group rebalance.
//
// This will trigger a group rebalance if the request is from the group leader,
// or if the request is from a group member with different metadata, or if the
// request is with a new group member.
//
// Version 4 introduced replying to joins of existing groups with
// MEMBER_ID_REQUIRED, which requires re-issuing the join group with the
// returned member ID. See KIP-394 for more details.
//
// Version 5 introduced GroupInstanceID, allowing for more "static" membership.
// See KIP-345 for more details.
type JoinGroupRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group to join.
	GroupID string

	// SessionTimeout is how long a member in the group can go between
	// heartbeats. If a member does not send a heartbeat within this timeout,
	// the broker will remove the member from the group and initiate a rebalance.
	SessionTimeout int32

	// RebalanceTimeout is how long the broker waits for members to join a group
	// once a rebalance begins. Kafka waits for the longest rebalance of all
	// members in the group. Member sessions are still alive; heartbeats will be
	// replied to with REBALANCE_IN_PROGRESS. Those members must transition to
	// joining within this rebalance timeout. Members that do not rejoin within
	// this timeout will be removed from the group. Members must commit offsets
	// within this timeout.
	//
	// The first join for a new group has a 3 second grace period for other
	// members to join; this grace period is extended until the RebalanceTimeout
	// is up or until 3 seconds lapse with no new members.
	RebalanceTimeout int32 // v1+

	// MemberID is the member ID to join the group with. When joining a group for
	// the first time, use the empty string. The response will contain the member
	// ID that should be used going forward.
	MemberID string

	// GroupInstanceID is a user configured ID that is used for making a group
	// member "static", allowing many rebalances to be avoided.
	GroupInstanceID *string // v5+

	// ProtocolType is the "type" of protocol being used for the join group.
	// The initial group creation sets the type; all additional members must
	// have the same type or they will be rejected.
	//
	// This is completely arbitrary, but the Java client and everything else
	// uses "consumer" as the protocol type.
	ProtocolType string

	// GroupProtocols contains arbitrary information that group members use
	// for rebalancing. All group members must agree on at least one protocol
	// name.
	GroupProtocols []JoinGroupRequestGroupProtocol
}

func (*JoinGroupRequest) Key() int16                   { return 11 }
func (*JoinGroupRequest) MaxVersion() int16            { return 5 }
func (v *JoinGroupRequest) SetVersion(version int16)   { v.Version = version }
func (v *JoinGroupRequest) GetVersion() int16          { return v.Version }
func (v *JoinGroupRequest) IsGroupCoordinatorRequest() {}
func (v *JoinGroupRequest) ResponseKind() Response     { return &JoinGroupResponse{Version: v.Version} }

func (v *JoinGroupRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.SessionTimeout
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.RebalanceTimeout
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 5 {
		v := v.GroupInstanceID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.ProtocolType
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.GroupProtocols
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ProtocolName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ProtocolMetadata
				dst = kbin.AppendBytes(dst, v)
			}
		}
	}
	return dst
}

type JoinGroupResponseMember struct {
	// MemberID is a member in this group.
	MemberID string

	// GroupInstanceID is an instance ID of a member in this group (KIP-345).
	GroupInstanceID *string // v5+

	// MemberMetadata is the metadata for this member.
	MemberMetadata []byte
}

// JoinGroupResponse is returned from a JoinGroupRequest.
type JoinGroupResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v2+

	// ErrorCode is the error for the join group request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to the group (no read perms).
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// (due to the requested broker shutting down or it has not completed startup).
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// INVALID_SESSION_TIMEOUT is returned if the requested SessionTimeout is
	// not within the broker's group.{min,max}.session.timeout.ms.
	//
	// INCONSISTENT_GROUP_PROTOCOL is returned if the requested protocols are
	// incompatible with the existing group member's protocols, or if the join
	// was for a new group but contained no protocols.
	//
	// UNKNOWN_MEMBER_ID is returned is the requested group is dead (likely
	// just migrated to another coordinator or the group is temporarily unstable),
	// or if the request was for a new group but contained a non-empty member ID,
	// or if the group does not have the requested member ID (and the client must
	// do the new-join-group dance).
	//
	// MEMBER_ID_REQUIRED is returned on the initial join of an existing group.
	// This error was proposed in KIP-394 and introduced in Kafka 2.2.0 to
	// prevent flaky clients from continually triggering rebalances and prevent
	// these clients from consuming RAM with metadata. If a client sees
	// this error, it should re-issue the join with the MemberID in the response.
	// Non-flaky clients will join with this new member ID, but flaky clients
	// will not join quickly enough before the pending member ID is rotated out
	// due to hitting the session.timeout.ms.
	//
	// GROUP_MAX_SIZE_REACHED is returned as of Kafka 2.2.0 if the group has
	// reached a broker's group.max.size.
	ErrorCode int16

	// GenerationID is the current "generation" of this group.
	GenerationID int32

	// GroupProtocol is the agreed upon protocol name.
	GroupProtocol string

	// LeaderID is the leader member.
	LeaderID string

	// MemberID is the member of the receiving client.
	MemberID string

	// Members contains all other members of this group. Only the group leader
	// receives the members. The leader is responsible for balancing subscribed
	// topic partitions and replying appropriately in a SyncGroup request.
	Members []JoinGroupResponseMember
}

func (v *JoinGroupResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 2 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Int32()
			s.GenerationID = v
		}
		{
			v := b.String()
			s.GroupProtocol = v
		}
		{
			v := b.String()
			s.LeaderID = v
		}
		{
			v := b.String()
			s.MemberID = v
		}
		{
			v := s.Members
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, JoinGroupResponseMember{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.MemberID = v
					}
					if version >= 5 {
						v := b.NullableString()
						s.GroupInstanceID = v
					}
					{
						v := b.Bytes()
						s.MemberMetadata = v
					}
				}
			}
			v = a
			s.Members = v
		}
	}
	return b.Complete()
}

// HeartbeatRequest issues a heartbeat for a member in a group, ensuring that
// Kafka does not expire the member from the group.
type HeartbeatRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group ID this heartbeat is for.
	GroupID string

	// GenerationID is the group generation this heartbeat is for.
	GenerationID int32

	// MemberID is the member ID this member is for.
	MemberID string

	// GroupInstanceID is the instance ID of this member in the group (KIP-345).
	GroupInstanceID *string // v3+
}

func (*HeartbeatRequest) Key() int16                   { return 12 }
func (*HeartbeatRequest) MaxVersion() int16            { return 3 }
func (v *HeartbeatRequest) SetVersion(version int16)   { v.Version = version }
func (v *HeartbeatRequest) GetVersion() int16          { return v.Version }
func (v *HeartbeatRequest) IsGroupCoordinatorRequest() {}
func (v *HeartbeatRequest) ResponseKind() Response     { return &HeartbeatResponse{Version: v.Version} }

func (v *HeartbeatRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.GenerationID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 3 {
		v := v.GroupInstanceID
		dst = kbin.AppendNullableString(dst, v)
	}
	return dst
}

// HeartbeatResponse is returned from a HeartbeatRequest.
type HeartbeatResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is the error for the heartbeat request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to the group (no read perms).
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// (due to the requested broker shutting down or it has not completed startup).
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
	// or if the group is empty or dead.
	//
	// ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
	//
	// REBALANCE_IN_PROGRESS is returned if the group is currently rebalancing.
	ErrorCode int16
}

func (v *HeartbeatResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

type LeaveGroupRequestMember struct {
	MemberID string

	GroupInstanceID *string
}

// LeaveGroupRequest issues a request for a group member to leave the group,
// triggering a group rebalance.
//
// Version 3 changed removed MemberID and added a batch instance+member ID
// way of leaving a group.
type LeaveGroupRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group to leave.
	GroupID string

	// MemberID is the member that is leaving.
	MemberID string

	// Members are member and group instance IDs to cause to leave a group.
	Members []LeaveGroupRequestMember // v3+
}

func (*LeaveGroupRequest) Key() int16                   { return 13 }
func (*LeaveGroupRequest) MaxVersion() int16            { return 3 }
func (v *LeaveGroupRequest) SetVersion(version int16)   { v.Version = version }
func (v *LeaveGroupRequest) GetVersion() int16          { return v.Version }
func (v *LeaveGroupRequest) IsGroupCoordinatorRequest() {}
func (v *LeaveGroupRequest) ResponseKind() Response     { return &LeaveGroupResponse{Version: v.Version} }

func (v *LeaveGroupRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 0 && version <= 2 {
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 3 {
		v := v.Members
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.MemberID
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.GroupInstanceID
				dst = kbin.AppendNullableString(dst, v)
			}
		}
	}
	return dst
}

type LeaveGroupResponseMember struct {
	MemberID string

	GroupInstanceID *string

	// An individual member's leave error code.
	ErrorCode int16
}

// LeaveGroupResponse is returned from a LeaveGroupRequest.
type LeaveGroupResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is the error for the leave group request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to the group (no read perms).
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
	// (due to the requested broker shutting down or it has not completed startup).
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
	// or if the group is empty or dead.
	ErrorCode int16

	// Members are the list of members and group instance IDs that left the group.
	Members []LeaveGroupResponseMember // v3+
}

func (v *LeaveGroupResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		if version >= 3 {
			v := s.Members
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, LeaveGroupResponseMember{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.MemberID = v
					}
					{
						v := b.NullableString()
						s.GroupInstanceID = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.Members = v
		}
	}
	return b.Complete()
}

type SyncGroupRequestGroupAssignment struct {
	// MemberID is the member this assignment is for.
	MemberID string

	// MemberAssignment is the assignment for this member. This is typically
	// of type GroupMemberAssignment.
	MemberAssignment []byte
}

// SyncGroupRequest is issued by all group members after they receive a a
// response for JoinGroup. The group leader is responsible for sending member
// assignments with the request; all other members do not.
//
// Once the leader sends the group assignment, all members will be replied to.
type SyncGroupRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupID is the group ID this sync group is for.
	GroupID string

	// GenerationID is the group generation this sync is for.
	GenerationID int32

	// MemberID is the member ID this member is.
	MemberID string

	// GroupInstanceID is the instance ID of this member in the group (KIP-345).
	GroupInstanceID *string // v3+

	// GroupAssignment, sent only from the group leader, is the topic partition
	// assignment it has decided on for all members.
	GroupAssignment []SyncGroupRequestGroupAssignment
}

func (*SyncGroupRequest) Key() int16                   { return 14 }
func (*SyncGroupRequest) MaxVersion() int16            { return 3 }
func (v *SyncGroupRequest) SetVersion(version int16)   { v.Version = version }
func (v *SyncGroupRequest) GetVersion() int16          { return v.Version }
func (v *SyncGroupRequest) IsGroupCoordinatorRequest() {}
func (v *SyncGroupRequest) ResponseKind() Response     { return &SyncGroupResponse{Version: v.Version} }

func (v *SyncGroupRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.GenerationID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 3 {
		v := v.GroupInstanceID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.GroupAssignment
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.MemberID
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.MemberAssignment
				dst = kbin.AppendBytes(dst, v)
			}
		}
	}
	return dst
}

// SyncGroupResponse is returned from a SyncGroupRequest.
type SyncGroupResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is the error for the sync group request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to the group (no read perms).
	//
	// INVALID_GROUP_ID is returned in the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the coordinator
	// for the requested group.
	//
	// UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
	// or if the group is empty or dead.
	//
	// ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
	//
	// REBALANCE_IN_PROGRESS is returned if the group switched back to rebalancing.
	//
	// UNKNOWN_SERVER_ERROR is returned if the store of the group assignment
	// resulted in a too large message.
	ErrorCode int16

	// MemberAssignment is the assignment for this member that the leader
	// determined.
	MemberAssignment []byte
}

func (v *SyncGroupResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Bytes()
			s.MemberAssignment = v
		}
	}
	return b.Complete()
}

// DescribeGroupsRequest requests metadata for group IDs.
type DescribeGroupsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupIDs is an array of group IDs to request metadata for.
	// If this is empty, the response will include all groups.
	GroupIDs []string

	// IncludeAuthorizedOperations, introduced in Kafka 2.3.0, specifies
	// whether to include a bitfield of AclOperations this client can perform
	// on the groups. See KIP-430 for more details.
	IncludeAuthorizedOperations bool
}

func (*DescribeGroupsRequest) Key() int16                   { return 15 }
func (*DescribeGroupsRequest) MaxVersion() int16            { return 4 }
func (v *DescribeGroupsRequest) SetVersion(version int16)   { v.Version = version }
func (v *DescribeGroupsRequest) GetVersion() int16          { return v.Version }
func (v *DescribeGroupsRequest) IsGroupCoordinatorRequest() {}
func (v *DescribeGroupsRequest) ResponseKind() Response {
	return &DescribeGroupsResponse{Version: v.Version}
}

func (v *DescribeGroupsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupIDs
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	{
		v := v.IncludeAuthorizedOperations
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type DescribeGroupsResponseGroupMember struct {
	// MemberID is the member ID of a member in this group.
	MemberID string

	// GroupInstanceID is the instance ID of this member in the group (KIP-345).
	GroupInstanceID *string // v4+

	// ClientID is the client ID used by this member.
	ClientID string

	// ClientHost is the host this client is running on.
	ClientHost string

	// MemberMetadata is the metadata this member included when joining
	// the group. If using normal (Java-like) consumers, this will be of
	// type GroupMemberMetadata.
	MemberMetadata []byte

	// MemberAssignment is the assignment for this member in the group.
	// If using normal (Java-like) consumers, this will be of type
	// GroupMemberAssignment.
	MemberAssignment []byte
}
type DescribeGroupsResponseGroup struct {
	// ErrorCode is the error code for an individual group in a request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe a group.
	//
	// INVALID_GROUP_ID is returned if the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
	// group is not yet active.
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the
	// coordinator for this group.
	ErrorCode int16

	// GroupID is the id of this group.
	GroupID string

	// State is the state this group is in.
	State string

	// ProtocolType is the "type" of protocol being used for this group.
	ProtocolType string

	// Protocol is the agreed upon protocol for all members in this group.
	Protocol string

	// Members contains members in this group.
	Members []DescribeGroupsResponseGroupMember

	// AuthorizedOperations is a bitfield containing which operations the
	// the client is allowed to perform on this group.
	// This is only returned if requested.
	AuthorizedOperations int32 // v3+
}

// DescribeGroupsResponse is returned from a DescribeGroupsRequest.
type DescribeGroupsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Groups is an array of group metadata.
	Groups []DescribeGroupsResponseGroup
}

func (v *DescribeGroupsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Groups
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeGroupsResponseGroup{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.GroupID = v
					}
					{
						v := b.String()
						s.State = v
					}
					{
						v := b.String()
						s.ProtocolType = v
					}
					{
						v := b.String()
						s.Protocol = v
					}
					{
						v := s.Members
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeGroupsResponseGroupMember{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.MemberID = v
								}
								if version >= 4 {
									v := b.NullableString()
									s.GroupInstanceID = v
								}
								{
									v := b.String()
									s.ClientID = v
								}
								{
									v := b.String()
									s.ClientHost = v
								}
								{
									v := b.Bytes()
									s.MemberMetadata = v
								}
								{
									v := b.Bytes()
									s.MemberAssignment = v
								}
							}
						}
						v = a
						s.Members = v
					}
					if version >= 3 {
						v := b.Int32()
						s.AuthorizedOperations = v
					}
				}
			}
			v = a
			s.Groups = v
		}
	}
	return b.Complete()
}

// ListGroupsRequest issues a request to list all groups.
type ListGroupsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16
}

func (*ListGroupsRequest) Key() int16                 { return 16 }
func (*ListGroupsRequest) MaxVersion() int16          { return 2 }
func (v *ListGroupsRequest) SetVersion(version int16) { v.Version = version }
func (v *ListGroupsRequest) GetVersion() int16        { return v.Version }
func (v *ListGroupsRequest) ResponseKind() Response   { return &ListGroupsResponse{Version: v.Version} }

func (v *ListGroupsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	return dst
}

type ListGroupsResponseGroup struct {
	// GroupID is a Kafka group.
	GroupID string

	// ProtocolType is the protocol type in use by the group.
	ProtocolType string
}

// ListGroupsResponse is returned from a ListGroupsRequest.
type ListGroupsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// ErrorCode is the error returned for the list groups request.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not yet active.
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group manager is loading.
	ErrorCode int16

	// Groups is the list of groups Kafka knows of.
	Groups []ListGroupsResponseGroup
}

func (v *ListGroupsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.Groups
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ListGroupsResponseGroup{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.GroupID = v
					}
					{
						v := b.String()
						s.ProtocolType = v
					}
				}
			}
			v = a
			s.Groups = v
		}
	}
	return b.Complete()
}

type SASLHandshakeRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	Mechanism string
}

func (*SASLHandshakeRequest) Key() int16                 { return 17 }
func (*SASLHandshakeRequest) MaxVersion() int16          { return 1 }
func (v *SASLHandshakeRequest) SetVersion(version int16) { v.Version = version }
func (v *SASLHandshakeRequest) GetVersion() int16        { return v.Version }
func (v *SASLHandshakeRequest) ResponseKind() Response {
	return &SASLHandshakeResponse{Version: v.Version}
}

func (v *SASLHandshakeRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Mechanism
		dst = kbin.AppendString(dst, v)
	}
	return dst
}

type SASLHandshakeResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	EnabledMechanisms []string
}

func (v *SASLHandshakeResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.EnabledMechanisms
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				v := b.String()
				a = append(a, v)
			}
			v = a
			s.EnabledMechanisms = v
		}
	}
	return b.Complete()
}

// ApiVersionsRequest requests what API versions a Kafka broker supports.
//
// Because a client does not know what version of ApiVersionsRequest a broker
// supports, Kafka responds to versions with the highest version it supports.
// This allows clients to always use the latest version of ApiVersionsRequest.
// If the broker supports only a lower version of the request, it will reply
// with an UNSUPPORTED_VERSION error.
type ApiVersionsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16
}

func (*ApiVersionsRequest) Key() int16                 { return 18 }
func (*ApiVersionsRequest) MaxVersion() int16          { return 2 }
func (v *ApiVersionsRequest) SetVersion(version int16) { v.Version = version }
func (v *ApiVersionsRequest) GetVersion() int16        { return v.Version }
func (v *ApiVersionsRequest) ResponseKind() Response   { return &ApiVersionsResponse{Version: v.Version} }

func (v *ApiVersionsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	return dst
}

type ApiVersionsResponseApiVersion struct {
	// ApiKey is the key of a message request.
	ApiKey int16

	// MinVersion is the min version a broker supports for an API key.
	MinVersion int16

	// MaxVersion is the max version a broker supports for an API key.
	MaxVersion int16
}

// ApiVersionsResponse is returned from an ApiVersionsRequest.
type ApiVersionsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ErrorCode is UNSUPPORTED_VERSION if the request was issued with a higher
	// version than the broker supports. Regardless of the error, the broker
	// replies with the ApiVersions it supports.
	ErrorCode int16

	// ApiVersions is an array corresponding to API keys the broker supports
	// and the range of supported versions for each key.
	ApiVersions []ApiVersionsResponseApiVersion

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+
}

func (v *ApiVersionsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.ApiVersions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ApiVersionsResponseApiVersion{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ApiKey = v
					}
					{
						v := b.Int16()
						s.MinVersion = v
					}
					{
						v := b.Int16()
						s.MaxVersion = v
					}
				}
			}
			v = a
			s.ApiVersions = v
		}
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type CreateTopicsRequestTopicReplicaAssignment struct {
	// Partition is a partition to create.
	Partition int32

	// Replicas are broker IDs the partition must exist on.
	Replicas []int32
}
type CreateTopicsRequestTopicConfigEntry struct {
	// ConfigName is a topic level config key (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is a topic level config value (e.g. 1073741824)
	ConfigValue *string
}
type CreateTopicsRequestTopic struct {
	// Topic is a topic to create.
	Topic string

	// NumPartitions is how many partitions to give a topic.
	NumPartitions int32

	// ReplicationFactor is how many replicas every partition must have.
	ReplicationFactor int16

	// ReplicaAssignment is an array to manually dicate replicas and their
	// partitions for a topic. If using this, both ReplicationFactor and
	// NumPartitions must be -1.
	ReplicaAssignment []CreateTopicsRequestTopicReplicaAssignment

	// ConfigEntries is an array of key value config pairs for a topic.
	// These correspond to Kafka Topic-Level Configs: http://kafka.apache.org/documentation/#topicconfigs.
	ConfigEntries []CreateTopicsRequestTopicConfigEntry
}

// CreateTopicsRequest creates Kafka topics.
//
// Version 4, introduced in Kafka 2.4.0, implies client support for
// creation defaults. See KIP-464.
type CreateTopicsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to attempt to create.
	Topics []CreateTopicsRequestTopic

	// Timeout is how long to allow for this request.
	Timeout int32

	// ValidateOnly is makes this request a dry-run; everything is validated but
	// no topics are actually created.
	ValidateOnly bool // v1+
}

func (*CreateTopicsRequest) Key() int16                 { return 19 }
func (*CreateTopicsRequest) MaxVersion() int16          { return 4 }
func (v *CreateTopicsRequest) SetVersion(version int16) { v.Version = version }
func (v *CreateTopicsRequest) GetVersion() int16        { return v.Version }
func (v *CreateTopicsRequest) IsAdminRequest()          {}
func (v *CreateTopicsRequest) ResponseKind() Response {
	return &CreateTopicsResponse{Version: v.Version}
}

func (v *CreateTopicsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.NumPartitions
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ReplicationFactor
				dst = kbin.AppendInt16(dst, v)
			}
			{
				v := v.ReplicaAssignment
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Replicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
			{
				v := v.ConfigEntries
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.ConfigName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.ConfigValue
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type CreateTopicsResponseTopicError struct {
	// Topic is the topic this error response corresponds to.
	Topic string

	// ErrorCode is the error code for an individual topic creation.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	//
	// INVALID_REQUEST is returned if the same topic occurred multiple times
	// in the request.
	//
	// POLICY_VIOLATION is returned if the broker is using a
	// create.topic.policy.class.name that returns a policy violation.
	//
	// INVALID_TOPIC_EXCEPTION if the topic collides with another topic when
	// both topic's names' periods are replaced with underscores (e.g.
	// topic.foo and topic_foo collide).
	//
	// TOPIC_ALREADY_EXISTS is returned if the topic already exists.
	//
	// INVALID_PARTITIONS is returned if the requested number of partitions is
	// <= 0.
	//
	// INVALID_REPLICATION_FACTOR is returned if the requested replication
	// factor is <= 0.
	//
	// INVALID_REPLICA_ASSIGNMENT is returned if not all partitions have the same
	// number of replicas, or duplica replicas are assigned, or the partitions
	// are not consecutive starting from 0.
	//
	// INVALID_CONFIG is returned if the requested topic config is invalid.
	// to create a topic.
	ErrorCode int16

	// ErrorMessage is an informative message if the topic creation failed.
	ErrorMessage *string // v1+
}

// CreateTopicsResponse is returned from a CreateTopicsRequest.
type CreateTopicsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v2+

	// TopicErrors is an the array of requested topics for creation and their
	// creation errors.
	TopicErrors []CreateTopicsResponseTopicError
}

func (v *CreateTopicsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 2 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrors
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, CreateTopicsResponseTopicError{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					if version >= 1 {
						v := b.NullableString()
						s.ErrorMessage = v
					}
				}
			}
			v = a
			s.TopicErrors = v
		}
	}
	return b.Complete()
}

// DeleteTopicsRequest deletes Kafka topics.
type DeleteTopicsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to delete.
	Topics []string

	// Timeout is the millisecond timeout of this request.
	Timeout int32
}

func (*DeleteTopicsRequest) Key() int16                 { return 20 }
func (*DeleteTopicsRequest) MaxVersion() int16          { return 3 }
func (v *DeleteTopicsRequest) SetVersion(version int16) { v.Version = version }
func (v *DeleteTopicsRequest) GetVersion() int16        { return v.Version }
func (v *DeleteTopicsRequest) IsAdminRequest()          {}
func (v *DeleteTopicsRequest) ResponseKind() Response {
	return &DeleteTopicsResponse{Version: v.Version}
}

func (v *DeleteTopicsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type DeleteTopicsResponseTopicErrorCode struct {
	// Topic is the topic requested for deletion.
	Topic string

	// ErrorCode is the error code returned for an individual topic in
	// deletion request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to delete a topic.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the topic.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_DELETION_DISABLED is returned for deletion requests version 3+
	// and brokers >= 2.1.0. INVALID_REQUEST is issued for request versions
	// 0-2 against brokers >= 2.1.0. Otherwise, the request hangs until it
	// times out.
	ErrorCode int16
}

// DeleteTopicsResponse is returned from a DeleteTopicsRequest.
// Version 3 added the TOPIC_DELETION_DISABLED error proposed in KIP-322
// and introduced in Kafka 2.1.0. Prior, the request timed out.
type DeleteTopicsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// TopicErrorCodes is contains the error codes for each topic requested
	// for deletion (or no error code).
	TopicErrorCodes []DeleteTopicsResponseTopicErrorCode
}

func (v *DeleteTopicsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrorCodes
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DeleteTopicsResponseTopicErrorCode{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.TopicErrorCodes = v
		}
	}
	return b.Complete()
}

type DeleteRecordsRequestTopicPartition struct {
	// Partition is a partition to delete records from.
	Partition int32

	// Offset is the offset to set the partition's low watermark (start
	// offset) to. After a successful response, all records before this
	// offset are considered deleted and are no longer readable.
	//
	// To delete all records, use -1, which is mapped to the partition's
	// current high watermark.
	Offset int64
}
type DeleteRecordsRequestTopic struct {
	// Topic is a topic to delete records from.
	Topic string

	// Partitions contains partitions to delete records from.
	Partitions []DeleteRecordsRequestTopicPartition
}

// DeleteRecordsRequest is an admin request to delete records from Kafka.
// This was added for KIP-107.
//
// To delete records, Kafka sets the LastStableOffset for partitions to
// the requested offset. All segments whose max partition is before the
// requested offset are deleted, and any records within the segement before
// the requested offset can no longer be read.
type DeleteRecordsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics contains topics for which to delete records from.
	Topics []DeleteRecordsRequestTopic

	// Timeout is how long to wait for a response before Kafka will return.
	// Kafka waits for all replicas to respond to the delete reords request;
	// any partition that all replicas do not reply to within this limit will
	// have a timeout error.
	Timeout int32
}

func (*DeleteRecordsRequest) Key() int16                 { return 21 }
func (*DeleteRecordsRequest) MaxVersion() int16          { return 1 }
func (v *DeleteRecordsRequest) SetVersion(version int16) { v.Version = version }
func (v *DeleteRecordsRequest) GetVersion() int16        { return v.Version }
func (v *DeleteRecordsRequest) IsAdminRequest()          {}
func (v *DeleteRecordsRequest) ResponseKind() Response {
	return &DeleteRecordsResponse{Version: v.Version}
}

func (v *DeleteRecordsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Offset
						dst = kbin.AppendInt64(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type DeleteRecordsResponseTopicPartition struct {
	// Partition is the partition this response corresponds to.
	Partition int32

	// LowWatermark is the new earliest offset for this partition.
	LowWatermark int64

	// ErrorCode is the error code returned for a given partition in
	// the delete request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned for all partitions if the
	// client is not authorized to delete records.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned for all partitions that
	// the requested broker does not know of.
	//
	// NOT_LEADER_FOR_PARTITION is returned for partitions that the
	// requested broker is not a leader of.
	//
	// OFFSET_OUT_OF_RANGE is returned if the requested offset is
	// negative or higher than the current high watermark.
	//
	// POLICY_VIOLATION is returned if records cannot be deleted due to
	// broker configuration.
	//
	// KAFKA_STORAGE_EXCEPTION is returned if the partition is in an
	// offline log directory.
	ErrorCode int16
}
type DeleteRecordsResponseTopic struct {
	// Topic is the topic this response corresponds to.
	Topic string

	// Partitions contains responses for each partition in a requested topic
	// in the delete records request.
	Partitions []DeleteRecordsResponseTopicPartition
}

// DeleteRecordsResponse is returned from a DeleteRecordsRequest.
type DeleteRecordsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Topics contains responses for each topic in the delete records request.
	Topics []DeleteRecordsResponseTopic
}

func (v *DeleteRecordsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DeleteRecordsResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DeleteRecordsResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int64()
									s.LowWatermark = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

type InitProducerIDRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID *string

	TransactionTimeoutMs int32
}

func (*InitProducerIDRequest) Key() int16                 { return 22 }
func (*InitProducerIDRequest) MaxVersion() int16          { return 2 }
func (v *InitProducerIDRequest) SetVersion(version int16) { v.Version = version }
func (v *InitProducerIDRequest) GetVersion() int16        { return v.Version }
func (v *InitProducerIDRequest) IsTxnCoordinatorRequest() {}
func (v *InitProducerIDRequest) ResponseKind() Response {
	return &InitProducerIDResponse{Version: v.Version}
}

func (v *InitProducerIDRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.TransactionTimeoutMs
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type InitProducerIDResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// CLUSTER_AUTHORIZATION_FAILED if idempotent and not authed
	//
	// transactional errors:
	// TRANSACTIONAL_ID_AUTHORIZATION_FAILED if transactional and not authed
	// INVALID_REQUEST if transactional id is an empty, non-null string
	// INVALID_TRANSACTION_TIMEOUT if timeout equal to over over transaction.max.timeout.ms or under 0
	// COORDINATOR_LOAD_IN_PROGRESS
	// NOT_COORDINATOR
	// COORDINATOR_NOT_AVAILABLE
	// CONCURRENT_TRANSACTIONS
	ErrorCode int16

	// the generated producer ID
	ProducerID int64

	// the current producer epoch
	ProducerEpoch int16
}

func (v *InitProducerIDResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Int64()
			s.ProducerID = v
		}
		{
			v := b.Int16()
			s.ProducerEpoch = v
		}
	}
	return b.Complete()
}

type OffsetForLeaderEpochRequestTopicPartition struct {
	Partition int32

	// CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// allows brokers to check if the client is fenced (has an out of date
	// leader) or is using an unknown leader.
	//
	// The initial leader epoch can be gleaned from a MetadataResponse.
	CurrentLeaderEpoch int32 // v2+

	LeaderEpoch int32
}
type OffsetForLeaderEpochRequestTopic struct {
	Topic string

	Partitions []OffsetForLeaderEpochRequestTopicPartition
}

// TODO more docs.s
// KIP-392 in v3.
type OffsetForLeaderEpochRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ReplicaID is the broker ID of the follower, or -1 if this request is
	// from a consumer.
	ReplicaID int32 // v3+

	Topics []OffsetForLeaderEpochRequestTopic
}

func (*OffsetForLeaderEpochRequest) Key() int16                 { return 23 }
func (*OffsetForLeaderEpochRequest) MaxVersion() int16          { return 3 }
func (v *OffsetForLeaderEpochRequest) SetVersion(version int16) { v.Version = version }
func (v *OffsetForLeaderEpochRequest) GetVersion() int16        { return v.Version }
func (v *OffsetForLeaderEpochRequest) ResponseKind() Response {
	return &OffsetForLeaderEpochResponse{Version: v.Version}
}

func (v *OffsetForLeaderEpochRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	if version >= 3 {
		v := v.ReplicaID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					if version >= 2 {
						v := v.CurrentLeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type OffsetForLeaderEpochResponseTopicPartition struct {
	ErrorCode int16

	Partition int32

	LeaderEpoch int32

	EndOffset int64
}
type OffsetForLeaderEpochResponseTopic struct {
	Topic string

	Partitions []OffsetForLeaderEpochResponseTopicPartition
}
type OffsetForLeaderEpochResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	Topics []OffsetForLeaderEpochResponseTopic
}

func (v *OffsetForLeaderEpochResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, OffsetForLeaderEpochResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, OffsetForLeaderEpochResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int32()
									s.LeaderEpoch = v
								}
								{
									v := b.Int64()
									s.EndOffset = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

type AddPartitionsToTxnRequestTopic struct {
	Topic string

	Partitions []int32
}
type AddPartitionsToTxnRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID string

	ProducerID int64

	ProducerEpoch int16

	Topics []AddPartitionsToTxnRequestTopic
}

func (*AddPartitionsToTxnRequest) Key() int16                 { return 24 }
func (*AddPartitionsToTxnRequest) MaxVersion() int16          { return 1 }
func (v *AddPartitionsToTxnRequest) SetVersion(version int16) { v.Version = version }
func (v *AddPartitionsToTxnRequest) GetVersion() int16        { return v.Version }
func (v *AddPartitionsToTxnRequest) IsTxnCoordinatorRequest() {}
func (v *AddPartitionsToTxnRequest) ResponseKind() Response {
	return &AddPartitionsToTxnResponse{Version: v.Version}
}

func (v *AddPartitionsToTxnRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.ProducerID
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerEpoch
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type AddPartitionsToTxnResponseErrorPartitionError struct {
	Partition int32

	ErrorCode int16
}
type AddPartitionsToTxnResponseError struct {
	Topic string

	PartitionErrors []AddPartitionsToTxnResponseErrorPartitionError
}
type AddPartitionsToTxnResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	Errors []AddPartitionsToTxnResponseError
}

func (v *AddPartitionsToTxnResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Errors
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, AddPartitionsToTxnResponseError{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionErrors
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, AddPartitionsToTxnResponseErrorPartitionError{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.PartitionErrors = v
					}
				}
			}
			v = a
			s.Errors = v
		}
	}
	return b.Complete()
}

type AddOffsetsToTxnRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID string

	ProducerID int64

	ProducerEpoch int16

	GroupID string
}

func (*AddOffsetsToTxnRequest) Key() int16                 { return 25 }
func (*AddOffsetsToTxnRequest) MaxVersion() int16          { return 1 }
func (v *AddOffsetsToTxnRequest) SetVersion(version int16) { v.Version = version }
func (v *AddOffsetsToTxnRequest) GetVersion() int16        { return v.Version }
func (v *AddOffsetsToTxnRequest) IsTxnCoordinatorRequest() {}
func (v *AddOffsetsToTxnRequest) ResponseKind() Response {
	return &AddOffsetsToTxnResponse{Version: v.Version}
}

func (v *AddOffsetsToTxnRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.ProducerID
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerEpoch
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	return dst
}

type AddOffsetsToTxnResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	ErrorCode int16
}

func (v *AddOffsetsToTxnResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

type EndTxnRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID string

	ProducerID int64

	ProducerEpoch int16

	TransactionalResult bool
}

func (*EndTxnRequest) Key() int16                 { return 26 }
func (*EndTxnRequest) MaxVersion() int16          { return 1 }
func (v *EndTxnRequest) SetVersion(version int16) { v.Version = version }
func (v *EndTxnRequest) GetVersion() int16        { return v.Version }
func (v *EndTxnRequest) IsTxnCoordinatorRequest() {}
func (v *EndTxnRequest) ResponseKind() Response   { return &EndTxnResponse{Version: v.Version} }

func (v *EndTxnRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.ProducerID
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerEpoch
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.TransactionalResult
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type EndTxnResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	ErrorCode int16
}

func (v *EndTxnResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

type WriteTxnMarkersRequestTransactionMarkerTopic struct {
	Topic string

	Partitions []int32
}
type WriteTxnMarkersRequestTransactionMarker struct {
	ProducerID int64

	ProducerEpoch int16

	TransactionResult bool

	Topics []WriteTxnMarkersRequestTransactionMarkerTopic

	CoordinatorEpoch int32
}
type WriteTxnMarkersRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionMarkers []WriteTxnMarkersRequestTransactionMarker
}

func (*WriteTxnMarkersRequest) Key() int16                 { return 27 }
func (*WriteTxnMarkersRequest) MaxVersion() int16          { return 0 }
func (v *WriteTxnMarkersRequest) SetVersion(version int16) { v.Version = version }
func (v *WriteTxnMarkersRequest) GetVersion() int16        { return v.Version }
func (v *WriteTxnMarkersRequest) ResponseKind() Response {
	return &WriteTxnMarkersResponse{Version: v.Version}
}

func (v *WriteTxnMarkersRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionMarkers
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ProducerID
				dst = kbin.AppendInt64(dst, v)
			}
			{
				v := v.ProducerEpoch
				dst = kbin.AppendInt16(dst, v)
			}
			{
				v := v.TransactionResult
				dst = kbin.AppendBool(dst, v)
			}
			{
				v := v.Topics
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Topic
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.Partitions
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
			{
				v := v.CoordinatorEpoch
				dst = kbin.AppendInt32(dst, v)
			}
		}
	}
	return dst
}

type WriteTxnMarkersResponseTransactionMarkerTopicPartition struct {
	Partition int32

	ErrorCode int16
}
type WriteTxnMarkersResponseTransactionMarkerTopic struct {
	Topic string

	Partitions []WriteTxnMarkersResponseTransactionMarkerTopicPartition
}
type WriteTxnMarkersResponseTransactionMarker struct {
	ProducerID int64

	Topics []WriteTxnMarkersResponseTransactionMarkerTopic
}
type WriteTxnMarkersResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionMarkers []WriteTxnMarkersResponseTransactionMarker
}

func (v *WriteTxnMarkersResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := s.TransactionMarkers
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, WriteTxnMarkersResponseTransactionMarker{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int64()
						s.ProducerID = v
					}
					{
						v := s.Topics
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, WriteTxnMarkersResponseTransactionMarkerTopic{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.Topic = v
								}
								{
									v := s.Partitions
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, WriteTxnMarkersResponseTransactionMarkerTopicPartition{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.Int32()
												s.Partition = v
											}
											{
												v := b.Int16()
												s.ErrorCode = v
											}
										}
									}
									v = a
									s.Partitions = v
								}
							}
						}
						v = a
						s.Topics = v
					}
				}
			}
			v = a
			s.TransactionMarkers = v
		}
	}
	return b.Complete()
}

type TxnOffsetCommitRequestTopicPartition struct {
	Partition int32

	Offset int64

	// LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// allows brokers to check if the client is fenced (has an out of date
	// leader) or is using an unknown leader.
	//
	// The initial leader epoch can be gleaned from a MetadataResponse.
	// To skip log truncation checking, use -1.
	LeaderEpoch int32 // v2+

	Metadata *string
}
type TxnOffsetCommitRequestTopic struct {
	Topic string

	Partitions []TxnOffsetCommitRequestTopicPartition
}
type TxnOffsetCommitRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID string

	GroupID string

	ProducerID int64

	ProducerEpoch int16

	Topics []TxnOffsetCommitRequestTopic
}

func (*TxnOffsetCommitRequest) Key() int16                 { return 28 }
func (*TxnOffsetCommitRequest) MaxVersion() int16          { return 2 }
func (v *TxnOffsetCommitRequest) SetVersion(version int16) { v.Version = version }
func (v *TxnOffsetCommitRequest) GetVersion() int16        { return v.Version }
func (v *TxnOffsetCommitRequest) IsTxnCoordinatorRequest() {}
func (v *TxnOffsetCommitRequest) ResponseKind() Response {
	return &TxnOffsetCommitResponse{Version: v.Version}
}

func (v *TxnOffsetCommitRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	{
		v := v.ProducerID
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.ProducerEpoch
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Offset
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 2 {
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Metadata
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type TxnOffsetCommitResponseTopicPartition struct {
	Partition int32

	ErrorCode int16
}
type TxnOffsetCommitResponseTopic struct {
	Topic string

	Partitions []TxnOffsetCommitResponseTopicPartition
}
type TxnOffsetCommitResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	Topics []TxnOffsetCommitResponseTopic
}

func (v *TxnOffsetCommitResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, TxnOffsetCommitResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, TxnOffsetCommitResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

// DescribeACLsRequest describes ACLs. Unfortunately, there exists little
// official documentation on this.
type DescribeACLsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ResourceType int8

	ResourceName *string

	ResourcePatternTypeFilter int8

	Principal *string

	Host *string

	Operation int8

	PermissionType int8
}

func (*DescribeACLsRequest) Key() int16                 { return 29 }
func (*DescribeACLsRequest) MaxVersion() int16          { return 1 }
func (v *DescribeACLsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeACLsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeACLsRequest) IsAdminRequest()          {}
func (v *DescribeACLsRequest) ResponseKind() Response {
	return &DescribeACLsResponse{Version: v.Version}
}

func (v *DescribeACLsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ResourceType
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.ResourceName
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.ResourcePatternTypeFilter
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Principal
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Host
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Operation
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.PermissionType
		dst = kbin.AppendInt8(dst, v)
	}
	return dst
}

type DescribeACLsResponseResourceACL struct {
	// Principal is who this ACL applies to.
	Principal string

	// Host is on which host this ACL applies.
	Host string

	// Operation is a type of operation this ACL applies to.
	//
	// UNKNOWN (0) is an operation that we do not understand (old client).
	//
	// ANY (1) mathches any ACL operation in a filter.
	//
	// ALL (2) (implies everything)
	//
	// READ (3) (implies DESCRIBE)
	//
	// WRITE (4) (implies DESCRIBE)
	//
	// CREATE (5)
	//
	// DELETE (6) (implies DESCRIBE)
	//
	// ALTER (7) (implies DESCRIBE)
	//
	// DESCRIBE (8)
	//
	// CLUSTER_ACTION (9)
	//
	// DESCRIBE_CONFIGS (10)
	//
	// ALTER_CONFIGS (11) (implies DESCRIBE_CONFIGS)
	//
	// IDEMPOTENT_WRITE (12)
	Operation int8

	// PermissionType is how this ACL is applied.
	//
	// UNKNOWN is a permission type we do not understand (old client).
	//
	// ANY allows anything.
	//
	// DENY disallows access.
	//
	// ALLOW allows access.
	PermissionType int8
}
type DescribeACLsResponseResource struct {
	ResourceType int8

	ResourceName string

	ResourcePatternType int8 // v1+

	ACLs []DescribeACLsResponseResourceACL
}
type DescribeACLsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	// ErrorCode is the error code returned on request failure.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the cluster.
	//
	// SECURITY_DISABLED is returned if there is no authorizer configured on the
	// broker.
	ErrorCode int16

	ErrorMessage *string

	Resources []DescribeACLsResponseResource
}

func (v *DescribeACLsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeACLsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
					if version >= 1 {
						v := b.Int8()
						s.ResourcePatternType = v
					}
					{
						v := s.ACLs
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeACLsResponseResourceACL{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.Principal = v
								}
								{
									v := b.String()
									s.Host = v
								}
								{
									v := b.Int8()
									s.Operation = v
								}
								{
									v := b.Int8()
									s.PermissionType = v
								}
							}
						}
						v = a
						s.ACLs = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type CreateACLsRequestCreation struct {
	ResourceType int8

	ResourceName string

	ResourcePatternType int8 // v1+

	Principal string

	Host string

	Operation int8

	PermissionType int8
}
type CreateACLsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	Creations []CreateACLsRequestCreation
}

func (*CreateACLsRequest) Key() int16                 { return 30 }
func (*CreateACLsRequest) MaxVersion() int16          { return 1 }
func (v *CreateACLsRequest) SetVersion(version int16) { v.Version = version }
func (v *CreateACLsRequest) GetVersion() int16        { return v.Version }
func (v *CreateACLsRequest) IsAdminRequest()          {}
func (v *CreateACLsRequest) ResponseKind() Response   { return &CreateACLsResponse{Version: v.Version} }

func (v *CreateACLsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Creations
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			if version >= 1 {
				v := v.ResourcePatternType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.Principal
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Host
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Operation
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.PermissionType
				dst = kbin.AppendInt8(dst, v)
			}
		}
	}
	return dst
}

type CreateACLsResponseCreationResponse struct {
	ErrorCode int16

	ErrorMessage *string
}
type CreateACLsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	CreationResponses []CreateACLsResponseCreationResponse
}

func (v *CreateACLsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.CreationResponses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, CreateACLsResponseCreationResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
				}
			}
			v = a
			s.CreationResponses = v
		}
	}
	return b.Complete()
}

type DeleteACLsRequestFilter struct {
	ResourceType int8

	ResourceName *string

	ResourcePatternTypeFilter int8 // v1+

	Principal *string

	Host *string

	Operation int8

	PermissionType int8
}
type DeleteACLsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	Filters []DeleteACLsRequestFilter
}

func (*DeleteACLsRequest) Key() int16                 { return 31 }
func (*DeleteACLsRequest) MaxVersion() int16          { return 1 }
func (v *DeleteACLsRequest) SetVersion(version int16) { v.Version = version }
func (v *DeleteACLsRequest) GetVersion() int16        { return v.Version }
func (v *DeleteACLsRequest) IsAdminRequest()          {}
func (v *DeleteACLsRequest) ResponseKind() Response   { return &DeleteACLsResponse{Version: v.Version} }

func (v *DeleteACLsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Filters
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendNullableString(dst, v)
			}
			if version >= 1 {
				v := v.ResourcePatternTypeFilter
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.Principal
				dst = kbin.AppendNullableString(dst, v)
			}
			{
				v := v.Host
				dst = kbin.AppendNullableString(dst, v)
			}
			{
				v := v.Operation
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.PermissionType
				dst = kbin.AppendInt8(dst, v)
			}
		}
	}
	return dst
}

type DeleteACLsResponseFilterResponseMatchingACL struct {
	ErrorCode int16

	ErrorMessage *string

	ResourceType int8

	ResourceName string

	ResourcePatternType int8 // v1+

	Principal string

	Host string

	Operation int8

	PermissionType int8
}
type DeleteACLsResponseFilterResponse struct {
	ErrorCode int16

	ErrorMessage *string

	MatchingACLs []DeleteACLsResponseFilterResponseMatchingACL
}
type DeleteACLsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	FilterResponses []DeleteACLsResponseFilterResponse
}

func (v *DeleteACLsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.FilterResponses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DeleteACLsResponseFilterResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := s.MatchingACLs
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DeleteACLsResponseFilterResponseMatchingACL{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.NullableString()
									s.ErrorMessage = v
								}
								{
									v := b.Int8()
									s.ResourceType = v
								}
								{
									v := b.String()
									s.ResourceName = v
								}
								if version >= 1 {
									v := b.Int8()
									s.ResourcePatternType = v
								}
								{
									v := b.String()
									s.Principal = v
								}
								{
									v := b.String()
									s.Host = v
								}
								{
									v := b.Int8()
									s.Operation = v
								}
								{
									v := b.Int8()
									s.PermissionType = v
								}
							}
						}
						v = a
						s.MatchingACLs = v
					}
				}
			}
			v = a
			s.FilterResponses = v
		}
	}
	return b.Complete()
}

type DescribeConfigsRequestResource struct {
	// ResourceType is an enum corresponding to the type of config to describe.
	// The only two valid values are 2 (for topic) and 4 (for broker).
	ResourceType int8

	// ResourceName is the name of config to describe.
	//
	// If the requested type is a topic, this corresponds to a topic name.
	//
	// If the requested type if a broker, this should either be empty or be
	// the ID of the broker this request is issued to. If it is empty, this
	// returns all broker configs, but only the dynamic configuration values.
	// If a specific ID, this returns all broker config values.
	ResourceName string

	// ConfigNames is a list of config entries to return. Null requests all.
	ConfigNames []string
}

// DescribeConfigsRequest issues a request to describe configs that Kafka
// currently has. These are the key/value pairs that one uses to configure
// brokers and topics.
type DescribeConfigsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Resources is a list of resources to describe.
	Resources []DescribeConfigsRequestResource

	// IncludeSynonyms signifies whether to return config entry synonyms for
	// all config entries.
	IncludeSynonyms bool // v1+
}

func (*DescribeConfigsRequest) Key() int16                 { return 32 }
func (*DescribeConfigsRequest) MaxVersion() int16          { return 2 }
func (v *DescribeConfigsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeConfigsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeConfigsRequest) IsAdminRequest()          {}
func (v *DescribeConfigsRequest) ResponseKind() Response {
	return &DescribeConfigsResponse{Version: v.Version}
}

func (v *DescribeConfigsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Resources
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ConfigNames
				dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
				for i := range v {
					v := v[i]
					dst = kbin.AppendString(dst, v)
				}
			}
		}
	}
	if version >= 1 {
		v := v.IncludeSynonyms
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type DescribeConfigsResponseResourceConfigEntryConfigSynonym struct {
	ConfigName string

	ConfigValue *string

	ConfigSource int8
}
type DescribeConfigsResponseResourceConfigEntry struct {
	// ConfigName is a key this entry corresponds to (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is the value for this config key. If the key is sensitive,
	// the value will be null.
	ConfigValue *string

	// ReadOnly signifies whether this is not a dynamic config option.
	ReadOnly bool

	// IsDefault is whether this is a default config option. This has been
	// replaced in favor of ConfigSource.
	IsDefault bool

	// ConfigSource is where this config entry is from. Note that if there
	// are no config synonyms, the source is DEFAULT_CONFIG. The values of
	// this enum are as follows.
	//
	// UNKNOWN (0): unknown; e.g. an altar request was issued with no source set
	//
	// DYNAMIC_TOPIC_CONFIG (1): dynamic topic config for a specific topic
	//
	// DYNAMIC_BROKER_CONFIG (2): dynamic broker config for a specific broker
	//
	// DYNAMIC_DEFAULT_BROKER_CONFIG (3): dynamic broker config used as the default for all brokers in a cluster
	//
	// STATIC_BROKER_CONFIG (4): static broker config provided at start up
	//
	// DEFAULT_CONFIG (5): built-in default configuration for those that have defaults
	ConfigSource int8 // v1+

	// IsSensitive signifies whether this is a sensitive config key, which
	// is either a password or an unknown type.
	IsSensitive bool

	// ConfigSynonyms contains config key/value pairs that can be used in
	// place of this config entry, in order of preference.
	ConfigSynonyms []DescribeConfigsResponseResourceConfigEntryConfigSynonym // v1+
}
type DescribeConfigsResponseResource struct {
	// ErrorCode is the error code returned for describing configs.
	//
	// INVALID_REQUEST is returned if asking to descibe an invalid resource
	// type.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if asking to describe broker
	// configs but the client is not authorized to do so.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if asking to describe topic
	// configs but the client is not authorized to do so.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic.
	ErrorCode int16

	// ErrorMessage is an informative message if the describe config failed.
	ErrorMessage *string

	// ResourceType is the enum corresponding to the type of described config.
	ResourceType int8

	// ResourceName is the name corresponding to the describe config request.
	ResourceName string

	// ConfigEntries contains information about key/value config pairs for
	// the requested resource.
	ConfigEntries []DescribeConfigsResponseResourceConfigEntry
}

// DescribeConfigsResponse is returned from a DescribeConfigsRequest.
type DescribeConfigsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Resources are responses for each resource in the describe config request.
	Resources []DescribeConfigsResponseResource
}

func (v *DescribeConfigsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeConfigsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
					{
						v := s.ConfigEntries
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeConfigsResponseResourceConfigEntry{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.ConfigName = v
								}
								{
									v := b.NullableString()
									s.ConfigValue = v
								}
								{
									v := b.Bool()
									s.ReadOnly = v
								}
								if version >= 0 && version <= 0 {
									v := b.Bool()
									s.IsDefault = v
								}
								if version >= 1 {
									v := b.Int8()
									s.ConfigSource = v
								}
								{
									v := b.Bool()
									s.IsSensitive = v
								}
								if version >= 1 {
									v := s.ConfigSynonyms
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, DescribeConfigsResponseResourceConfigEntryConfigSynonym{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.String()
												s.ConfigName = v
											}
											{
												v := b.NullableString()
												s.ConfigValue = v
											}
											{
												v := b.Int8()
												s.ConfigSource = v
											}
										}
									}
									v = a
									s.ConfigSynonyms = v
								}
							}
						}
						v = a
						s.ConfigEntries = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type AlterConfigsRequestResourceConfigEntry struct {
	// ConfigName is a key to set (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is a value to set for the key (e.g. 10).
	ConfigValue *string
}
type AlterConfigsRequestResource struct {
	// ResourceType is an enum corresponding to the type of config to alter.
	// The only two valid values are 2 (for topic) and 4 (for broker).
	ResourceType int8

	// ResourceName is the name of config to alter.
	//
	// If the requested type is a topic, this corresponds to a topic name.
	//
	// If the requested type if a broker, this should either be empty or be
	// the ID of the broker this request is issued to. If it is empty, this
	// updates all broker configs. If a specific ID, this updates just the
	// broker. Using a specific ID also ensures that brokers reload config
	// or secret files even if the file path has not changed. Lastly, password
	// config options can only be defined on a per broker basis.
	ResourceName string

	// ConfigEntries contains key/value config pairs to set on the resource.
	ConfigEntries []AlterConfigsRequestResourceConfigEntry
}

// AlterConfigsRequest issues a request to alter either topic or broker
// configs.
//
// Note that to alter configs, you must specify the whole config on every
// request. All existing non-static values will be removed. This means that
// to add one key/value to a config, you must describe the config and then
// issue an alter request with the current config with the new key value.
// This also means that dynamic sensitive values, which are not returned
// in describe configs, will be lost.
//
// To fix this problem, the AlterConfigs request / response was deprecated
// in Kafka 2.3.0 in favor of the new IncrementalAlterConfigs request / response.
// See KIP-339 for more details.
type AlterConfigsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Resources is an array of configs to alter.
	Resources []AlterConfigsRequestResource

	// ValidateOnly validates the request but does not apply it.
	ValidateOnly bool
}

func (*AlterConfigsRequest) Key() int16                 { return 33 }
func (*AlterConfigsRequest) MaxVersion() int16          { return 1 }
func (v *AlterConfigsRequest) SetVersion(version int16) { v.Version = version }
func (v *AlterConfigsRequest) GetVersion() int16        { return v.Version }
func (v *AlterConfigsRequest) IsAdminRequest()          {}
func (v *AlterConfigsRequest) ResponseKind() Response {
	return &AlterConfigsResponse{Version: v.Version}
}

func (v *AlterConfigsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Resources
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ConfigEntries
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.ConfigName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.ConfigValue
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type AlterConfigsResponseResource struct {
	// ErrorCode is the error code returned for altering configs.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
	// configs but the client is not authorized to do so.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
	// configs but the client is not authorized to do so.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic.
	//
	// INVALID_REQUEST is returned if the requested config is invalid or if
	// asking Kafka to alter an invalid resource.
	ErrorCode int16

	// ErrorMessage is an informative message if the alter config failed.
	ErrorMessage *string

	// ResourceType is the enum corresponding to the type of altered config.
	ResourceType int8

	// ResourceName is the name corresponding to the alter config request.
	ResourceName string
}

// AlterConfigsResponse is returned from an AlterConfigsRequest.
type AlterConfigsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Resources are responses for each resource in the alter request.
	Resources []AlterConfigsResponseResource
}

func (v *AlterConfigsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, AlterConfigsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type AlterReplicaLogDirsRequestLogDirTopic struct {
	// Topic is a topic to move.
	Topic string

	// Partitions contains partitions for the topic to move.
	Partitions []int32
}
type AlterReplicaLogDirsRequestLogDir struct {
	// LogDir is an absolute path where everything listed below should
	// end up.
	LogDir string

	// Topics contains topics to move to the above log directory.
	Topics []AlterReplicaLogDirsRequestLogDirTopic
}

// AlterReplicaLogDirsRequest requests for log directories to be moved
// within Kafka.
//
// This is primarily useful for moving directories between disks.
type AlterReplicaLogDirsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// LogDirs contains absolute paths of where you want things to end up.
	LogDirs []AlterReplicaLogDirsRequestLogDir
}

func (*AlterReplicaLogDirsRequest) Key() int16                 { return 34 }
func (*AlterReplicaLogDirsRequest) MaxVersion() int16          { return 1 }
func (v *AlterReplicaLogDirsRequest) SetVersion(version int16) { v.Version = version }
func (v *AlterReplicaLogDirsRequest) GetVersion() int16        { return v.Version }
func (v *AlterReplicaLogDirsRequest) IsAdminRequest()          {}
func (v *AlterReplicaLogDirsRequest) ResponseKind() Response {
	return &AlterReplicaLogDirsResponse{Version: v.Version}
}

func (v *AlterReplicaLogDirsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.LogDirs
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.LogDir
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Topics
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Topic
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.Partitions
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
		}
	}
	return dst
}

type AlterReplicaLogDirsResponseTopicPartition struct {
	// Partition is the partition this array slot corresponds to.
	Partition int32

	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to alter replica dirs.
	//
	// LOG_DIR_NOT_FOUND is returned when the requested log directory
	// is not in the broker config.
	//
	// KAFKA_STORAGE_EXCEPTION is returned when destination directory or
	// requested replica is offline.
	//
	// REPLICA_NOT_AVAILABLE is returned if the replica does not exist
	// yet.
	ErrorCode int16
}
type AlterReplicaLogDirsResponseTopic struct {
	// Topic is the topic this array slot corresponds to.
	Topic string

	// Partitions contains responses to each partition that was requested
	// to move.
	Partitions []AlterReplicaLogDirsResponseTopicPartition
}

// AlterReplicaLogDirsResponse is returned from an AlterReplicaLogDirsRequest.
type AlterReplicaLogDirsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Topics contains responses to each topic that had partitions requested
	// for moving.
	Topics []AlterReplicaLogDirsResponseTopic
}

func (v *AlterReplicaLogDirsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, AlterReplicaLogDirsResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, AlterReplicaLogDirsResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

type DescribeLogDirsRequestTopic struct {
	// Topic is a topic to describe the log dir of.
	Topic string

	// Partitions contains topic partitions to describe the log dirs of.
	Partitions []int32
}

// DescribeLogDirsRequest requests directory information for topic partitions.
// This request was added in support of KIP-113.
type DescribeLogDirsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to describe the log dirs of. If this is
	// null, the response includes all topics and all of their partitions.
	Topics []DescribeLogDirsRequestTopic
}

func (*DescribeLogDirsRequest) Key() int16                 { return 35 }
func (*DescribeLogDirsRequest) MaxVersion() int16          { return 1 }
func (v *DescribeLogDirsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeLogDirsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeLogDirsRequest) IsAdminRequest()          {}
func (v *DescribeLogDirsRequest) ResponseKind() Response {
	return &DescribeLogDirsResponse{Version: v.Version}
}

func (v *DescribeLogDirsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type DescribeLogDirsResponseLogDirTopicPartition struct {
	// Partition is a partition ID.
	Partition int32

	// Size is the total size of the log sements of this partition, in bytes.
	Size int64

	// OffsetLag is how far behind the log end offset is compared to
	// the partition's high watermark (if this is the current log for
	// the partition) or compared to the current replica's log end
	// offset (if this is the future log for the patition).
	//
	// The math is,
	//
	// if IsFuture, localLogEndOffset - futurelogEndOffset.
	//
	// otherwise, max(localHighWatermark - logEndOffset, 0).
	OffsetLag int64

	// IsFuture is true if this replica was created by an
	// AlterReplicaLogDirsRequest and will replace the current log of the
	// replica in the future.
	IsFuture bool
}
type DescribeLogDirsResponseLogDirTopic struct {
	// Topic is the name of a Kafka topic.
	Topic string

	// Partitions is the set of queried partitions for a topic that are
	// within a log directory.
	Partitions []DescribeLogDirsResponseLogDirTopicPartition
}
type DescribeLogDirsResponseLogDir struct {
	// ErrorCode is the error code returned for descrbing log dirs.
	//
	// KAFKA_STORAGE_ERROR is returned if the log directoy is offline.
	ErrorCode int16

	// LogDir is the absolute path of a log directory.
	LogDir string

	// Topics is an array of topics within a log directory.
	Topics []DescribeLogDirsResponseLogDirTopic
}

// DescribeLogDirsResponse is returned from a DescribeLogDirsRequest.
type DescribeLogDirsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// LogDirs pairs log directories with the topics and partitions that are
	// stored in those directores.
	LogDirs []DescribeLogDirsResponseLogDir
}

func (v *DescribeLogDirsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.LogDirs
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeLogDirsResponseLogDir{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.LogDir = v
					}
					{
						v := s.Topics
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeLogDirsResponseLogDirTopic{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.Topic = v
								}
								{
									v := s.Partitions
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, DescribeLogDirsResponseLogDirTopicPartition{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.Int32()
												s.Partition = v
											}
											{
												v := b.Int64()
												s.Size = v
											}
											{
												v := b.Int64()
												s.OffsetLag = v
											}
											{
												v := b.Bool()
												s.IsFuture = v
											}
										}
									}
									v = a
									s.Partitions = v
								}
							}
						}
						v = a
						s.Topics = v
					}
				}
			}
			v = a
			s.LogDirs = v
		}
	}
	return b.Complete()
}

type SASLAuthenticateRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	SASLAuthBytes []byte
}

func (*SASLAuthenticateRequest) Key() int16                 { return 36 }
func (*SASLAuthenticateRequest) MaxVersion() int16          { return 1 }
func (v *SASLAuthenticateRequest) SetVersion(version int16) { v.Version = version }
func (v *SASLAuthenticateRequest) GetVersion() int16        { return v.Version }
func (v *SASLAuthenticateRequest) ResponseKind() Response {
	return &SASLAuthenticateResponse{Version: v.Version}
}

func (v *SASLAuthenticateRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.SASLAuthBytes
		dst = kbin.AppendBytes(dst, v)
	}
	return dst
}

type SASLAuthenticateResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	ErrorMessage *string

	SASLAuthBytes []byte

	SessionLifetimeMs int64 // v1+
}

func (v *SASLAuthenticateResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := b.Bytes()
			s.SASLAuthBytes = v
		}
		if version >= 1 {
			v := b.Int64()
			s.SessionLifetimeMs = v
		}
	}
	return b.Complete()
}

type CreatePartitionsRequestTopicPartition struct {
	// Topic is a topic for which to create additional partitions for.
	Topic string

	// Count is the final count of partitions this topic must have after this
	// request. This must be greater than the current number of partitions.
	Count int32

	// Assignment is a two-level array, the first corresponding to new
	// partitions, the second contining broker IDs for where new partition
	// replicas should live.
	//
	// The second level, the replicas, cannot have duplicate broker IDs
	// (i.e. you cannot replicate a single partition twice on the same
	// broker). Additionally, the number of replicas must match the current
	// number of replicas per partition on the topic.
	//
	// The first level's length must be equal to the delta of Count and
	// the current number of partitions.
	Assignment [][]int32
}

// CreatePartitionsRequest creates additional partitions for topics.
type CreatePartitionsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// TopicPartitions paris topics with their partition creation requests.
	TopicPartitions []CreatePartitionsRequestTopicPartition

	// Timeout is how long to allow for this request.
	Timeout int32

	// ValidateOnly is makes this request a dry-run; everything is validated but
	// no partitions are actually created.
	ValidateOnly bool
}

func (*CreatePartitionsRequest) Key() int16                 { return 37 }
func (*CreatePartitionsRequest) MaxVersion() int16          { return 1 }
func (v *CreatePartitionsRequest) SetVersion(version int16) { v.Version = version }
func (v *CreatePartitionsRequest) GetVersion() int16        { return v.Version }
func (v *CreatePartitionsRequest) IsAdminRequest()          {}
func (v *CreatePartitionsRequest) ResponseKind() Response {
	return &CreatePartitionsResponse{Version: v.Version}
}

func (v *CreatePartitionsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TopicPartitions
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Count
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Assignment
				dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
				for i := range v {
					v := v[i]
					dst = kbin.AppendArrayLen(dst, len(v))
					for i := range v {
						v := v[i]
						dst = kbin.AppendInt32(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type CreatePartitionsResponseTopicError struct {
	// Topic is the topic that partitions were requested to be made for.
	Topic string

	// ErrorCode is the error code returned for each topic in the request.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to create partitions for a topic.
	//
	// INVALID_REQUEST is returned for duplicate topics in the request.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the topic is queued for deletion.
	//
	// REASSIGNMENT_IN_PROGRESS is returned if the request was issued while
	// partitions were being reassigned.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the topic for which to create partitions.
	//
	// INVALID_PARTITIONS is returned if the request would drop the total
	// count of partitions down, or if the request would not add any more
	// partitions, or if the request uses unknown brokers, or if the request
	// assigns a different number of brokers than the increase in the
	// partition count.
	ErrorCode int16

	// ErrorMessage is an informative message if the topic creation failed.
	ErrorMessage *string
}

// CreatePartitionsResponse is returned from a CreatePartitionsRequest.
type CreatePartitionsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// TopicErrors is an the array of requested topics with partition creations
	// and their creation errors.
	TopicErrors []CreatePartitionsResponseTopicError
}

func (v *CreatePartitionsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrors
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, CreatePartitionsResponseTopicError{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
				}
			}
			v = a
			s.TopicErrors = v
		}
	}
	return b.Complete()
}

type CreateDelegationTokenRequestRenewer struct {
	PrincipalType string

	Name string
}
type CreateDelegationTokenRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	Renewers []CreateDelegationTokenRequestRenewer

	MaxLifetime int64
}

func (*CreateDelegationTokenRequest) Key() int16                 { return 38 }
func (*CreateDelegationTokenRequest) MaxVersion() int16          { return 1 }
func (v *CreateDelegationTokenRequest) SetVersion(version int16) { v.Version = version }
func (v *CreateDelegationTokenRequest) GetVersion() int16        { return v.Version }
func (v *CreateDelegationTokenRequest) IsAdminRequest()          {}
func (v *CreateDelegationTokenRequest) ResponseKind() Response {
	return &CreateDelegationTokenResponse{Version: v.Version}
}

func (v *CreateDelegationTokenRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Renewers
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.PrincipalType
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Name
				dst = kbin.AppendString(dst, v)
			}
		}
	}
	{
		v := v.MaxLifetime
		dst = kbin.AppendInt64(dst, v)
	}
	return dst
}

type CreateDelegationTokenResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	PrincipalType string

	OwnerName string

	IssueTimestamp int64

	ExpiryTimestamp int64

	MaxTimestamp int64

	TokenID string

	HMAC []byte

	ThrottleTimeMs int32
}

func (v *CreateDelegationTokenResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.String()
			s.PrincipalType = v
		}
		{
			v := b.String()
			s.OwnerName = v
		}
		{
			v := b.Int64()
			s.IssueTimestamp = v
		}
		{
			v := b.Int64()
			s.ExpiryTimestamp = v
		}
		{
			v := b.Int64()
			s.MaxTimestamp = v
		}
		{
			v := b.String()
			s.TokenID = v
		}
		{
			v := b.Bytes()
			s.HMAC = v
		}
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type RenewDelegationTokenRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	HMAC []byte

	RenewTimePeriod int64
}

func (*RenewDelegationTokenRequest) Key() int16                 { return 39 }
func (*RenewDelegationTokenRequest) MaxVersion() int16          { return 1 }
func (v *RenewDelegationTokenRequest) SetVersion(version int16) { v.Version = version }
func (v *RenewDelegationTokenRequest) GetVersion() int16        { return v.Version }
func (v *RenewDelegationTokenRequest) IsAdminRequest()          {}
func (v *RenewDelegationTokenRequest) ResponseKind() Response {
	return &RenewDelegationTokenResponse{Version: v.Version}
}

func (v *RenewDelegationTokenRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.HMAC
		dst = kbin.AppendBytes(dst, v)
	}
	{
		v := v.RenewTimePeriod
		dst = kbin.AppendInt64(dst, v)
	}
	return dst
}

type RenewDelegationTokenResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	ExpiryTimestamp int64

	ThrottleTimeMs int32
}

func (v *RenewDelegationTokenResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Int64()
			s.ExpiryTimestamp = v
		}
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type ExpireDelegationTokenRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	HMAC []byte

	ExpiryTimePeriod int64
}

func (*ExpireDelegationTokenRequest) Key() int16                 { return 40 }
func (*ExpireDelegationTokenRequest) MaxVersion() int16          { return 1 }
func (v *ExpireDelegationTokenRequest) SetVersion(version int16) { v.Version = version }
func (v *ExpireDelegationTokenRequest) GetVersion() int16        { return v.Version }
func (v *ExpireDelegationTokenRequest) IsAdminRequest()          {}
func (v *ExpireDelegationTokenRequest) ResponseKind() Response {
	return &ExpireDelegationTokenResponse{Version: v.Version}
}

func (v *ExpireDelegationTokenRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.HMAC
		dst = kbin.AppendBytes(dst, v)
	}
	{
		v := v.ExpiryTimePeriod
		dst = kbin.AppendInt64(dst, v)
	}
	return dst
}

type ExpireDelegationTokenResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	ExpiryTimestamp int64

	ThrottleTimeMs int32
}

func (v *ExpireDelegationTokenResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Int64()
			s.ExpiryTimestamp = v
		}
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type DescribeDelegationTokenRequestOwner struct {
	PrincipalType string

	Name string
}
type DescribeDelegationTokenRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Owners contains owners to describe delegation tokens for, or null for all.
	Owners []DescribeDelegationTokenRequestOwner
}

func (*DescribeDelegationTokenRequest) Key() int16                 { return 41 }
func (*DescribeDelegationTokenRequest) MaxVersion() int16          { return 1 }
func (v *DescribeDelegationTokenRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeDelegationTokenRequest) GetVersion() int16        { return v.Version }
func (v *DescribeDelegationTokenRequest) IsAdminRequest()          {}
func (v *DescribeDelegationTokenRequest) ResponseKind() Response {
	return &DescribeDelegationTokenResponse{Version: v.Version}
}

func (v *DescribeDelegationTokenRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Owners
		dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		for i := range v {
			v := &v[i]
			{
				v := v.PrincipalType
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Name
				dst = kbin.AppendString(dst, v)
			}
		}
	}
	return dst
}

type DescribeDelegationTokenResponseTokenDetailRenewer struct {
	PrincipalType string

	Name string
}
type DescribeDelegationTokenResponseTokenDetail struct {
	PrincipalType string

	OwnerName string

	IssueTimestamp int64

	ExpiryTimestamp int64

	MaxTimestamp int64

	TokenID string

	HMAC []byte

	Renewers []DescribeDelegationTokenResponseTokenDetailRenewer
}
type DescribeDelegationTokenResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	TokenDetails []DescribeDelegationTokenResponseTokenDetail

	ThrottleTimeMs int32
}

func (v *DescribeDelegationTokenResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.TokenDetails
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeDelegationTokenResponseTokenDetail{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.PrincipalType = v
					}
					{
						v := b.String()
						s.OwnerName = v
					}
					{
						v := b.Int64()
						s.IssueTimestamp = v
					}
					{
						v := b.Int64()
						s.ExpiryTimestamp = v
					}
					{
						v := b.Int64()
						s.MaxTimestamp = v
					}
					{
						v := b.String()
						s.TokenID = v
					}
					{
						v := b.Bytes()
						s.HMAC = v
					}
					{
						v := s.Renewers
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeDelegationTokenResponseTokenDetailRenewer{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.PrincipalType = v
								}
								{
									v := b.String()
									s.Name = v
								}
							}
						}
						v = a
						s.Renewers = v
					}
				}
			}
			v = a
			s.TokenDetails = v
		}
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

// DeleteGroupsRequest deletes consumer groups. This request was added for
// Kafka 1.1.0 corresponding to the removal of RetentionTime from
// OffsetCommitRequest. See KIP-229 for more details.
type DeleteGroupsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Groups is a list of groups to delete.
	Groups []string
}

func (*DeleteGroupsRequest) Key() int16                   { return 42 }
func (*DeleteGroupsRequest) MaxVersion() int16            { return 1 }
func (v *DeleteGroupsRequest) SetVersion(version int16)   { v.Version = version }
func (v *DeleteGroupsRequest) GetVersion() int16          { return v.Version }
func (v *DeleteGroupsRequest) IsGroupCoordinatorRequest() {}
func (v *DeleteGroupsRequest) ResponseKind() Response {
	return &DeleteGroupsResponse{Version: v.Version}
}

func (v *DeleteGroupsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Groups
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	return dst
}

type DeleteGroupsResponseGroupErrorCode struct {
	// GroupID is a group ID requested for deletion.
	GroupID string

	// ErrorCode is the error code returned for this group's deletion request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to delete a group.
	//
	// INVALID_GROUP_ID is returned if the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
	// group is not yet active.
	//
	// GROUP_ID_NOT_FOUND is returned if the group ID does not exist.
	//
	// NON_EMPTY_GROUP is returned if attempting to delete a group that is
	// not in the empty state.
	ErrorCode int16
}

// DeleteGroupsResponse is returned from a DeleteGroupsRequest.
type DeleteGroupsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// GroupErrorCodes are the responses to each group requested for deletion.
	GroupErrorCodes []DeleteGroupsResponseGroupErrorCode
}

func (v *DeleteGroupsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.GroupErrorCodes
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DeleteGroupsResponseGroupErrorCode{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.GroupID = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.GroupErrorCodes = v
		}
	}
	return b.Complete()
}

type ElectPreferredLeadersRequestTopicPartition struct {
	// Topic is a topic to trigger leader elections for (but only for the
	// partitions below).
	Topic string

	// Partitions is an array of partitions in a topic to trigger leader
	// elections for.
	Partitions []int32
}

// ElectPreferredLeadersRequest begins a leader election for all given topic
// partitions. This request was added in Kafka 2.2.0 to replace the zookeeper
// only option of triggering leader elections before. See KIP-183 for more
// details. KIP-460 introduced the ElectionType field with Kafka 2.4.0.
type ElectPreferredLeadersRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ElectionType is the type of election to conduct. 0 elects the preferred
	// replica, 1 elects the first live replica if there are no in-sync replicas
	// (i.e., unclean leader election).
	ElectionType int8 // v1+

	// TopicPartitions is an array of topics and corresponding partitions to
	// trigger leader elections for, or null for all.
	TopicPartitions []ElectPreferredLeadersRequestTopicPartition

	// TimeoutMs is how long to wait for the response. This limits how long to
	// wait since responses are not sent until election results are complete.
	TimeoutMs int32
}

func (*ElectPreferredLeadersRequest) Key() int16                 { return 43 }
func (*ElectPreferredLeadersRequest) MaxVersion() int16          { return 1 }
func (v *ElectPreferredLeadersRequest) SetVersion(version int16) { v.Version = version }
func (v *ElectPreferredLeadersRequest) GetVersion() int16        { return v.Version }
func (v *ElectPreferredLeadersRequest) IsAdminRequest()          {}
func (v *ElectPreferredLeadersRequest) ResponseKind() Response {
	return &ElectPreferredLeadersResponse{Version: v.Version}
}

func (v *ElectPreferredLeadersRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	if version >= 1 {
		v := v.ElectionType
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.TopicPartitions
		dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	{
		v := v.TimeoutMs
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type ElectPreferredLeadersResponseReplicaElectionResultPartitionResult struct {
	// PartitionID is the partition for this result.
	PartitionID int32

	// ErrorCode is the error code returned for this topic/partition leader
	// election.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to trigger leader elections.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the topic/partition does
	// not exist on any broker in the cluster (this is slightly different
	// from the usual meaning of a single broker not knowing of the topic
	// partition).
	//
	// PREFERRED_LEADER_NOT_AVAILABLE is returned if the preferred leader
	// could not be elected (for example, the preferred leader was not in
	// the ISR).
	ErrorCode int16

	// ErrorMessage is an informative message if the leader election failed.
	ErrorMessage *string
}
type ElectPreferredLeadersResponseReplicaElectionResult struct {
	// Topic is topic for the given partition results below.
	Topic string

	// PartitionResults contains election results for a topic's partitions.
	PartitionResults []ElectPreferredLeadersResponseReplicaElectionResultPartitionResult
}
type ElectPreferredLeadersResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after responding to this request.
	ThrottleTimeMs int32

	// ErrorCode is any error that applies to all partitions.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to reassign partitions.
	ErrorCode int16

	// ReplicaElectionResults is the leader election results for each requested
	// topic / partition.
	ReplicaElectionResults []ElectPreferredLeadersResponseReplicaElectionResult
}

func (v *ElectPreferredLeadersResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.ReplicaElectionResults
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ElectPreferredLeadersResponseReplicaElectionResult{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResults
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ElectPreferredLeadersResponseReplicaElectionResultPartitionResult{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.PartitionID = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.NullableString()
									s.ErrorMessage = v
								}
							}
						}
						v = a
						s.PartitionResults = v
					}
				}
			}
			v = a
			s.ReplicaElectionResults = v
		}
	}
	return b.Complete()
}

type IncrementalAlterConfigsRequestResourceConfigEntry struct {
	// ConfigName is a key to modify (e.g. segment.bytes).
	ConfigName string

	// Op is the type of operation to perform for this config name.
	//
	// SET (0) is to set a configuration value; the value must not be null.
	//
	// DELETE (1) is to delete a configuration key.
	//
	// APPEND (2) is to add a value to the list of values for a key (if the
	// key is for a list of values).
	//
	// SUBTRACT (3) is to remove a value from a list of values (if the key
	// is for a list of values).
	Op int8

	// ConfigValue is a value to set for the key (e.g. 10).
	ConfigValue *string
}
type IncrementalAlterConfigsRequestResource struct {
	// ResourceType is an enum corresponding to the type of config to alter.
	// The only two valid values are 2 (for topic) and 4 (for broker).
	ResourceType int8

	// ResourceName is the name of config to alter.
	//
	// If the requested type is a topic, this corresponds to a topic name.
	//
	// If the requested type if a broker, this should either be empty or be
	// the ID of the broker this request is issued to. If it is empty, this
	// updates all broker configs. If a specific ID, this updates just the
	// broker. Using a specific ID also ensures that brokers reload config
	// or secret files even if the file path has not changed. Lastly, password
	// config options can only be defined on a per broker basis.
	ResourceName string

	// ConfigEntries contains key/value config pairs to set on the resource.
	ConfigEntries []IncrementalAlterConfigsRequestResourceConfigEntry
}

// IncrementalAlterConfigsRequest issues ar equest to alter either topic or
// broker configs.
//
// This API was added in Kafka 2.3.0 to replace AlterConfigs. The key benefit
// of this API is that consumers do not need to know the full config state
// to add or remove new config options. See KIP-339 for more details.
type IncrementalAlterConfigsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Resources is an array of configs to alter.
	Resources []IncrementalAlterConfigsRequestResource

	// ValidateOnly validates the request but does not apply it.
	ValidateOnly bool
}

func (*IncrementalAlterConfigsRequest) Key() int16                 { return 44 }
func (*IncrementalAlterConfigsRequest) MaxVersion() int16          { return 0 }
func (v *IncrementalAlterConfigsRequest) SetVersion(version int16) { v.Version = version }
func (v *IncrementalAlterConfigsRequest) GetVersion() int16        { return v.Version }
func (v *IncrementalAlterConfigsRequest) IsAdminRequest()          {}
func (v *IncrementalAlterConfigsRequest) ResponseKind() Response {
	return &IncrementalAlterConfigsResponse{Version: v.Version}
}

func (v *IncrementalAlterConfigsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Resources
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ConfigEntries
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.ConfigName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.Op
						dst = kbin.AppendInt8(dst, v)
					}
					{
						v := v.ConfigValue
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type IncrementalAlterConfigsResponseResponse struct {
	// ErrorCode is the error code returned for incrementally altering configs.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
	// configs but the client is not authorized to do so.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
	// configs but the client is not authorized to do so.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic.
	//
	// INVALID_REQUEST is returned if the requested config is invalid or if
	// asking Kafka to alter an invalid resource.
	ErrorCode int16

	// ErrorMessage is an informative message if the incremental alter config failed.
	ErrorMessage *string

	// ResourceType is the enum corresponding to the type of altered config.
	ResourceType int8

	// ResourceName is the name corresponding to the incremental alter config
	// request.
	ResourceName string
}

// IncrementalAlterConfigsResponse is returned from an IncrementalAlterConfigsRequest.
type IncrementalAlterConfigsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after responding to this request.
	ThrottleTimeMs int32

	Responses []IncrementalAlterConfigsResponseResponse
}

func (v *IncrementalAlterConfigsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, IncrementalAlterConfigsResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

type AlterPartitionReassignmentsRequestTopicPartition struct {
	// Partition is a partition to reassign.
	Partition int32

	// Replicas are replicas to place the partition on, or null to
	// cancel a pending reassignment of this partition.
	Replicas []int32
}
type AlterPartitionReassignmentsRequestTopic struct {
	// Topic is a topic to reassign the partitions of.
	Topic string

	// Partitions contains partitions to reassign.
	Partitions []AlterPartitionReassignmentsRequestTopicPartition
}

// AlterPartitionReassignmentsRequest, proposed in KIP-455 and implemented in
// Kafka 2.4.0, is a request to reassign partitions to certain brokers.
//
// ACL wise, this requires ALTER on CLUSTER.
type AlterPartitionReassignmentsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// TimeoutMs is how long to wait for the response.
	TimeoutMs int32

	// Topics are topics for which to reassign partitions of.
	Topics []AlterPartitionReassignmentsRequestTopic
}

func (*AlterPartitionReassignmentsRequest) Key() int16                 { return 45 }
func (*AlterPartitionReassignmentsRequest) MaxVersion() int16          { return 0 }
func (v *AlterPartitionReassignmentsRequest) SetVersion(version int16) { v.Version = version }
func (v *AlterPartitionReassignmentsRequest) GetVersion() int16        { return v.Version }
func (v *AlterPartitionReassignmentsRequest) IsAdminRequest()          {}
func (v *AlterPartitionReassignmentsRequest) ResponseKind() Response {
	return &AlterPartitionReassignmentsResponse{Version: v.Version}
}

func (v *AlterPartitionReassignmentsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TimeoutMs
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Replicas
						dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
		}
	}
	return dst
}

type AlterPartitionReassignmentsResponseTopicPartition struct {
	// Partition is the partition being responded to.
	Partition int32

	// ErrorCode is the error code returned for partition reassignments.
	//
	// REQUEST_TIMED_OUT is returned if the request timed out.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to reassign partitions.
	//
	// NO_REASSIGNMENT_IN_PROGRESS is returned for partition reassignment
	// cancellations when the partition was not being reassigned.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic or the topic is being deleted.
	ErrorCode int16

	// ErrorMessage is an informative message if the partition reassignment failed.
	ErrorMessage *string
}
type AlterPartitionReassignmentsResponseTopic struct {
	// Topic is the topic being responded to.
	Topic string

	// Partitions contains responses for partitions.
	Partitions []AlterPartitionReassignmentsResponseTopicPartition
}

// AlterPartitionReassignmentsResponse is returned for an AlterPartitionReassignmentsRequest.
type AlterPartitionReassignmentsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after responding to this request.
	ThrottleTimeMs int32

	// ErrorCode is any global (applied to all partitions) error code.
	ErrorCode int16

	// ErrorMessage is any global (applied to all partitions) error message.
	ErrorMessage *string

	// Topics contains responses for each topic requested.
	Topics []AlterPartitionReassignmentsResponseTopic
}

func (v *AlterPartitionReassignmentsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, AlterPartitionReassignmentsResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, AlterPartitionReassignmentsResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.NullableString()
									s.ErrorMessage = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

type ListPartitionReassignmentsRequestTopic struct {
	// Topic is a topic to list in progress partition reassingments of.
	Topic string

	// Partitions are partitions to list in progress reassignments of.
	Partitions []int32
}

// ListPartitionReassignmentsRequest, proposed in KIP-455 and implemented in
// Kafka 2.4.0, is a request to list in progress partition reassignments.
//
// ACL wise, this requires DESCRIBE on CLUSTER.
type ListPartitionReassignmentsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// TimeoutMs is how long to wait for the response.
	TimeoutMs int32

	// Topics are topics to list in progress partition reassignments of, or null
	// to list everything.
	Topics []ListPartitionReassignmentsRequestTopic
}

func (*ListPartitionReassignmentsRequest) Key() int16                 { return 46 }
func (*ListPartitionReassignmentsRequest) MaxVersion() int16          { return 0 }
func (v *ListPartitionReassignmentsRequest) SetVersion(version int16) { v.Version = version }
func (v *ListPartitionReassignmentsRequest) GetVersion() int16        { return v.Version }
func (v *ListPartitionReassignmentsRequest) IsAdminRequest()          {}
func (v *ListPartitionReassignmentsRequest) ResponseKind() Response {
	return &ListPartitionReassignmentsResponse{Version: v.Version}
}

func (v *ListPartitionReassignmentsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TimeoutMs
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type ListPartitionReassignmentsResponseTopicPartition struct {
	// Partition is the partition being responded to.
	Partition int32

	// Replicas is the partition's current replicas.
	Replicas []int32

	// AddingReplicas are replicas currently being added to the partition.
	AddingReplicas []int32

	// RemovingReplicas are replicas currently being removed from the partition.
	RemovingReplicas []int32
}
type ListPartitionReassignmentsResponseTopic struct {
	// Topic is the topic being responded to.
	Topic string

	// Partitions contains responses for partitions.
	Partitions []ListPartitionReassignmentsResponseTopicPartition
}

// ListPartitionReassignmentsResponse is returned for a ListPartitionReassignmentsRequest.
type ListPartitionReassignmentsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after responding to this request.
	ThrottleTimeMs int32

	// ErrorCode is the error code returned for listing reassignments.
	//
	// REQUEST_TIMED_OUT is returned if the request timed out.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
	// authorized to reassign partitions.
	ErrorCode int16

	// ErrorMessage is any global (applied to all partitions) error message.
	ErrorMessage *string

	// Topics contains responses for each topic requested.
	Topics []ListPartitionReassignmentsResponseTopic
}

func (v *ListPartitionReassignmentsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := s.Topics
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ListPartitionReassignmentsResponseTopic{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.Partitions
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ListPartitionReassignmentsResponseTopicPartition{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := s.Replicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.Replicas = v
								}
								{
									v := s.AddingReplicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.AddingReplicas = v
								}
								{
									v := s.RemovingReplicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.RemovingReplicas = v
								}
							}
						}
						v = a
						s.Partitions = v
					}
				}
			}
			v = a
			s.Topics = v
		}
	}
	return b.Complete()
}

// RequestForKey returns the request corresponding to the given request key
// or nil if the key is unknown.
func RequestForKey(key int16) Request {
	switch key {
	default:
		return nil
	case 0:
		return new(ProduceRequest)
	case 1:
		return new(FetchRequest)
	case 2:
		return new(ListOffsetsRequest)
	case 3:
		return new(MetadataRequest)
	case 4:
		return new(LeaderAndISRRequest)
	case 5:
		return new(StopReplicaRequest)
	case 6:
		return new(UpdateMetadataRequest)
	case 7:
		return new(ControlledShutdownRequest)
	case 8:
		return new(OffsetCommitRequest)
	case 9:
		return new(OffsetFetchRequest)
	case 10:
		return new(FindCoordinatorRequest)
	case 11:
		return new(JoinGroupRequest)
	case 12:
		return new(HeartbeatRequest)
	case 13:
		return new(LeaveGroupRequest)
	case 14:
		return new(SyncGroupRequest)
	case 15:
		return new(DescribeGroupsRequest)
	case 16:
		return new(ListGroupsRequest)
	case 17:
		return new(SASLHandshakeRequest)
	case 18:
		return new(ApiVersionsRequest)
	case 19:
		return new(CreateTopicsRequest)
	case 20:
		return new(DeleteTopicsRequest)
	case 21:
		return new(DeleteRecordsRequest)
	case 22:
		return new(InitProducerIDRequest)
	case 23:
		return new(OffsetForLeaderEpochRequest)
	case 24:
		return new(AddPartitionsToTxnRequest)
	case 25:
		return new(AddOffsetsToTxnRequest)
	case 26:
		return new(EndTxnRequest)
	case 27:
		return new(WriteTxnMarkersRequest)
	case 28:
		return new(TxnOffsetCommitRequest)
	case 29:
		return new(DescribeACLsRequest)
	case 30:
		return new(CreateACLsRequest)
	case 31:
		return new(DeleteACLsRequest)
	case 32:
		return new(DescribeConfigsRequest)
	case 33:
		return new(AlterConfigsRequest)
	case 34:
		return new(AlterReplicaLogDirsRequest)
	case 35:
		return new(DescribeLogDirsRequest)
	case 36:
		return new(SASLAuthenticateRequest)
	case 37:
		return new(CreatePartitionsRequest)
	case 38:
		return new(CreateDelegationTokenRequest)
	case 39:
		return new(RenewDelegationTokenRequest)
	case 40:
		return new(ExpireDelegationTokenRequest)
	case 41:
		return new(DescribeDelegationTokenRequest)
	case 42:
		return new(DeleteGroupsRequest)
	case 43:
		return new(ElectPreferredLeadersRequest)
	case 44:
		return new(IncrementalAlterConfigsRequest)
	case 45:
		return new(AlterPartitionReassignmentsRequest)
	case 46:
		return new(ListPartitionReassignmentsRequest)
	}
}

// NameForKey returns the name (e.g., "Fetch") corresponding to a given request key
// or "" if the key is unknown.
func NameForKey(key int16) string {
	switch key {
	default:
		return ""
	case 0:
		return "Produce"
	case 1:
		return "Fetch"
	case 2:
		return "ListOffsets"
	case 3:
		return "Metadata"
	case 4:
		return "LeaderAndISR"
	case 5:
		return "StopReplica"
	case 6:
		return "UpdateMetadata"
	case 7:
		return "ControlledShutdown"
	case 8:
		return "OffsetCommit"
	case 9:
		return "OffsetFetch"
	case 10:
		return "FindCoordinator"
	case 11:
		return "JoinGroup"
	case 12:
		return "Heartbeat"
	case 13:
		return "LeaveGroup"
	case 14:
		return "SyncGroup"
	case 15:
		return "DescribeGroups"
	case 16:
		return "ListGroups"
	case 17:
		return "SASLHandshake"
	case 18:
		return "ApiVersions"
	case 19:
		return "CreateTopics"
	case 20:
		return "DeleteTopics"
	case 21:
		return "DeleteRecords"
	case 22:
		return "InitProducerID"
	case 23:
		return "OffsetForLeaderEpoch"
	case 24:
		return "AddPartitionsToTxn"
	case 25:
		return "AddOffsetsToTxn"
	case 26:
		return "EndTxn"
	case 27:
		return "WriteTxnMarkers"
	case 28:
		return "TxnOffsetCommit"
	case 29:
		return "DescribeACLs"
	case 30:
		return "CreateACLs"
	case 31:
		return "DeleteACLs"
	case 32:
		return "DescribeConfigs"
	case 33:
		return "AlterConfigs"
	case 34:
		return "AlterReplicaLogDirs"
	case 35:
		return "DescribeLogDirs"
	case 36:
		return "SASLAuthenticate"
	case 37:
		return "CreatePartitions"
	case 38:
		return "CreateDelegationToken"
	case 39:
		return "RenewDelegationToken"
	case 40:
		return "ExpireDelegationToken"
	case 41:
		return "DescribeDelegationToken"
	case 42:
		return "DeleteGroups"
	case 43:
		return "ElectPreferredLeaders"
	case 44:
		return "IncrementalAlterConfigs"
	case 45:
		return "AlterPartitionReassignments"
	case 46:
		return "ListPartitionReassignments"
	}
}

package kmsg

import "github.com/twmb/kgo/kbin"

// Code generated by kgo/generate. DO NOT EDIT.

// MaxKey is the maximum key used for any messages in this package.
// Note that this value may change as Kafka adds more messages.
const MaxKey = 37

// Header is user provided metadata for a record. Kafka does not look at
// headers at all; they are solely for producers and consumers.
type Header struct {
	Key string

	Value []byte
}

// A Record is a Kafka v0.11.0.0 record. It corresponds to an individual
// message as it is written on the wire.
type Record struct {
	// Length is the length of this record on the wire of everything that
	// follows this field. It is an int32 encoded as a varint.
	Length int32

	// Attributes are record level attributes. This field currently is unused.
	Attributes int8

	// TimestampDelta is the millisecond delta of this record's timestamp
	// from the record's RecordBatch's FirstTimestamp.
	TimestampDelta int32

	// OffsetDelta is the delta of this record's offset from the record's
	// RecordBatch's FirstOffset.
	//
	// For producing, this is usually equal to the index of the record in
	// the record batch.
	OffsetDelta int32

	// Key is an blob of data for a record.
	//
	// Key's are usually used for hashing the record to specific Kafka partitions.
	Key []byte

	// Value is  a blob of data. This field is the main "message" portion of a
	// record.
	Value []byte

	// Headers are optional user provided metadata for records. Unlike normal
	// arrays, the number of headers is encoded as a varint.
	Headers []Header
}

// RecordBatch is a Kafka concept that groups many individual records together
// in a more optimized format.
type RecordBatch struct {
	// NullableBytesLength is not officially a field in a RecordBatch, however,
	// RecordBatch is a special form of NULLABLE_BYTES. Since all nullable bytes
	// must be prefixed with a int32 length, we throw that here.
	// This length should not include itself, only data that follows.
	NullableBytesLength int32

	// FirstOffset is the first offset in a record batch.
	//
	// For producing, this is usually 0.
	FirstOffset int64

	// Length is the wire length of everything that follows this field.
	Length int32

	// PartitionLeaderEpoch is a number that Kafka uses for cluster
	// communication. Clients generally do not need to worry about this
	// field and producers should set it to -1.
	PartitionLeaderEpoch int32

	// Magic is the current "magic" number of this message format.
	// The current magic number is 2.
	Magic int8

	// CRC is the crc of everything that follows this field using the
	// Castagnoli polynomial.
	CRC int32

	// Attributes describe the records array of this batch.
	//
	// Bits 0 thru 3 correspond to compression:
	//   - 000 is no compression
	//   - 001 is snappy compression
	//   - 010 is lz4 compression
	//   - 011 is zstd compression (produce request version 7+)
	//
	// Bit 4 is the timestamp type, with 0 meaning CreateTime corresponding
	// to the timestamp being from the producer, and 1 meaning LogAppendTime
	// corresponding to the timestamp being from the broker.
	// Setting this to LogAppendTime will cause batches to be rejected.
	//
	// Bit 5 indicates whether the batch is part of a transaction (1 is yes).
	//
	// Bit 6 indicates if the batch includes a control message (1 is yes).
	// Control messages are used to enable transactions and are generated from
	// the broker. Clients should not return control batches to applications.
	Attributes int16

	// LastOffsetDelta is the offset of the last message in a batch. This is
	// by the broker to ensure correct behavior even with batch compaction.
	LastOffsetDelta int32

	// FirstTimestamp is the timestamp (in milliseconds) of the first record
	// in a batch.
	FirstTimestamp int64

	// MaxTimestamp is the timestamp (in milliseconds) of the last record
	// in a batch. Similar to LastOffsetDelta, this is used to ensure correct
	// behavior with compacting.
	MaxTimestamp int64

	// ProducerID is the broker assigned producerID from an InitProducerID
	// request.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	ProducerID int64

	// ProducerEpoch is the broker assigned producerEpoch from an InitProducerID
	// request.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	ProducerEpoch int16

	// FirstSequence is the producer assigned sequence number used by the
	// broker to deduplicate messages.
	//
	// Clients that wish to support idempotent messages and transactions must
	// set this field.
	//
	// The sequence number for each record in a batch is OffsetDelta + FirstSequence.
	FirstSequence int32

	// Records are the batch of records to send.
	//
	// Note that to compress a batch, you compress the entire set of records
	// and then use that as the value for a single record.
	Records []Record
}
type ProduceRequestTopicDataData struct {
	// Partition is a partition to send a record batch to.
	Partition int32

	// Records is a batch of records to write to a topic's partition.
	Records RecordBatch
}
type ProduceRequestTopicData struct {
	// Topic is a topic to send record batches to.
	Topic string

	// Data is an array of partitions to send record batches to.
	Data []ProduceRequestTopicDataData
}

// ProduceRequest issues records to be created to Kafka.
//
// The min version of this type is currently 2, released with Kafka 0.11.0.0.
// Prior, the RecordBatch format was completely different (and was called a
// MessageSet).
//
// Note that the special client ID "__admin_client" will allow you to produce
// records to internal topics. This is generally recommended if you want to
// break your Kafka cluster.
type ProduceRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionID *string // v3+

	// Acks specifies the number of acks that the partition leaders must receive
	// from in sync replicas before considering a record batch fully written.
	//
	// Valid values are -1, 0, or 1 corresponding to all, none, or one.
	//
	// Note that if no acks are requested, Kafka will close the connection
	// if any topic or partition errors to trigger a client metadata refresh.
	Acks int16

	// Timeout is the millisecond timeout of this request.
	Timeout int32

	// TopicData is an array of topics to send record batches to.
	TopicData []ProduceRequestTopicData
}

func (*ProduceRequest) Key() int16                 { return 0 }
func (*ProduceRequest) MaxVersion() int16          { return 7 }
func (*ProduceRequest) MinVersion() int16          { return 2 }
func (v *ProduceRequest) SetVersion(version int16) { v.Version = version }
func (v *ProduceRequest) GetVersion() int16        { return v.Version }
func (v *ProduceRequest) ResponseKind() Response   { return &ProduceResponse{Version: v.Version} }

func (v *ProduceRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	if version >= 3 {
		v := v.TransactionID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Acks
		dst = kbin.AppendInt16(dst, v)
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.TopicData
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Data
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := &v.Records
						{
							v := v.NullableBytesLength
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.FirstOffset
							dst = kbin.AppendInt64(dst, v)
						}
						{
							v := v.Length
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.PartitionLeaderEpoch
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.Magic
							dst = kbin.AppendInt8(dst, v)
						}
						{
							v := v.CRC
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.Attributes
							dst = kbin.AppendInt16(dst, v)
						}
						{
							v := v.LastOffsetDelta
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.FirstTimestamp
							dst = kbin.AppendInt64(dst, v)
						}
						{
							v := v.MaxTimestamp
							dst = kbin.AppendInt64(dst, v)
						}
						{
							v := v.ProducerID
							dst = kbin.AppendInt64(dst, v)
						}
						{
							v := v.ProducerEpoch
							dst = kbin.AppendInt16(dst, v)
						}
						{
							v := v.FirstSequence
							dst = kbin.AppendInt32(dst, v)
						}
						{
							v := v.Records
							dst = kbin.AppendArrayLen(dst, len(v))
							for i := range v {
								v := &v[i]
								{
									v := v.Length
									dst = kbin.AppendVarint(dst, v)
								}
								{
									v := v.Attributes
									dst = kbin.AppendInt8(dst, v)
								}
								{
									v := v.TimestampDelta
									dst = kbin.AppendVarint(dst, v)
								}
								{
									v := v.OffsetDelta
									dst = kbin.AppendVarint(dst, v)
								}
								{
									v := v.Key
									dst = kbin.AppendVarintBytes(dst, v)
								}
								{
									v := v.Value
									dst = kbin.AppendVarintBytes(dst, v)
								}
								{
									v := v.Headers
									dst = kbin.AppendVarint(dst, int32(len(v)))
									for i := range v {
										v := &v[i]
										{
											v := v.Key
											dst = kbin.AppendVarintString(dst, v)
										}
										{
											v := v.Value
											dst = kbin.AppendVarintBytes(dst, v)
										}
									}
								}
							}
						}
					}
				}
			}
		}
	}
	return dst
}

type ProduceResponseResponsePartitionResponse struct {
	// Partition is the partition this response pertains to.
	Partition int32

	// ErrorCode is any error for a topic/partition in the request.
	// There are many error codes for produce requests.
	//
	// TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for all topics and
	// partitions if the request had a transactional ID but the client
	// is not authorized for transactions.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned for all topics and partitions
	// if the request was idempotent but the client is not authorized
	// for idempotent requests.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned for all topics the client
	// is not authorized to talk to.
	//
	// INVALID_REQUIRED_ACKS is returned if the request contained an invalid
	// number for "acks".
	//
	// CORRUPT_MESSAGE is returned for many reasons, generally related to
	// problems with messages (invalid magic, size mismatch, etc.).
	//
	// MESSAGE_TOO_LARGE is returned if a record batch is larger than the
	// broker's configured max.message.size.
	//
	// RECORD_LIST_TOO_LARGE is returned if the record batch is larger than
	// the broker's segment.bytes.
	//
	// INVALID_TIMESTAMP is returned if the record batch uses LogAppendTime
	// or if the timestamp delta from when the broker receives the message
	// is more than the broker's log.message.timestamp.difference.max.ms.
	//
	// UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if using a Kafka v2 message
	// format (i.e. RecordBatch) feature (idempotence) while sending v1
	// messages (i.e. a MessageSet).
	//
	// KAFKA_STORAGE_ERROR is returned if the log directory for a partition
	// is offline.
	//
	// NOT_ENOUGH_REPLICAS is returned if all acks are required, but there
	// are not enough in sync replicas yet.
	//
	// NOT_ENOUGH_REPLICAS_AFTER_APPEND is returned on old Kafka versions
	// (pre 0.11.0.0) when a message was written to disk and then Kafka
	// noticed not enough replicas existed to replicate the message.
	//
	// DUPLICATE_SEQUENCE_NUMBER is returned for Kafka <1.1.0 when a
	// sequence number is detected as a duplicate. After, out of order
	// is returned.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
	// is unknown.
	//
	// NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
	// for this partition. This means that the client has stale metadata.
	//
	// INVALID_PRODUCER_EPOCH is returned if the produce request was
	// attempted with an old epoch. Either there is a newer producer using
	// the same transaction ID, or the transaction ID used has expired.
	//
	// UNKNOWN_PRODUCER_ID, added in Kafka 1.0.0 (message format v5+) is
	// returned if the producer used an ID that Kafka does not know about.
	// The LogStartOffset must be checked in this case. If the offset is
	// greater than the last acknowledged offset, then no data loss has
	// occurred; the client just sent data so long ago that Kafka rotated
	// the partition out of existence and no longer knows of this producer
	// ID. In this case, initialize a new ID. If the log start offset is
	// equal to or less than what the client sent prior, then data loss
	// has occurred. This See KAFKA-5793 for more details.
	//
	// OUT_OF_ORDER_SEQUENCE_NUMBER is sent if the batch's FirstSequence was
	// not what it should be (the last FirstSequence, plus the number of
	// records in the last batch, plus one). After 1.0.0, this generally
	// means data loss. Before, there could be confusion on if the broker
	// actually rotated the partition out of existence (this is why
	// UNKNOWN_PRODUCER_ID was introduced).
	ErrorCode int16

	// BaseOffset is the offset that the records in the produce request began
	// at in the partition.
	BaseOffset int64

	// LogAppendTime is the time that records were appended to the partition
	// inside Kafka. This is only not -1 if records were written with the log
	// append time flag (which producers cannot do).
	LogAppendTime int64 // v2+

	// LogStartOffset, introduced in Kafka 1.0.0,  can be used to see if an
	// UNKNOWN_PRODUCER_ID means Kafka rotated records containing the used
	// producer ID out of existence, or if Kafka lost data.
	LogStartOffset int64 // v5+
}
type ProduceResponseResponse struct {
	// Topic is the topic this response pertains to.
	Topic string

	// PartitionResponses is an array of responses for the partition's that
	// batches were sent to.
	PartitionResponses []ProduceResponseResponsePartitionResponse
}

// ProduceResponse is returned from a ProduceRequest.
type ProduceResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Responses is an array of responses for the topic's that batches were sent
	// to.
	Responses []ProduceResponseResponse

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32
}

func (v *ProduceResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ProduceResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ProduceResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int64()
									s.BaseOffset = v
								}
								if version >= 2 {
									v := b.Int64()
									s.LogAppendTime = v
								}
								if version >= 5 {
									v := b.Int64()
									s.LogStartOffset = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type FetchRequestTopicPartition struct {
	Partition int32

	CurrentLeaderEpoch int32 // v9+

	FetchOffset int64

	LogStartOffset int64 // v5+

	PartitionMaxBytes int32
}
type FetchRequestTopic struct {
	Topic string

	Partitions []FetchRequestTopicPartition
}
type FetchRequestForgottenTopicsData struct {
	Topic string

	Partitions []int32
}
type FetchRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ReplicaID int32

	MaxWaitTime int32

	MinBytes int32

	MaxBytes int32 // v3+

	IsolationLevel int8 // v4+

	SessionID int32 // v7+

	SessionEpoch int32 // v7+

	Topics []FetchRequestTopic

	ForgottenTopicsData []FetchRequestForgottenTopicsData
}

func (*FetchRequest) Key() int16                 { return 1 }
func (*FetchRequest) MaxVersion() int16          { return 10 }
func (*FetchRequest) MinVersion() int16          { return 0 }
func (v *FetchRequest) SetVersion(version int16) { v.Version = version }
func (v *FetchRequest) GetVersion() int16        { return v.Version }
func (v *FetchRequest) ResponseKind() Response   { return &FetchResponse{Version: v.Version} }

func (v *FetchRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ReplicaID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MaxWaitTime
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.MinBytes
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 3 {
		v := v.MaxBytes
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 4 {
		v := v.IsolationLevel
		dst = kbin.AppendInt8(dst, v)
	}
	if version >= 7 {
		v := v.SessionID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 7 {
		v := v.SessionEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					if version >= 9 {
						v := v.CurrentLeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.FetchOffset
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 5 {
						v := v.LogStartOffset
						dst = kbin.AppendInt64(dst, v)
					}
					{
						v := v.PartitionMaxBytes
						dst = kbin.AppendInt32(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.ForgottenTopicsData
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type FetchResponseResponsePartitionResponsePartitionHeaderAbortedTransaction struct {
	ProducerID int64

	FirstOffset int64
}
type FetchResponseResponsePartitionResponsePartitionHeader struct {
	Partition int32

	ErrorCode int16

	HighWatermark int64

	LastStableOffset int64 // v4+

	LogStartOffset int64 // v5+

	AbortedTransactions []FetchResponseResponsePartitionResponsePartitionHeaderAbortedTransaction // v4+
}
type FetchResponseResponsePartitionResponse struct {
	PartitionHeader FetchResponseResponsePartitionResponsePartitionHeader

	RecordSet []Record
}
type FetchResponseResponse struct {
	Topic string

	PartitionResponses []FetchResponseResponsePartitionResponse
}
type FetchResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32 // v1+

	ErrorCode int16 // v7+

	SessionID int32 // v7+

	Responses []FetchResponseResponse
}

func (v *FetchResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		if version >= 7 {
			v := b.Int16()
			s.ErrorCode = v
		}
		if version >= 7 {
			v := b.Int32()
			s.SessionID = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, FetchResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, FetchResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := &s.PartitionHeader
									{
										s := v
										{
											v := b.Int32()
											s.Partition = v
										}
										{
											v := b.Int16()
											s.ErrorCode = v
										}
										{
											v := b.Int64()
											s.HighWatermark = v
										}
										if version >= 4 {
											v := b.Int64()
											s.LastStableOffset = v
										}
										if version >= 5 {
											v := b.Int64()
											s.LogStartOffset = v
										}
										if version >= 4 {
											v := s.AbortedTransactions
											a := v
											for i := b.ArrayLen(); i > 0; i-- {
												a = append(a, FetchResponseResponsePartitionResponsePartitionHeaderAbortedTransaction{})
												v := &a[len(a)-1]
												{
													s := v
													{
														v := b.Int64()
														s.ProducerID = v
													}
													{
														v := b.Int64()
														s.FirstOffset = v
													}
												}
											}
											v = a
											s.AbortedTransactions = v
										}
									}
								}
								{
									v := s.RecordSet
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, Record{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.Varint()
												s.Length = v
											}
											{
												v := b.Int8()
												s.Attributes = v
											}
											{
												v := b.Varint()
												s.TimestampDelta = v
											}
											{
												v := b.Varint()
												s.OffsetDelta = v
											}
											{
												v := b.VarintBytes()
												s.Key = v
											}
											{
												v := b.VarintBytes()
												s.Value = v
											}
											{
												v := s.Headers
												a := v
												for i := b.Varint(); i > 0; i-- {
													a = append(a, Header{})
													v := &a[len(a)-1]
													{
														s := v
														{
															v := b.VarintString()
															s.Key = v
														}
														{
															v := b.VarintBytes()
															s.Value = v
														}
													}
												}
												v = a
												s.Headers = v
											}
										}
									}
									v = a
									s.RecordSet = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

type ListOffsetsRequestTopicPartition struct {
	// Partition is a partition of a topic to get offsets for.
	Partition int32

	// CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
	// allows brokers to check if the client is fenced (has an out of date
	// leader) or is using an unknown leader.
	CurrentLeaderEpoch int32 // v4+

	// Timestamp controls which offset to return in a response for this
	// partition.
	//
	// The offset returned will be the one of the message whose timestamp is
	// the first timestamp greater than or equal to this requested timestamp.
	//
	// If no such message is found, the log end offset is returned.
	//
	// There exist two special timestamps: -2 corresponds to the earliest
	// timestamp, and -1 corresponds to the latest.
	Timestamp int64
}
type ListOffsetsRequestTopic struct {
	// Topic is a topic to get offsets for.
	Topic string

	// Partitions is an array of partitions in a topic to get offsets for.
	Partitions []ListOffsetsRequestTopicPartition
}
type ListOffsetsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ReplicaID is the broker ID to get offsets from. As a Kafka client, use -1.
	// The consumer replica ID (-1) causes requests to only succeed if issued
	// against the leader broker.
	ReplicaID int32

	// IsolationLevel configures which record offsets are visible in the
	// response. READ_UNCOMMITTED (0) makes all records visible. READ_COMMITTED
	// (1) makes non-transactional and committed transactional records visible.
	// READ_COMMITTED means all offsets smaller than the last stable offset and
	// includes aborted transactions (allowing consumers to discard aborted
	// records).
	IsolationLevel int8 // v2+

	// Topics is an array of topics to get offsets for.
	Topics []ListOffsetsRequestTopic
}

func (*ListOffsetsRequest) Key() int16                 { return 2 }
func (*ListOffsetsRequest) MaxVersion() int16          { return 4 }
func (*ListOffsetsRequest) MinVersion() int16          { return 1 }
func (v *ListOffsetsRequest) SetVersion(version int16) { v.Version = version }
func (v *ListOffsetsRequest) GetVersion() int16        { return v.Version }
func (v *ListOffsetsRequest) IsAdminRequest() bool     { return true }
func (v *ListOffsetsRequest) ResponseKind() Response   { return &ListOffsetsResponse{Version: v.Version} }

func (v *ListOffsetsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ReplicaID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 2 {
		v := v.IsolationLevel
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					if version >= 4 {
						v := v.CurrentLeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Timestamp
						dst = kbin.AppendInt64(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type ListOffsetsResponseResponsePartitionResponse struct {
	// Partition is the partition this array slot is for.
	Partition int32

	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the topic.
	//
	// INVALID_REQUEST is returned if the requested topic partitions had
	// contained duplicates.
	//
	// KAFKA_STORAGE_EXCEPTION is returned if the topic / partition is in
	// an offline log directory.
	//
	// UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if the broker is using
	// Kafka 0.10.0 messages and the requested timestamp was not -1 nor -2.
	//
	// NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
	// for this partition. This means that the client has stale metadata.
	// If the request used the debug replica ID, the returned error will
	// be REPLICA_NOT_AVAILABLE.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know
	// of the requested topic or partition.
	//
	// FENCED_LEADER_EPOCH is returned if the broker has a higher leader
	// epoch than what the request sent.
	//
	// UNKNOWN_LEADER_EPOCH is returned if the request used a leader epoch
	// that the broker does not know about.
	//
	// OFFSET_NOT_AVAILABLE, introduced in Kafka 2.2.0 with produce request
	// v5+, is returned when talking to a broker that is a new leader while
	// that broker's high water mark catches up. This avoids situations where
	// the old broker returned higher offsets than the new broker would. Note
	// that if unclean leader election is allowed, you could still run into
	// the situation where offsets returned from list offsets requests are
	// not monotonically increasing. This error is only returned if the
	// request used the consumer replica ID (-1). If the client did not use
	// a v5+ list offsets request, LEADER_NOT_AVAILABLE is returned.
	// See KIP-207 for more details.
	ErrorCode int16

	// If the request was for the earliest or latest timestamp (-2 or -1), or
	// if an offset could not be found after the requested one, this will be -1.
	Timestamp int64

	// Offset is the offset corresponding to the record on or after the
	// requested timestamp. If one could not be found, this will be -1.
	Offset int64 // v1+

	// LeaderEpoch is the leader epoch of the record at this offset,
	// or -1 if there was no leader epoch.
	LeaderEpoch int32 // v4+
}
type ListOffsetsResponseResponse struct {
	// Topic is the topic this array slot is for.
	Topic string

	// PartitionResponses is an array of partition responses corresponding to
	// the requested partitions for a topic.
	PartitionResponses []ListOffsetsResponseResponsePartitionResponse
}

// ListOffsetsResponse is returned from a ListOffsetsRequest.
type ListOffsetsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v2+

	// Responses is an array of topic / partition responses corresponding to
	// the requested topics and partitions.
	Responses []ListOffsetsResponseResponse
}

func (v *ListOffsetsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 2 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ListOffsetsResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, ListOffsetsResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int64()
									s.Timestamp = v
								}
								if version >= 1 {
									v := b.Int64()
									s.Offset = v
								}
								if version >= 4 {
									v := b.Int32()
									s.LeaderEpoch = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

// MetadataRequest requests metadata from Kafka.
type MetadataRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is a list of topics to return metadata about. If this is null,
	// all topics are included. If this is empty, no topics are.
	// For v0 (<Kafka 0.10.0.0), if this is empty, all topics are included.
	Topics []string

	// AllowAutoTopicCreation, introduced in Kafka 0.11.0.0, allows topic
	// auto creation of the topics in this request if they do not exist.
	AllowAutoTopicCreation bool // v4+

	// IncludeClusterAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
	// whether to return a bitfield of AclOperations that this client can perform
	// on the cluster.
	IncludeClusterAuthorizedOperations bool // v8+

	// IncludeTopicAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
	// whether to return a bitfield of AclOperations that this client can perform
	// on individual topics.
	IncludeTopicAuthorizedOperations bool // v8+
}

func (*MetadataRequest) Key() int16                 { return 3 }
func (*MetadataRequest) MaxVersion() int16          { return 8 }
func (*MetadataRequest) MinVersion() int16          { return 0 }
func (v *MetadataRequest) SetVersion(version int16) { v.Version = version }
func (v *MetadataRequest) GetVersion() int16        { return v.Version }
func (v *MetadataRequest) ResponseKind() Response   { return &MetadataResponse{Version: v.Version} }

func (v *MetadataRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	if version >= 4 {
		v := v.AllowAutoTopicCreation
		dst = kbin.AppendBool(dst, v)
	}
	if version >= 8 {
		v := v.IncludeClusterAuthorizedOperations
		dst = kbin.AppendBool(dst, v)
	}
	if version >= 8 {
		v := v.IncludeTopicAuthorizedOperations
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type MetadataResponseBroker struct {
	// NodeID is the node ID of a Kafka broker.
	NodeID int32

	// Host is the hostname of a Kafka broker.
	Host string

	// Port is the port of a Kafka broker.
	Port int32

	// Rack is the rack this Kafka broker is in.
	Rack *string // v1+
}
type MetadataResponseTopicMetadataPartitionMetadata struct {
	// ErrorCode is any error for a partition in topic metadata.
	//
	// LEADER_NOT_AVAILABLE is returned if a leader is unavailable for this
	// partition. For v0 metadata responses, this is also returned if a
	// partition leader's listener does not exist.
	//
	// LISTENER_NOT_FOUND is returned if a leader ID is known but the
	// listener for it is not (v1+).
	//
	// REPLICA_NOT_AVAILABLE is returned in v0 responses if any replica is
	// unavailable.
	ErrorCode int16

	// Partition is a partition number for a topic.
	Partition int32

	// Leader is the broker leader for this partition. This will be -1
	// on leader / listener error.
	Leader int32

	// LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0  is the
	// epoch of the broker leader.
	LeaderEpoch int32 // v7+

	// Replicas returns all broker IDs containing replicas of this partition.
	Replicas []int32

	// ISR returns all broker IDs of in-sync replicas of this partition.
	ISR []int32

	// OfflineReplicas, proposed in KIP-112 and introduced in Kafka 1.0,
	// returns all offline broker IDs that should be replicating this partition.
	OfflineReplicas []int32 // v5+
}
type MetadataResponseTopicMetadata struct {
	// ErrorCode is any error for a topic in a metadata request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the topic, or if the metadata request specified topic auto
	// creation, the topic did not exist, and the user lacks permission to create.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if a topic does not exist and
	// the request did not specify autocreation.
	//
	// LEADER_NOT_AVAILABLE is returned if a new topic is created successfully
	// (since there is no leader on an immediately new topic).
	//
	// There can be a myriad of other errors for unsuccessful topic creation.
	ErrorCode int16

	// Topic is the topic this metadata corresponds to.
	Topic string

	// IsInternal signifies whether this topic is a Kafka internal topic.
	IsInternal bool // v1+

	// PartitionMetadata contains metadata about partitions for a topic.
	PartitionMetadata []MetadataResponseTopicMetadataPartitionMetadata

	// AuthorizedOperations, proposed in KIP-430 and introduced in Kafka 2.3.0,
	// returns a bitfield (corresponding to AclOperation) containing which
	// operations the client is allowed to perform on this topic.
	// This is only returned if requested.
	AuthorizedOperations int32 // v8+
}

// MetadataResponse is returned from a MetdataRequest.
type MetadataResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v3+

	// Brokers is a set of alive Kafka brokers.
	Brokers []MetadataResponseBroker

	// ClusterID, proposed in KIP-78 and introduced in Kafka 0.10.1.0, is a
	// unique string specifying the cluster that the replying Kafka belongs to.
	ClusterID *string // v2+

	// ControllerID is the ID of the controller broker (the admin broker).
	ControllerID int32 // v1+

	// TopicMetadata contains metadata about each topic requested in the
	// MetadataRequest.
	TopicMetadata []MetadataResponseTopicMetadata

	// AuthorizedOperations returns a bitfield containing which operations the
	// client is allowed to perform on this cluster.
	AuthorizedOperations int32 // v8+
}

func (v *MetadataResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 3 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Brokers
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, MetadataResponseBroker{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int32()
						s.NodeID = v
					}
					{
						v := b.String()
						s.Host = v
					}
					{
						v := b.Int32()
						s.Port = v
					}
					if version >= 1 {
						v := b.NullableString()
						s.Rack = v
					}
				}
			}
			v = a
			s.Brokers = v
		}
		if version >= 2 {
			v := b.NullableString()
			s.ClusterID = v
		}
		if version >= 1 {
			v := b.Int32()
			s.ControllerID = v
		}
		{
			v := s.TopicMetadata
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, MetadataResponseTopicMetadata{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.Topic = v
					}
					if version >= 1 {
						v := b.Bool()
						s.IsInternal = v
					}
					{
						v := s.PartitionMetadata
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, MetadataResponseTopicMetadataPartitionMetadata{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int16()
									s.ErrorCode = v
								}
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int32()
									s.Leader = v
								}
								if version >= 7 {
									v := b.Int32()
									s.LeaderEpoch = v
								}
								{
									v := s.Replicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.Replicas = v
								}
								{
									v := s.ISR
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.ISR = v
								}
								if version >= 5 {
									v := s.OfflineReplicas
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										v := b.Int32()
										a = append(a, v)
									}
									v = a
									s.OfflineReplicas = v
								}
							}
						}
						v = a
						s.PartitionMetadata = v
					}
					if version >= 8 {
						v := b.Int32()
						s.AuthorizedOperations = v
					}
				}
			}
			v = a
			s.TopicMetadata = v
		}
		if version >= 8 {
			v := b.Int32()
			s.AuthorizedOperations = v
		}
	}
	return b.Complete()
}

type LeaderAndISRRequestPartitionState struct {
	Topic string

	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	IsNew bool
}
type LeaderAndISRRequestLiveLeader struct {
	ID int32

	Host string

	Port int32
}
type LeaderAndISRRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	PartitionStates []LeaderAndISRRequestPartitionState

	LiveLeaders []LeaderAndISRRequestLiveLeader
}

func (*LeaderAndISRRequest) Key() int16                 { return 4 }
func (*LeaderAndISRRequest) MaxVersion() int16          { return 1 }
func (*LeaderAndISRRequest) MinVersion() int16          { return 0 }
func (v *LeaderAndISRRequest) SetVersion(version int16) { v.Version = version }
func (v *LeaderAndISRRequest) GetVersion() int16        { return v.Version }
func (v *LeaderAndISRRequest) IsAdminRequest() bool     { return true }
func (v *LeaderAndISRRequest) ResponseKind() Response {
	return &LeaderAndISRResponse{Version: v.Version}
}

func (v *LeaderAndISRRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.PartitionStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ControllerEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Leader
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.LeaderEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ISR
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.ZKVersion
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Replicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.IsNew
				dst = kbin.AppendBool(dst, v)
			}
		}
	}
	{
		v := v.LiveLeaders
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ID
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Host
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Port
				dst = kbin.AppendInt32(dst, v)
			}
		}
	}
	return dst
}

type LeaderAndISRResponsePartition struct {
	Topic string

	Partition int32

	ErrorCode int16
}
type LeaderAndISRResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	Partitions []LeaderAndISRResponsePartition
}

func (v *LeaderAndISRResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.Partitions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, LeaderAndISRResponsePartition{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.Partitions = v
		}
	}
	return b.Complete()
}

type StopReplicaRequestPartition struct {
	Topic string

	Partition int32
}
type StopReplicaRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	DeletePartitions bool

	Partitions []StopReplicaRequestPartition
}

func (*StopReplicaRequest) Key() int16                 { return 5 }
func (*StopReplicaRequest) MaxVersion() int16          { return 0 }
func (*StopReplicaRequest) MinVersion() int16          { return 0 }
func (v *StopReplicaRequest) SetVersion(version int16) { v.Version = version }
func (v *StopReplicaRequest) GetVersion() int16        { return v.Version }
func (v *StopReplicaRequest) IsAdminRequest() bool     { return true }
func (v *StopReplicaRequest) ResponseKind() Response   { return &StopReplicaResponse{Version: v.Version} }

func (v *StopReplicaRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.DeletePartitions
		dst = kbin.AppendBool(dst, v)
	}
	{
		v := v.Partitions
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
		}
	}
	return dst
}

type StopReplicaResponsePartition struct {
	Topic string

	Partition int32

	ErrorCode int16
}
type StopReplicaResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	Partitions []StopReplicaResponsePartition
}

func (v *StopReplicaResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.Partitions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, StopReplicaResponsePartition{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.Partitions = v
		}
	}
	return b.Complete()
}

type UpdateMetadataRequestPartitionState struct {
	Topic string

	Partition int32

	ControllerEpoch int32

	Leader int32

	LeaderEpoch int32

	ISR []int32

	ZKVersion int32

	Replicas []int32

	OfflineReplicas []int32
}
type UpdateMetadataRequestLiveBrokerEndpoint struct {
	Port int32

	Host string

	ListenerName string // v3+

	SecurityProtocolType int16
}
type UpdateMetadataRequestLiveBroker struct {
	ID int32

	Endpoints []UpdateMetadataRequestLiveBrokerEndpoint // v1+

	Rack *string // v2+
}

// V1 switched LiveBrokers struct type
type UpdateMetadataRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ControllerID int32

	ControllerEpoch int32

	PartitionStates []UpdateMetadataRequestPartitionState

	LiveBrokers []UpdateMetadataRequestLiveBroker
}

func (*UpdateMetadataRequest) Key() int16                 { return 6 }
func (*UpdateMetadataRequest) MaxVersion() int16          { return 4 }
func (*UpdateMetadataRequest) MinVersion() int16          { return 1 }
func (v *UpdateMetadataRequest) SetVersion(version int16) { v.Version = version }
func (v *UpdateMetadataRequest) GetVersion() int16        { return v.Version }
func (v *UpdateMetadataRequest) IsAdminRequest() bool     { return true }
func (v *UpdateMetadataRequest) ResponseKind() Response {
	return &UpdateMetadataResponse{Version: v.Version}
}

func (v *UpdateMetadataRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ControllerID
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ControllerEpoch
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.PartitionStates
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partition
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ControllerEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Leader
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.LeaderEpoch
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ISR
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.ZKVersion
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.Replicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
			{
				v := v.OfflineReplicas
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	{
		v := v.LiveBrokers
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ID
				dst = kbin.AppendInt32(dst, v)
			}
			if version >= 1 {
				v := v.Endpoints
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Port
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Host
						dst = kbin.AppendString(dst, v)
					}
					if version >= 3 {
						v := v.ListenerName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.SecurityProtocolType
						dst = kbin.AppendInt16(dst, v)
					}
				}
			}
			if version >= 2 {
				v := v.Rack
				dst = kbin.AppendNullableString(dst, v)
			}
		}
	}
	return dst
}

type UpdateMetadataResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16
}

func (v *UpdateMetadataResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
	}
	return b.Complete()
}

type ControlledShutdownRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	BrokerID int32
}

func (*ControlledShutdownRequest) Key() int16                 { return 7 }
func (*ControlledShutdownRequest) MaxVersion() int16          { return 1 }
func (*ControlledShutdownRequest) MinVersion() int16          { return 0 }
func (v *ControlledShutdownRequest) SetVersion(version int16) { v.Version = version }
func (v *ControlledShutdownRequest) GetVersion() int16        { return v.Version }
func (v *ControlledShutdownRequest) IsAdminRequest() bool     { return true }
func (v *ControlledShutdownRequest) ResponseKind() Response {
	return &ControlledShutdownResponse{Version: v.Version}
}

func (v *ControlledShutdownRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.BrokerID
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type ControlledShutdownResponsePartitionsRemaining struct {
	Topic string

	Partition int32
}
type ControlledShutdownResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ErrorCode int16

	PartitionsRemaining []ControlledShutdownResponsePartitionsRemaining
}

func (v *ControlledShutdownResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.PartitionsRemaining
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ControlledShutdownResponsePartitionsRemaining{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int32()
						s.Partition = v
					}
				}
			}
			v = a
			s.PartitionsRemaining = v
		}
	}
	return b.Complete()
}

type OffsetCommitRequestTopicPartition struct {
	Partition int32

	Offset int64

	Timestamp int64 // v1+

	LeaderEpoch int32 // v6+

	Metadata *string
}
type OffsetCommitRequestTopic struct {
	Topic string

	Partitions []OffsetCommitRequestTopicPartition
}
type OffsetCommitRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	GroupID string

	GenerationID int32 // v1+

	MemberID string // v1+

	RetentionTime int64 // v2+

	Topics []OffsetCommitRequestTopic
}

func (*OffsetCommitRequest) Key() int16                 { return 8 }
func (*OffsetCommitRequest) MaxVersion() int16          { return 6 }
func (*OffsetCommitRequest) MinVersion() int16          { return 0 }
func (v *OffsetCommitRequest) SetVersion(version int16) { v.Version = version }
func (v *OffsetCommitRequest) GetVersion() int16        { return v.Version }
func (v *OffsetCommitRequest) ResponseKind() Response {
	return &OffsetCommitResponse{Version: v.Version}
}

func (v *OffsetCommitRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 1 {
		v := v.GenerationID
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.MemberID
		dst = kbin.AppendString(dst, v)
	}
	if version >= 2 && version <= 4 {
		v := v.RetentionTime
		dst = kbin.AppendInt64(dst, v)
	}
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Offset
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 1 && version <= 1 {
						v := v.Timestamp
						dst = kbin.AppendInt64(dst, v)
					}
					if version >= 6 {
						v := v.LeaderEpoch
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Metadata
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	return dst
}

type OffsetCommitResponseResponsePartitionResponse struct {
	Partition int32

	ErrorCode int16
}
type OffsetCommitResponseResponse struct {
	Topic string

	PartitionResponses []OffsetCommitResponseResponsePartitionResponse
}
type OffsetCommitResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32 // v3+

	Responses []OffsetCommitResponseResponse
}

func (v *OffsetCommitResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 3 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Responses
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, OffsetCommitResponseResponse{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := s.PartitionResponses
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, OffsetCommitResponseResponsePartitionResponse{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.Int32()
									s.Partition = v
								}
								{
									v := b.Int16()
									s.ErrorCode = v
								}
							}
						}
						v = a
						s.PartitionResponses = v
					}
				}
			}
			v = a
			s.Responses = v
		}
	}
	return b.Complete()
}

// DescribeGroupsRequest requests metadata for group IDs.
type DescribeGroupsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// GroupIDs is an array of group IDs to request metadata for.
	// If this is empty, the response will include all groups.
	GroupIDs []string
}

func (*DescribeGroupsRequest) Key() int16                 { return 15 }
func (*DescribeGroupsRequest) MaxVersion() int16          { return 2 }
func (*DescribeGroupsRequest) MinVersion() int16          { return 0 }
func (v *DescribeGroupsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeGroupsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeGroupsRequest) IsAdminRequest() bool     { return true }
func (v *DescribeGroupsRequest) ResponseKind() Response {
	return &DescribeGroupsResponse{Version: v.Version}
}

func (v *DescribeGroupsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.GroupIDs
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	return dst
}

type DescribeGroupsResponseGroupMember struct {
	MemberID string

	ClientID string

	ClientHost string

	MemberMetadata []byte

	MemberAssignment []byte
}
type DescribeGroupsResponseGroup struct {
	// ErrorCode is the error code for an individual group in a request.
	//
	// GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe a group.
	//
	// INVALID_GROUP_ID is returned if the requested group ID is invalid.
	//
	// COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
	// group is not yet active.
	//
	// COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
	//
	// NOT_COORDINATOR is returned if the requested broker is not the
	// coordinator for this group.
	ErrorCode int16

	// GroupID is the id of this group.
	GroupID string

	State string

	ProtocolType string

	Protocol string

	Members []DescribeGroupsResponseGroupMember
}

// DescribeGroupsResponse is returned from a DescribeGroupsRequest.
type DescribeGroupsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Groups is an array of group metadata.
	Groups []DescribeGroupsResponseGroup
}

func (v *DescribeGroupsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Groups
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeGroupsResponseGroup{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.GroupID = v
					}
					{
						v := b.String()
						s.State = v
					}
					{
						v := b.String()
						s.ProtocolType = v
					}
					{
						v := b.String()
						s.Protocol = v
					}
					{
						v := s.Members
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeGroupsResponseGroupMember{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.MemberID = v
								}
								{
									v := b.String()
									s.ClientID = v
								}
								{
									v := b.String()
									s.ClientHost = v
								}
								{
									v := b.Bytes()
									s.MemberMetadata = v
								}
								{
									v := b.Bytes()
									s.MemberAssignment = v
								}
							}
						}
						v = a
						s.Members = v
					}
				}
			}
			v = a
			s.Groups = v
		}
	}
	return b.Complete()
}

// ApiVersionsRequest requests what API versions a Kafka broker supports.
//
// Because a client does not know what version of ApiVersionsRequest a broker
// supports, Kafka responds to versions with the highest version it supports.
// This allows clients to always use the latest version of ApiVersionsRequest.
// If the broker supports only a lower version of the request, it will reply
// with an UNSUPPORTED_VERSION error.
type ApiVersionsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16
}

func (*ApiVersionsRequest) Key() int16                 { return 18 }
func (*ApiVersionsRequest) MaxVersion() int16          { return 2 }
func (*ApiVersionsRequest) MinVersion() int16          { return 0 }
func (v *ApiVersionsRequest) SetVersion(version int16) { v.Version = version }
func (v *ApiVersionsRequest) GetVersion() int16        { return v.Version }
func (v *ApiVersionsRequest) ResponseKind() Response   { return &ApiVersionsResponse{Version: v.Version} }

func (v *ApiVersionsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	return dst
}

type ApiVersionsResponseApiVersion struct {
	// ApiKey is the key of a message request.
	ApiKey int16

	// MinVersion is the min version a broker supports for an API key.
	MinVersion int16

	// MaxVersion is the max version a broker supports for an API key.
	MaxVersion int16
}

// ApiVersionsResponse is returned from an ApiVersionsRequest.
type ApiVersionsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ErrorCode is UNSUPPORTED_VERSION if the request was issued with a higher
	// version than the broker supports. Regardless of the error, the broker
	// replies with the ApiVersions it supports.
	ErrorCode int16

	// ApiVersions is an array corresponding to API keys the broker supports
	// and the range of supported versions for each key.
	ApiVersions []ApiVersionsResponseApiVersion

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+
}

func (v *ApiVersionsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := s.ApiVersions
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, ApiVersionsResponseApiVersion{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ApiKey = v
					}
					{
						v := b.Int16()
						s.MinVersion = v
					}
					{
						v := b.Int16()
						s.MaxVersion = v
					}
				}
			}
			v = a
			s.ApiVersions = v
		}
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
	}
	return b.Complete()
}

type CreateTopicsRequestTopicReplicaAssignment struct {
	// Partition is a partition to create.
	Partition int32

	// Replicas are broker IDs the partition must exist on.
	Replicas []int32
}
type CreateTopicsRequestTopicConfigEntry struct {
	// ConfigName is a topic level config key (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is a topic level config value (e.g. 1073741824)
	ConfigValue *string
}
type CreateTopicsRequestTopic struct {
	// Topic is a topic to create.
	Topic string

	// NumPartitions is how many partitions to give a topic.
	NumPartitions int32

	// ReplicationFactor is how many replicas every partition must have.
	ReplicationFactor int16

	// ReplicaAssignment is an array to manually dicate replicas and their
	// partitions for a topic. If using this, both ReplicationFactor and
	// NumPartitions must be -1.
	ReplicaAssignment []CreateTopicsRequestTopicReplicaAssignment

	// ConfigEntries is an array of key value config pairs for a topic.
	// These correspond to Kafka Topic-Level Configs: http://kafka.apache.org/documentation/#topicconfigs.
	ConfigEntries []CreateTopicsRequestTopicConfigEntry
}

// CreateTopicsRequest creates Kafka topics.
type CreateTopicsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to attempt to create.
	Topics []CreateTopicsRequestTopic

	// Timeout is how long to allow for this request.
	Timeout int32

	// ValidateOnly is makes this request a dry-run; everything is validated but
	// no topics are actually created.
	ValidateOnly bool // v1+
}

func (*CreateTopicsRequest) Key() int16                 { return 19 }
func (*CreateTopicsRequest) MaxVersion() int16          { return 3 }
func (*CreateTopicsRequest) MinVersion() int16          { return 0 }
func (v *CreateTopicsRequest) SetVersion(version int16) { v.Version = version }
func (v *CreateTopicsRequest) GetVersion() int16        { return v.Version }
func (v *CreateTopicsRequest) IsAdminRequest() bool     { return true }
func (v *CreateTopicsRequest) ResponseKind() Response {
	return &CreateTopicsResponse{Version: v.Version}
}

func (v *CreateTopicsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.NumPartitions
				dst = kbin.AppendInt32(dst, v)
			}
			{
				v := v.ReplicationFactor
				dst = kbin.AppendInt16(dst, v)
			}
			{
				v := v.ReplicaAssignment
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Partition
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Replicas
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
			{
				v := v.ConfigEntries
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.ConfigName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.ConfigValue
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	if version >= 1 {
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type CreateTopicsResponseTopicError struct {
	// Topic is the topic this error response corresponds to.
	Topic string

	// ErrorCode is the error code for an individual topic creation.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	//
	// INVALID_REQUEST is returned if the same topic occurred multiple times
	// in the request.
	//
	// POLICY_VIOLATION is returned if the broker is using a
	// create.topic.policy.class.name that returns a policy violation.
	//
	// INVALID_TOPIC_EXCEPTION if the topic collides with another topic when
	// both topic's names' periods are replaced with underscores (e.g.
	// topic.foo and topic_foo collide).
	//
	// TOPIC_ALREADY_EXISTS is returned if the topic already exists.
	//
	// INVALID_PARTITIONS is returned if the requested number of partitions is
	// <= 0.
	//
	// INVALID_REPLICATION_FACTOR is returned if the requested replication
	// factor is <= 0.
	//
	// INVALID_REPLICA_ASSIGNMENT is returned if not all partitions have the same
	// number of replicas, or duplica replicas are assigned, or the partitions
	// are not consecutive starting from 0.
	//
	// INVALID_CONFIG is returned if the requested topic config is invalid.
	// to create a topic.
	ErrorCode int16

	// ErrorMessage is an informative message if the topic creation failed.
	ErrorMessage *string // v1+
}

// CreateTopicsResponse is returned from a CreateTopicsRequest.
type CreateTopicsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v2+

	// TopicErrors is an the array of requested topics for creation and their
	// creation errors.
	TopicErrors []CreateTopicsResponseTopicError
}

func (v *CreateTopicsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 2 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrors
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, CreateTopicsResponseTopicError{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					if version >= 1 {
						v := b.NullableString()
						s.ErrorMessage = v
					}
				}
			}
			v = a
			s.TopicErrors = v
		}
	}
	return b.Complete()
}

// DeleteTopicsRequest deletes Kafka topics.
type DeleteTopicsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to delete.
	Topics []string

	// Timeout is the millisecond timeout of this request.
	Timeout int32
}

func (*DeleteTopicsRequest) Key() int16                 { return 20 }
func (*DeleteTopicsRequest) MaxVersion() int16          { return 3 }
func (*DeleteTopicsRequest) MinVersion() int16          { return 0 }
func (v *DeleteTopicsRequest) SetVersion(version int16) { v.Version = version }
func (v *DeleteTopicsRequest) GetVersion() int16        { return v.Version }
func (v *DeleteTopicsRequest) IsAdminRequest() bool     { return true }
func (v *DeleteTopicsRequest) ResponseKind() Response {
	return &DeleteTopicsResponse{Version: v.Version}
}

func (v *DeleteTopicsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := v[i]
			dst = kbin.AppendString(dst, v)
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type DeleteTopicsResponseTopicErrorCode struct {
	// Topic is the topic requested for deletion.
	Topic string

	// ErrorCode is the error code returned for an individual topic in
	// deletion request.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to delete a topic.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the topic.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_DELETION_DISABLED is returned for deletion requests version 3+
	// and brokers >= 2.1.0. INVALID_REQUEST is issued for request versions
	// 0-2 against brokers >= 2.1.0. Otherwise, the request hangs until it
	// times out.
	ErrorCode int16
}

// DeleteTopicsResponse is returned from a DeleteTopicsRequest.
// Version 3 added the TOPIC_DELETION_DISABLED error proposed in KIP-322
// and introduced in Kafka 2.1.0. Prior, the request timed out.
type DeleteTopicsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32 // v1+

	// TopicErrorCodes is contains the error codes for each topic requested
	// for deletion (or no error code).
	TopicErrorCodes []DeleteTopicsResponseTopicErrorCode
}

func (v *DeleteTopicsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		if version >= 1 {
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrorCodes
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DeleteTopicsResponseTopicErrorCode{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
				}
			}
			v = a
			s.TopicErrorCodes = v
		}
	}
	return b.Complete()
}

type InitProducerIDRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	TransactionalID *string

	TransactionTimeoutMs int32
}

func (*InitProducerIDRequest) Key() int16                 { return 22 }
func (*InitProducerIDRequest) MaxVersion() int16          { return 2 }
func (*InitProducerIDRequest) MinVersion() int16          { return 0 }
func (v *InitProducerIDRequest) SetVersion(version int16) { v.Version = version }
func (v *InitProducerIDRequest) GetVersion() int16        { return v.Version }
func (v *InitProducerIDRequest) ResponseKind() Response {
	return &InitProducerIDResponse{Version: v.Version}
}

func (v *InitProducerIDRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TransactionalID
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.TransactionTimeoutMs
		dst = kbin.AppendInt32(dst, v)
	}
	return dst
}

type InitProducerIDResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// CLUSTER_AUTHORIZATION_FAILED if idempotent and not authed
	//
	// transactional errors:
	// TRANSACTIONAL_ID_AUTHORIZATION_FAILED if transactional and not authed
	// INVALID_REQUEST if transactional id is an empty, non-null string
	// INVALID_TRANSACTION_TIMEOUT if timeout equal to over over transaction.max.timeout.ms or under 0
	// COORDINATOR_LOAD_IN_PROGRESS
	// NOT_COORDINATOR
	// COORDINATOR_NOT_AVAILABLE
	// CONCURRENT_TRANSACTIONS
	ErrorCode int16

	// the generated producer ID
	ProducerID int64

	// the current producer epoch
	ProducerEpoch int16
}

func (v *InitProducerIDResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.Int64()
			s.ProducerID = v
		}
		{
			v := b.Int16()
			s.ProducerEpoch = v
		}
	}
	return b.Complete()
}

// DescribeACLsRequest describes ACLs. Unfortunately, there exists little
// official documentation on this.
type DescribeACLsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ResourceType int8

	ResourceName *string

	ResourcePatternTypeFilter int8

	Principal *string

	Host *string

	Operation int8

	PermissionType int8
}

func (*DescribeACLsRequest) Key() int16                 { return 29 }
func (*DescribeACLsRequest) MaxVersion() int16          { return 1 }
func (*DescribeACLsRequest) MinVersion() int16          { return 0 }
func (v *DescribeACLsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeACLsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeACLsRequest) IsAdminRequest() bool     { return true }
func (v *DescribeACLsRequest) ResponseKind() Response {
	return &DescribeACLsResponse{Version: v.Version}
}

func (v *DescribeACLsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.ResourceType
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.ResourceName
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.ResourcePatternTypeFilter
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.Principal
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Host
		dst = kbin.AppendNullableString(dst, v)
	}
	{
		v := v.Operation
		dst = kbin.AppendInt8(dst, v)
	}
	{
		v := v.PermissionType
		dst = kbin.AppendInt8(dst, v)
	}
	return dst
}

type DescribeACLsResponseResourceACL struct {
	// Principal is who this ACL applies to.
	Principal string

	// Host is on which host this ACL applies.
	Host string

	// Operation is a type of operation this ACL applies to.
	//
	// UNKNOWN (0) is an operation that we do not understand (old client).
	//
	// ANY (1) mathches any ACL operation in a filter.
	//
	// ALL (2) (implies everything)
	//
	// READ (3) (implies DESCRIBE)
	//
	// WRITE (4) (implies DESCRIBE)
	//
	// CREATE (5)
	//
	// DELETE (6) (implies DESCRIBE)
	//
	// ALTER (7) (implies DESCRIBE)
	//
	// DESCRIBE (8)
	//
	// CLUSTER_ACTION (9)
	//
	// DESCRIBE_CONFIGS (10)
	//
	// ALTER_CONFIGS (11) (implies DESCRIBE_CONFIGS)
	//
	// IDEMPOTENT_WRITE (12)
	Operation int8

	// PermissionType is how this ACL is applied.
	//
	// UNKNOWN is a permission type we do not understand (old client).
	//
	// ANY allows anything.
	//
	// DENY disallows access.
	//
	// ALLOW allows access.
	PermissionType int8
}
type DescribeACLsResponseResource struct {
	ResourceType int8

	ResourceName string

	ResourcePatternType int8 // v1+

	ACLs []DescribeACLsResponseResourceACL
}
type DescribeACLsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	ThrottleTimeMs int32

	// ErrorCode is the error code returned on request failure.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to describe the cluster.
	//
	// SECURITY_DISABLED is returned if there is no authorizer configured on the
	// broker.
	ErrorCode int16

	ErrorMessage *string

	Resources []DescribeACLsResponseResource
}

func (v *DescribeACLsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := b.Int16()
			s.ErrorCode = v
		}
		{
			v := b.NullableString()
			s.ErrorMessage = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeACLsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
					if version >= 1 {
						v := b.Int8()
						s.ResourcePatternType = v
					}
					{
						v := s.ACLs
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeACLsResponseResourceACL{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.Principal = v
								}
								{
									v := b.String()
									s.Host = v
								}
								{
									v := b.Int8()
									s.Operation = v
								}
								{
									v := b.Int8()
									s.PermissionType = v
								}
							}
						}
						v = a
						s.ACLs = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type DescribeConfigsRequestResource struct {
	// ResourceType is an enum corresponding to the type of config to describe.
	// The only two valid values are 2 (for topic) and 4 (for broker).
	ResourceType int8

	// ResourceName is the name of config to describe.
	//
	// If the requested type is a topic, this corresponds to a topic name.
	//
	// If the requested type if a broker, this should either be empty or be
	// the ID of the broker this request is issued to. If it is empty, this
	// returns all broker configs, but only the dynamic configuration values.
	// If a specific ID, this returns all broker config values.
	ResourceName string

	// ConfigNames is a list of config entries to return. Null requests all.
	ConfigNames []string
}

// DescribeConfigsRequest issues a request to describe configs that Kafka
// currently has. These are the key/value pairs that one uses to configure
// brokers and topics.
type DescribeConfigsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Resources is a list of resources to describe.
	Resources []DescribeConfigsRequestResource

	// IncludeSynonyms signifies whether to return config entry synonyms for
	// all config entries.
	IncludeSynonyms bool // v1+
}

func (*DescribeConfigsRequest) Key() int16                 { return 32 }
func (*DescribeConfigsRequest) MaxVersion() int16          { return 2 }
func (*DescribeConfigsRequest) MinVersion() int16          { return 0 }
func (v *DescribeConfigsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeConfigsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeConfigsRequest) IsAdminRequest() bool     { return true }
func (v *DescribeConfigsRequest) ResponseKind() Response {
	return &DescribeConfigsResponse{Version: v.Version}
}

func (v *DescribeConfigsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Resources
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ConfigNames
				dst = kbin.AppendNullableArrayLen(dst, len(v), v == nil)
				for i := range v {
					v := v[i]
					dst = kbin.AppendString(dst, v)
				}
			}
		}
	}
	if version >= 1 {
		v := v.IncludeSynonyms
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type DescribeConfigsResponseResourceConfigEntryConfigSynonym struct {
	ConfigName string

	ConfigValue *string

	ConfigSource int8
}
type DescribeConfigsResponseResourceConfigEntry struct {
	// ConfigName is a key this entry corresponds to (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is the value for this config key. If the key is sensitive,
	// the value will be null.
	ConfigValue *string

	// ReadOnly signifies whether this is not a dynamic config option.
	ReadOnly bool

	// IsDefault is whether this is a default config option. This has been
	// replaced in favor of ConfigSource.
	IsDefault bool

	// ConfigSource is where this config entry is from. Note that if there
	// are no config synonyms, the source is DEFAULT_CONFIG. The values of
	// this enum are as follows.
	//
	// UNKNOWN (0): unknown; e.g. an altar request was issued with no source set
	//
	// DYNAMIC_TOPIC_CONFIG (1): dynamic topic config for a specific topic
	//
	// DYNAMIC_BROKER_CONFIG (2): dynamic broker config for a specific broker
	//
	// DYNAMIC_DEFAULT_BROKER_CONFIG (3): dynamic broker config used as the default for all brokers in a cluster
	//
	// STATIC_BROKER_CONFIG (4): static broker config provided at start up
	//
	// DEFAULT_CONFIG (5): built-in default configuration for those that have defaults
	ConfigSource int8 // v1+

	// IsSensitive signifies whether this is a sensitive config key, which
	// is either a password or an unknown type.
	IsSensitive bool

	// ConfigSynonyms contains config key/value pairs that can be used in
	// place of this config entry, in order of preference.
	ConfigSynonyms []DescribeConfigsResponseResourceConfigEntryConfigSynonym // v1+
}
type DescribeConfigsResponseResource struct {
	// ErrorCode is the error code returned for describing configs.
	//
	// INVALID_REQUEST is returned if asking to descibe an invalid resource
	// type.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if asking to describe broker
	// configs but the client is not authorized to do so.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if asking to describe topic
	// configs but the client is not authorized to do so.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic.
	ErrorCode int16

	// ErrorMessage is an informative message if the describe config failed.
	ErrorMessage *string

	// ResourceType is the enum corresponding to the type of described config.
	ResourceType int8

	// ResourceName is the name corresponding to the describe config request.
	ResourceName string

	// ConfigEntries contains information about key/value config pairs for
	// the requested resource.
	ConfigEntries []DescribeConfigsResponseResourceConfigEntry
}

// DescribeConfigsResponse is returned from a DescribeConfigsRequest.
type DescribeConfigsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Resources are responses for each resource in the describe config request.
	Resources []DescribeConfigsResponseResource
}

func (v *DescribeConfigsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeConfigsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
					{
						v := s.ConfigEntries
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeConfigsResponseResourceConfigEntry{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.ConfigName = v
								}
								{
									v := b.NullableString()
									s.ConfigValue = v
								}
								{
									v := b.Bool()
									s.ReadOnly = v
								}
								if version >= 0 && version <= 0 {
									v := b.Bool()
									s.IsDefault = v
								}
								if version >= 1 {
									v := b.Int8()
									s.ConfigSource = v
								}
								{
									v := b.Bool()
									s.IsSensitive = v
								}
								if version >= 1 {
									v := s.ConfigSynonyms
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, DescribeConfigsResponseResourceConfigEntryConfigSynonym{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.String()
												s.ConfigName = v
											}
											{
												v := b.NullableString()
												s.ConfigValue = v
											}
											{
												v := b.Int8()
												s.ConfigSource = v
											}
										}
									}
									v = a
									s.ConfigSynonyms = v
								}
							}
						}
						v = a
						s.ConfigEntries = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type AlterConfigsRequestResourceConfigEntry struct {
	// ConfigName is a key to set (e.g. segment.bytes).
	ConfigName string

	// ConfigValue is a value to set for the key (e.g. 10).
	ConfigValue *string
}
type AlterConfigsRequestResource struct {
	// ResourceType is an enum corresponding to the type of config to alter.
	// The only two valid values are 2 (for topic) and 4 (for broker).
	ResourceType int8

	// ResourceName is the name of config to alter.
	//
	// If the requested type is a topic, this corresponds to a topic name.
	//
	// If the requested type if a broker, this should either be empty or be
	// the ID of the broker this request is issued to. If it is empty, this
	// updates all broker configs. If a specific ID, this updates just the
	// broker. Using a specific ID also ensures that brokers reload config
	// or secret files even if the file path has not changed. Lastly, password
	// config options can only be defined on a per broker basis.
	ResourceName string

	// ConfigEntries contains key/value config pairs to set on the resource.
	ConfigEntries []AlterConfigsRequestResourceConfigEntry
}

// AlterConfigsRequest issues a request to alter either topic or broker
// configs.
type AlterConfigsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Resources is an array of configs to alter.
	Resources []AlterConfigsRequestResource

	// ValidateOnly validates the request but does not apply it.
	ValidateOnly bool
}

func (*AlterConfigsRequest) Key() int16                 { return 33 }
func (*AlterConfigsRequest) MaxVersion() int16          { return 1 }
func (*AlterConfigsRequest) MinVersion() int16          { return 0 }
func (v *AlterConfigsRequest) SetVersion(version int16) { v.Version = version }
func (v *AlterConfigsRequest) GetVersion() int16        { return v.Version }
func (v *AlterConfigsRequest) IsAdminRequest() bool     { return true }
func (v *AlterConfigsRequest) ResponseKind() Response {
	return &AlterConfigsResponse{Version: v.Version}
}

func (v *AlterConfigsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Resources
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.ResourceType
				dst = kbin.AppendInt8(dst, v)
			}
			{
				v := v.ResourceName
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.ConfigEntries
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.ConfigName
						dst = kbin.AppendString(dst, v)
					}
					{
						v := v.ConfigValue
						dst = kbin.AppendNullableString(dst, v)
					}
				}
			}
		}
	}
	{
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type AlterConfigsResponseResource struct {
	// ErrorCode is the error code returned for altering configs.
	//
	// CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
	// configs but the client is not authorized to do so.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
	// configs but the client is not authorized to do so.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the requested topic.
	//
	// INVALID_REQUEST is returned if the requested config is invalid or if
	// asking Kafka to describe an invalid resource.
	ErrorCode int16

	// ErrorMessage is an informative message if the alter config failed.
	ErrorMessage *string

	// ResourceType is the enum corresponding to the type of altered config.
	ResourceType int8

	// ResourceName is the name corresponding to the alter config request.
	ResourceName string
}

// AlterConfigsResponse is returned from an AlterConfigsRequest.
type AlterConfigsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// Resources are responses for each resource in the alter request.
	Resources []AlterConfigsResponseResource
}

func (v *AlterConfigsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.Resources
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, AlterConfigsResponseResource{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
					{
						v := b.Int8()
						s.ResourceType = v
					}
					{
						v := b.String()
						s.ResourceName = v
					}
				}
			}
			v = a
			s.Resources = v
		}
	}
	return b.Complete()
}

type DescribeLogDirsRequestTopic struct {
	// Topic is a topic to describe the log dir of.
	Topic string

	// Partitions contains topic partitions to describe the log dirs of.
	Partitions []int32
}

// DescribeLogDirsRequest requests directory information for topic partitions.
// This request was added in support of KIP-113.
type DescribeLogDirsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// Topics is an array of topics to describe the log dirs of. If this is
	// empty, the response includes all topics and all of their partitions.
	Topics []DescribeLogDirsRequestTopic
}

func (*DescribeLogDirsRequest) Key() int16                 { return 35 }
func (*DescribeLogDirsRequest) MaxVersion() int16          { return 1 }
func (*DescribeLogDirsRequest) MinVersion() int16          { return 0 }
func (v *DescribeLogDirsRequest) SetVersion(version int16) { v.Version = version }
func (v *DescribeLogDirsRequest) GetVersion() int16        { return v.Version }
func (v *DescribeLogDirsRequest) IsAdminRequest() bool     { return true }
func (v *DescribeLogDirsRequest) ResponseKind() Response {
	return &DescribeLogDirsResponse{Version: v.Version}
}

func (v *DescribeLogDirsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.Topics
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.Partitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := v[i]
					dst = kbin.AppendInt32(dst, v)
				}
			}
		}
	}
	return dst
}

type DescribeLogDirsResponseLogDirTopicPartition struct {
	// Partition is a partition ID.
	Partition int32

	// Size is the total size of the log sements of this partition, in bytes.
	Size int64

	// OffsetLag is how far behind the log end offset is compared to
	// the partition's high watermark (if this is the current log for
	// the partition) or compared to the current replica's log end
	// offset (if this is the future log for the patition).
	//
	// The math is,
	//
	// if IsFuture, localLogEndOffset - futurelogEndOffset.
	//
	// otherwise, max(localHighWatermark - logEndOffset, 0).
	OffsetLag int64

	// IsFuture is true if this replica was created by an
	// AlterReplicaLogDirsRequest and will replace the current log of the
	// replica in the future.
	IsFuture bool
}
type DescribeLogDirsResponseLogDirTopic struct {
	// Topic is the name of a Kafka topic.
	Topic string

	// Partitions is the set of queried partitions for a topic that are
	// within a log directory.
	Partitions []DescribeLogDirsResponseLogDirTopicPartition
}
type DescribeLogDirsResponseLogDir struct {
	// ErrorCode is the error code returned for descrbing log dirs.
	//
	// KAFKA_STORAGE_ERROR is returned if the log directoy is offline.
	ErrorCode int16

	// LogDir is the absolute path of a log directory.
	LogDir string

	// Topics is an array of topics within a log directory.
	Topics []DescribeLogDirsResponseLogDirTopic
}

// DescribeLogDirsResponse is returned from a DescribeLogDirsRequest.
type DescribeLogDirsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// LogDirs pairs log directories with the topics and partitions that are
	// stored in those directores.
	LogDirs []DescribeLogDirsResponseLogDir
}

func (v *DescribeLogDirsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.LogDirs
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, DescribeLogDirsResponseLogDir{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.String()
						s.LogDir = v
					}
					{
						v := s.Topics
						a := v
						for i := b.ArrayLen(); i > 0; i-- {
							a = append(a, DescribeLogDirsResponseLogDirTopic{})
							v := &a[len(a)-1]
							{
								s := v
								{
									v := b.String()
									s.Topic = v
								}
								{
									v := s.Partitions
									a := v
									for i := b.ArrayLen(); i > 0; i-- {
										a = append(a, DescribeLogDirsResponseLogDirTopicPartition{})
										v := &a[len(a)-1]
										{
											s := v
											{
												v := b.Int32()
												s.Partition = v
											}
											{
												v := b.Int64()
												s.Size = v
											}
											{
												v := b.Int64()
												s.OffsetLag = v
											}
											{
												v := b.Bool()
												s.IsFuture = v
											}
										}
									}
									v = a
									s.Partitions = v
								}
							}
						}
						v = a
						s.Topics = v
					}
				}
			}
			v = a
			s.LogDirs = v
		}
	}
	return b.Complete()
}

type CreatePartitionsRequestTopicPartitionNewPartition struct {
	// Count is the final count of partitions this topic must have. This
	// must be greater than the current number of partitions.
	Count int32

	// Assignment is an array containing which brokers NEW partitions
	// should be assigned to. This must be the delta of Count and the
	// number of current partitions in length.
	Assignment []int32
}
type CreatePartitionsRequestTopicPartition struct {
	// Topic is a topic for which to create additional partitions for.
	Topic string

	// NewPartitions contains the total number of partitions a topic must
	// have after this request, and the assignment of which brokers should
	// own new partitions.
	NewPartitions []CreatePartitionsRequestTopicPartitionNewPartition
}

// CreatePartitionsRequest creates additional partitions for topics.
type CreatePartitionsRequest struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// TopicPartitions paris topics with their partition creation requests.
	TopicPartitions []CreatePartitionsRequestTopicPartition

	// Timeout is how long to allow for this request.
	Timeout int32

	// ValidateOnly is makes this request a dry-run; everything is validated but
	// no partitions are actually created.
	ValidateOnly bool
}

func (*CreatePartitionsRequest) Key() int16                 { return 37 }
func (*CreatePartitionsRequest) MaxVersion() int16          { return 1 }
func (*CreatePartitionsRequest) MinVersion() int16          { return 0 }
func (v *CreatePartitionsRequest) SetVersion(version int16) { v.Version = version }
func (v *CreatePartitionsRequest) GetVersion() int16        { return v.Version }
func (v *CreatePartitionsRequest) IsAdminRequest() bool     { return true }
func (v *CreatePartitionsRequest) ResponseKind() Response {
	return &CreatePartitionsResponse{Version: v.Version}
}

func (v *CreatePartitionsRequest) AppendTo(dst []byte) []byte {
	version := v.Version
	_ = version
	{
		v := v.TopicPartitions
		dst = kbin.AppendArrayLen(dst, len(v))
		for i := range v {
			v := &v[i]
			{
				v := v.Topic
				dst = kbin.AppendString(dst, v)
			}
			{
				v := v.NewPartitions
				dst = kbin.AppendArrayLen(dst, len(v))
				for i := range v {
					v := &v[i]
					{
						v := v.Count
						dst = kbin.AppendInt32(dst, v)
					}
					{
						v := v.Assignment
						dst = kbin.AppendArrayLen(dst, len(v))
						for i := range v {
							v := v[i]
							dst = kbin.AppendInt32(dst, v)
						}
					}
				}
			}
		}
	}
	{
		v := v.Timeout
		dst = kbin.AppendInt32(dst, v)
	}
	{
		v := v.ValidateOnly
		dst = kbin.AppendBool(dst, v)
	}
	return dst
}

type CreatePartitionsResponseTopicError struct {
	// Topic is the topic that partitions were requested to be made for.
	Topic string

	// ErrorCode is the error code returned for each topic in the request.
	//
	// NOT_CONTROLLER is returned if the request was not issued to a Kafka
	// controller.
	//
	// TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
	// to create partitions for a topic.
	//
	// INVALID_REQUEST is returned for duplicate topics in the request.
	//
	// INVALID_TOPIC_EXCEPTION is returned if the topic is queued for deletion.
	//
	// REASSIGNMENT_IN_PROGRESS is returned if the request was issued while
	// partitions were being reassigned.
	//
	// UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
	// the topic for which to create partitions.
	//
	// INVALID_PARTITIONS is returned if the request would drop the total
	// count of partitions down, or if the request would not add any more
	// partitions, or if the request uses unknown brokers, or if the request
	// assigns a different number of brokers than the increase in the
	// partition count.
	ErrorCode int16

	// ErrorMessage is an informative message if the topic creation failed.
	ErrorMessage *string
}

// CreatePartitionsResponse is returned from a CreatePartitionsRequest.
type CreatePartitionsResponse struct {
	// Version is the version of this message used with a Kafka broker.
	Version int16

	// ThrottleTimeMs is how long of a throttle Kafka will apply to the client
	// after this request.
	// For Kafka < 2.0.0, the throttle is applied before issuing a response.
	// For Kafka >= 2.0.0, the throttle is applied after issuing a response.
	ThrottleTimeMs int32

	// TopicErrors is an the array of requested topics with partition creations
	// and their creation errors.
	TopicErrors []CreatePartitionsResponseTopicError
}

func (v *CreatePartitionsResponse) ReadFrom(src []byte) error {
	version := v.Version
	_ = version
	b := kbin.Reader{Src: src}
	{
		s := v
		{
			v := b.Int32()
			s.ThrottleTimeMs = v
		}
		{
			v := s.TopicErrors
			a := v
			for i := b.ArrayLen(); i > 0; i-- {
				a = append(a, CreatePartitionsResponseTopicError{})
				v := &a[len(a)-1]
				{
					s := v
					{
						v := b.String()
						s.Topic = v
					}
					{
						v := b.Int16()
						s.ErrorCode = v
					}
					{
						v := b.NullableString()
						s.ErrorMessage = v
					}
				}
			}
			v = a
			s.TopicErrors = v
		}
	}
	return b.Complete()
}

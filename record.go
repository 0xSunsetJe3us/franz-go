package kgo

import "time"

// RecordHeader contains extra information that can be sent with Records.
type RecordHeader struct {
	Key   string
	Value []byte
}

// Record is a record to write to Kafka.
type Record struct {
	// Key is an optional field that can be used for partition assignment.
	//
	// This is generally used with a hash partitioner to cause all records
	// with the same key to go to the same partition.
	Key []byte
	// Value is blob of data to write to Kafka.
	Value []byte

	// Headers are optional key/value pairs that are passed along with
	// records.
	//
	// These are purely for producers and consumers; Kafka does not look at
	// this field and only writes it to disk.
	Headers []RecordHeader

	// NOTE: if logAppendTime, timestamp is MaxTimestamp, not first + delta
	// zendesk/ruby-kafka#706

	// Timestamp is the timestamp that will be used for this record.
	//
	// Record batches are always written with "CreateTime", meaning that
	// timestamps are generated by clients rather than brokers.
	//
	// This field is always set in Produce.
	Timestamp time.Time

	// TimestampType specifies how Timestamp was determined.
	//
	// The default, 0, means that the timestamp was determined in a client
	// when the record was produced.
	//
	// The alternative is 1, which is when the Timestamp is set in Kafka.
	//
	// Records pre 0.11.0.0 did not have timestamps.
	TimestampType int8

	// Topic is the topic that a record is written to.
	//
	// This must be set for producing.
	Topic string

	// Partition is the partition that a record is written to.
	//
	// For producing, this is left unset. If acks are required, this field
	// will be filled in before the produce callback if the produce is
	// successful.
	Partition int32

	// Offset is the offset that a record is written as.
	//
	// For producing, this is left unset. If acks are required, this field
	// will be filled in before the produce callback if the produce is
	// successful.
	Offset int64
}

// MessageV0 is the message format Kafka used prior to 0.10.
//
// To produce or fetch messages, Kafka would write many messages contiguously
// as an array without specifying the array length.
MessageV0 => not top level
  // Offset is the offset of this record.
  //
  // If this is the outer message of a recursive message set (i.e. a
  // message set has been compressed and this is the outer message),
  // then the offset should be the offset of the last inner value.
  Offset: int64
  // MessageSize is the size of everything that follows in this message.
  MessageSize: int32
  // CRC is the crc of everything that follows this field (NOT using the
  // Castagnoli polynomial, as is the case in the 0.11+ RecordBatch).
  CRC: int32
  // Magic is 0.
  Magic: int8
  // Attributes describe the attributes of this message.
  //
  // Bits 0 thru 2 correspond to compression:
  //   - 00 is no compression
  //   - 01 is gzip compression
  //   - 10 is snappy compression
  //
  // The remaining bits are unused and must be 0.
  Attributes: int8
  // Key is an blob of data for a record.
  //
  // Key's are usually used for hashing the record to specific Kafka partitions.
  Key: nullable-bytes
  // Value is  a blob of data. This field is the main "message" portion of a
  // record.
  Value: nullable-bytes

// MessageV0 is the message format Kafka used prior to 0.11.
//
// To produce or fetch messages, Kafka would write many messages contiguously
// as an array without specifying the array length.
//
// To support compression, an entire message set would be compressed and used
// as the Value in another message set (thus being "recursive"). The key for
// this outer message set must be null.
MessageV1 => not top level
  // Offset is the offset of this record.
  //
  // Different from v0, if this message set is a recursive message set
  // (that is, compressed and inside another message set), the offset
  // on the inner set is relative to the offset of the outer set.
  Offset: int64
  // MessageSize is the size of everything that follows in this message.
  MessageSize: int32
  // CRC is the crc of everything that follows this field (NOT using the
  // Castagnoli polynomial, as is the case in the 0.11+ RecordBatch).
  CRC: int32
  // Magic is 1.
  Magic: int8
  // Attributes describe the attributes of this message.
  //
  // Bits 0 thru 2 correspond to compression:
  //   - 00 is no compression
  //   - 01 is gzip compression
  //   - 10 is snappy compression
  //
  // Bit 3 is the timestamp type, with 0 meaning CreateTime corresponding
  // to the timestamp being from the producer, and 1 meaning LogAppendTime
  // corresponding to the timestamp being from the broker.
  // Setting this to LogAppendTime will cause batches to be rejected.
  //
  // The remaining bits are unused and must be 0.
  Attributes: int8
  // Timestamp is the millisecond timestamp of this message.
  Timestamp: int64
  // Key is an blob of data for a record.
  //
  // Key's are usually used for hashing the record to specific Kafka partitions.
  Key: nullable-bytes
  // Value is  a blob of data. This field is the main "message" portion of a
  // record.
  Value: nullable-bytes

// Header is user provided metadata for a record. Kafka does not look at
// headers at all; they are solely for producers and consumers.
Header => not top level
  Key: varint-string
  Value: varint-bytes

// A Record is a Kafka v0.11.0.0 record. It corresponds to an individual
// message as it is written on the wire.
Record => not top level
  // Length is the length of this record on the wire of everything that
  // follows this field. It is an int32 encoded as a varint.
  Length: varint
  // Attributes are record level attributes. This field currently is unused.
  Attributes: int8
  // TimestampDelta is the millisecond delta of this record's timestamp
  // from the record's RecordBatch's FirstTimestamp.
  TimestampDelta: varint
  // OffsetDelta is the delta of this record's offset from the record's
  // RecordBatch's FirstOffset.
  //
  // For producing, this is usually equal to the index of the record in
  // the record batch.
  OffsetDelta: varint
  // Key is an blob of data for a record.
  //
  // Key's are usually used for hashing the record to specific Kafka partitions.
  Key: varint-bytes
  // Value is  a blob of data. This field is the main "message" portion of a
  // record.
  Value: varint-bytes
  // Headers are optional user provided metadata for records. Unlike normal
  // arrays, the number of headers is encoded as a varint.
  Headers: varint[Header]

// RecordBatch is a Kafka concept that groups many individual records together
// in a more optimized format.
RecordBatch => not top level
  // FirstOffset is the first offset in a record batch.
  //
  // For producing, this is usually 0.
  FirstOffset: int64
  // Length is the wire length of everything that follows this field.
  Length: int32
  // PartitionLeaderEpoch is the leader epoch of the broker at the time
  // this batch was written. Kafka uses this for cluster communication,
  // but clients can also use this to better aid truncation detection.
  // See KIP-320. Producers should set this to -1.
  PartitionLeaderEpoch: int32
  // Magic is the current "magic" number of this message format.
  // The current magic number is 2.
  Magic: int8
  // CRC is the crc of everything that follows this field using the
  // Castagnoli polynomial.
  CRC: int32
  // Attributes describe the records array of this batch.
  //
  // Bits 0 thru 3 correspond to compression:
  //   - 000 is no compression
  //   - 001 is gzip compression
  //   - 010 is snappy compression
  //   - 011 is lz4 compression
  //   - 100 is zstd compression (produce request version 7+)
  //
  // Bit 4 is the timestamp type, with 0 meaning CreateTime corresponding
  // to the timestamp being from the producer, and 1 meaning LogAppendTime
  // corresponding to the timestamp being from the broker.
  // Setting this to LogAppendTime will cause batches to be rejected.
  //
  // Bit 5 indicates whether the batch is part of a transaction (1 is yes).
  //
  // Bit 6 indicates if the batch includes a control message (1 is yes).
  // Control messages are used to enable transactions and are generated from
  // the broker. Clients should not return control batches to applications.
  Attributes: int16
  // LastOffsetDelta is the offset of the last message in a batch. This is used
  // by the broker to ensure correct behavior even with batch compaction.
  LastOffsetDelta: int32
  // FirstTimestamp is the timestamp (in milliseconds) of the first record
  // in a batch.
  FirstTimestamp: int64
  // MaxTimestamp is the timestamp (in milliseconds) of the last record
  // in a batch. Similar to LastOffsetDelta, this is used to ensure correct
  // behavior with compacting.
  MaxTimestamp: int64
  // ProducerID is the broker assigned producerID from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  //
  // Note that when not using transactions, any producer here is always
  // accepted (and the epoch is always zero). Outside transactions, the ID
  // is used only to deduplicate requests (and there must be at max 5
  // concurrent requests).
  ProducerID: int64
  // ProducerEpoch is the broker assigned producerEpoch from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  ProducerEpoch: int16
  // FirstSequence is the producer assigned sequence number used by the
  // broker to deduplicate messages.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  //
  // The sequence number for each record in a batch is OffsetDelta + FirstSequence.
  FirstSequence: int32
  // NumRecords is the number of records in the array below.
  //
  // This is separate from Records due to the potential for records to be
  // compressed.
  NumRecords: int32
  // Records contains records, either compressed or uncompressed.
  //
  // For uncompressed records, this is an array of records ([Record]).
  //
  // For compressed records, the length of the uncompressed array is kept
  // but everything that follows is compressed.
  //
  // The number of bytes is expected to be the Length field minus 49.
  Records: length-field-minus => Length - 49

// ProduceRequest issues records to be created to Kafka.
//
// Kafka 0.9.0 (v1) changed Records from MessageSet v0 to MessageSet v1.
// Kafka 0.11.0 (v3) again changed Records to RecordBatch.
//
// Note that the special client ID "__admin_client" will allow you to produce
// records to internal topics. This is generally recommended if you want to
// break your Kafka cluster.
ProduceRequest => key 0, max version 8
  // TransactionID is the transaction ID to use for this request, allowing for
  // exactly once semantics.
  TransactionID: nullable-string // v3+
  // Acks specifies the number of acks that the partition leaders must receive
  // from in sync replicas before considering a record batch fully written.
  //
  // Valid values are -1, 0, or 1 corresponding to all, none, or the leader only.
  //
  // Note that if no acks are requested, Kafka will close the connection
  // if any topic or partition errors to trigger a client metadata refresh.
  Acks: int16
  // TimeoutMillis is the millisecond timeout of this request.
  TimeoutMillis: int32
  // Topics is an array of topics to send record batches to.
  Topics: [=>]
    // Topic is a topic to send record batches to.
    Topic: string
    // Partitions is an array of partitions to send record batches to.
    Partitions: [=>]
      // Partition is a partition to send a record batch to.
      Partition: int32
      // Records is a batch of records to write to a topic's partition.
      //
      // For Kafka pre 0.11.0, the contents of the byte array is a serialized
      // message set. At or after 0.11.0, the contents of the byte array is a
      // serialized RecordBatch.
      Records: nullable-bytes

// ProduceResponse is returned from a ProduceRequest.
ProduceResponse =>
  // Topics is an array of responses for the topic's that batches were sent
  // to.
  Topics: [=>]
    // Topic is the topic this response pertains to.
    Topic: string
    // Partitions is an array of responses for the partition's that
    // batches were sent to.
    Partitions: [=>]
      // Partition is the partition this response pertains to.
      Partition: int32
      // ErrorCode is any error for a topic/partition in the request.
      // There are many error codes for produce requests.
      //
      // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for all topics and
      // partitions if the request had a transactional ID but the client
      // is not authorized for transactions.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned for all topics and partitions
      // if the request was idempotent but the client is not authorized
      // for idempotent requests.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all topics the client
      // is not authorized to talk to.
      //
      // INVALID_REQUIRED_ACKS is returned if the request contained an invalid
      // number for "acks".
      //
      // CORRUPT_MESSAGE is returned for many reasons, generally related to
      // problems with messages (invalid magic, size mismatch, etc.).
      //
      // MESSAGE_TOO_LARGE is returned if a record batch is larger than the
      // broker's configured max.message.size.
      //
      // RECORD_LIST_TOO_LARGE is returned if the record batch is larger than
      // the broker's segment.bytes.
      //
      // INVALID_TIMESTAMP is returned if the record batch uses LogAppendTime
      // or if the timestamp delta from when the broker receives the message
      // is more than the broker's log.message.timestamp.difference.max.ms.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if using a Kafka v2 message
      // format (i.e. RecordBatch) feature (idempotence) while sending v1
      // messages (i.e. a MessageSet).
      //
      // KAFKA_STORAGE_ERROR is returned if the log directory for a partition
      // is offline.
      //
      // NOT_ENOUGH_REPLICAS is returned if all acks are required, but there
      // are not enough in sync replicas yet.
      //
      // NOT_ENOUGH_REPLICAS_AFTER_APPEND is returned on old Kafka versions
      // (pre 0.11.0.0) when a message was written to disk and then Kafka
      // noticed not enough replicas existed to replicate the message.
      //
      // DUPLICATE_SEQUENCE_NUMBER is returned for Kafka <1.1.0 when a
      // sequence number is detected as a duplicate. After, out of order
      // is returned.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
      // is unknown.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      //
      // INVALID_PRODUCER_EPOCH is returned if the produce request was
      // attempted with an old epoch. Either there is a newer producer using
      // the same transaction ID, or the transaction ID used has expired.
      //
      // UNKNOWN_PRODUCER_ID, added in Kafka 1.0.0 (message format v5+) is
      // returned if the producer used an ID that Kafka does not know about or
      // if the request has a larger sequence number than Kafka expects.  The
      // LogStartOffset must be checked in this case. If the offset is greater
      // than the last acknowledged offset, then no data loss has occurred; the
      // client just sent data so long ago that Kafka rotated the partition out
      // of existence and no longer knows of this producer ID. In this case,
      // reset your sequence numbers to 0. If the log start offset is equal to
      // or less than what the client sent prior, then data loss has occurred.
      // See KAFKA-5793 for more details. NOTE: Unfortunately, even UNKNOWN_PRODUCER_ID
      // is unsafe to handle, so this error should likely be treated the same
      // as OUT_OF_ORDER_SEQUENCE_NUMER. See KIP-360 for more details.
      //
      // OUT_OF_ORDER_SEQUENCE_NUMBER is sent if the batch's FirstSequence was
      // not what it should be (the last FirstSequence, plus the number of
      // records in the last batch, plus one). After 1.0.0, this generally
      // means data loss. Before, there could be confusion on if the broker
      // actually rotated the partition out of existence (this is why
      // UNKNOWN_PRODUCER_ID was introduced).
      ErrorCode: int16
      // BaseOffset is the offset that the records in the produce request began
      // at in the partition.
      BaseOffset: int64
      // LogAppendTime is the millisecond that records were appended to the
      // partition inside Kafka. This is only not -1 if records were written
      // with the log append time flag (which producers cannot do).
      LogAppendTime: int64 // v2+
      // LogStartOffset, introduced in Kafka 1.0.0, can be used to see if an
      // UNKNOWN_PRODUCER_ID means Kafka rotated records containing the used
      // producer ID out of existence, or if Kafka lost data.
      LogStartOffset: int64 // v5+
      // ErrorRecords are indices of individual records that caused a batch
      // to error. This was added for KIP-467.
      ErrorRecords: [=>] // v8+
        // RelativeOffset is the offset of the record that caused problems.
        RelativeOffset: int32
        // ErrorMessage is the error of this record.
        ErrorMessage: nullable-string
      // ErrorMessage is the global error message of of what caused this batch
      // to error.
      ErrorMessage: nullable-string // v8+
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+

// FetchRequest is a long-poll request of records from Kafka.
//
// Kafka 0.11.0.0 released v4 and changed the returned RecordBatches to contain
// the RecordBatch type. Prior, Kafka used the MessageSet type (and, for v0 and
// v1, Kafka used a different type).
//
// Note that starting in v3, Kafka began processing partitions in order,
// meaning the order of partitions in the fetch request is important due to
// potential size constraints.
FetchRequest => key 1, max version 11
  // ReplicaID is the broker ID of performing the fetch request. Standard
  // clients should use -1. To be a "debug" replica, use -2. The debug
  // replica can be used to fetch messages from non-leaders.
  ReplicaID: int32
  // MaxWaitMillis is how long to wait for MinBytes to be hit before a broker
  // responds to a fetch request.
  MaxWaitMillis: int32
  // MinBytes is the minimum amount of bytes to attempt to read before a broker
  // responds to a fetch request.
  MinBytes: int32
  // MaxBytes is the maximum amount of bytes to read in a fetch request. The
  // response can exceed MaxBytes if the first record in the first non-empty
  // partition is larger than MaxBytes.
  MaxBytes: int32 // v3+
  // IsolationLevel changes which messages are fetched. Follower replica ID's
  // (non-negative, non-standard-client) fetch from the end.
  //
  // Standard clients fetch from the high watermark, which corresponds to
  // IsolationLevel 0, READ_UNCOMMITTED.
  //
  // To only read committed records, use IsolationLevel 1, corresponding to
  // READ_COMMITTED.
  IsolationLevel: int8 // v4+
  // SessionID is used for broker-to-broker communication.
  //
  // Because this is not needed in general clients, documentation is elided.
  // Read KIP-227 for more details. Use -1 as a general client.
  SessionID: int32 // v7+
  // SessionEpoch is used for broker-to-broker communication.
  //
  // Because this is not needed in general clients, documentation is elided.
  // Read KIP-227 for more details. Use -1 as a general client.
  SessionEpoch: int32 // v7+
  // Topic contains topics to try to fetch records for.
  Topics: [=>]
    // Topic is a topic to try to fetch records for.
    Topic: string
    // Partitions contains partitions in a topic to try to fetch records for.
    Partitions: [=>]
      // Partition is a partition in a topic to try to fetch records for.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be determined from a MetadataResponse.
      // To skip log truncation checking, use -1.
      CurrentLeaderEpoch: int32 // v9+
      // FetchOffset is the offset to begin the fetch from. Kafka will
      // return records at and after this offset.
      FetchOffset: int64
      // LogStartOffset is a broker-follower only field added for KIP-107.
      // This is the start offset of the partition in a follower.
      LogStartOffset: int64 // v5+
      // PartitionMaxBytes is the maximum bytes to return for this partition.
      // This can be used to limit how many bytes an individual partition in
      // a request is allotted so that it does not dominate all of MaxBytes.
      PartitionMaxBytes: int32
  // ForgottenTopicsData contains topics and partitions that a fetch session
  // wants to remove from its session. This is generally only needed for
  // brokers; see KIP-227 for more details.
  ForgottenTopicsData: [=>] // v7+
    // Topic is a topic to remove from being tracked (with the partitions below).
    Topic: string
    // Partitions are partitions to remove from tracking for a topic.
    Partitions: [int32]
  // Rack of the consumer making this request (see KIP-392; introduced in
  // Kafka 2.2.0).
  Rack: string // v11+

// FetchResponse is returned from a FetchRequest.
FetchResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is a full-response error code for a fetch request. This was
  // added in support of KIP-227. This error is only non-zero if using fetch
  // sessions (clients should not).
  //
  // FETCH_SESSION_ID_NOT_FOUND is returned if the request used a
  // session ID that the broker does not know of.
  //
  // INVALID_FETCH_SESSION_EPOCH is returned if the request used an
  // invalid session epoch.
  ErrorCode: int16 // v7+
  // SessionID is for broker to broker communication. See KIP-227 for more details.
  SessionID: int32 // v7+
  // Topics contains an array of topic partitions and the records received
  // for them.
  Topics: [=>]
    // Topic is a topic that records may have been received for.
    Topic: string
    // Partitions contains partitions in a topic that records may have
    // been received for.
    Partitions: [=>]
      // Partition is a partition in a topic that records may have been
      // received for.
      Partition: int32
      // ErrorCode is an error returned for an individual partition in a
      // fetch request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to read the partition.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
      // does not exist on this broker.
      //
      // UNSUPPORTED_COMPRESSION_TYPE is returned if the request version was
      // under 10 and the batch is compressed with zstd.
      //
      // UNSUPPORTED_VERSION is returned if the broker has records newer than
      // the client can support (magic value) and the broker has disabled
      // message downconversion.
      //
      // NOT_LEADER_FOR_PARTITION is returned if requesting data for this
      // partition as a follower (non-negative ReplicaID) and the broker
      // is not the leader for this partition.
      //
      // REPLICA_NOT_AVAILABLE is returned if the partition exists but
      // the requested broker is not the leader for it.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the requested partition is
      // offline.
      //
      // UNKNOWN_LEADER_EPOCH is returned if the request used a larger leader
      // epoch than the broker knows of.
      //
      // FENCED_LEADER_EPOCH is returned if the request used a smaller leader
      // epoch than the broker is at (see KIP-320).
      //
      // OFFSET_OUT_OF_RANGE is returned if requesting an offset past the
      // current end offset or before the beginning offset.
      ErrorCode: int16
      // HighWatermark is the current high watermark for this partition,
      // that is, the current offset that is on all in sync replicas.
      HighWatermark: int64
      // LastStableOffset is the offset at which all prior offsets have
      // been "decided". Non transactional records are always decided
      // immediately, but transactional records are only decided once
      // they are commited or aborted.
      //
      // The LastStableOffset will always be at or under the HighWatermark.
      LastStableOffset: int64 // v4+
      // LogStartOffset is the beginning offset for this partition.
      // This field was added for KIP-107.
      LogStartOffset: int64 // v5+
      // AbortedTransactions is an array of aborted transactions within the
      // returned offset range. This is only returned if the requested
      // isolation level was READ_COMMITTED.
      AbortedTransactions: nullable[=>] // v4+
        // ProducerID is the producer ID that caused this aborted transaction.
        ProducerID: int64
        // FirstOffset is the offset where this aborted transaction began.
        FirstOffset: int64
      // PreferredReadReplica is the preferred replica for the consumer
      // to use on its next fetch request. See KIP-392.
      PreferredReadReplica: int32 // v11+
      // RecordBatches is an array of record batches for a topic partition.
      //
      // This is encoded as a raw byte array, with the standard int32 size
      // prefix. One important catch to note is that the final element of the
      // array may be **partial**. This is an optimization in Kafka that
      // clients must deal with by discarding a partial trailing batch.
      //
      // Starting v2, this transitioned to the MessageSet v1 format (and this
      // would contain many MessageV1 structs).
      //
      // Starting v4, this transitioned to the RecordBatch format (thus this
      // contains many RecordBatch structs).
      RecordBatches: nullable-bytes

// ListOffsetsRequest requests partition offsets from Kafka for use in
// consuming records.
//
// Version 5, introduced in Kafka 2.2.0, is the same as version 4. Using
// version 5 implies you support Kafka's OffsetNotAvailableException
// See KIP-207 for details.
ListOffsetsRequest => key 2, max version 5, admin
  // ReplicaID is the broker ID to get offsets from. As a Kafka client, use -1.
  // The consumer replica ID (-1) causes requests to only succeed if issued
  // against the leader broker.
  ReplicaID: int32
  // IsolationLevel configures which record offsets are visible in the
  // response. READ_UNCOMMITTED (0) makes all records visible. READ_COMMITTED
  // (1) makes non-transactional and committed transactional records visible.
  // READ_COMMITTED means all offsets smaller than the last stable offset and
  // includes aborted transactions (allowing consumers to discard aborted
  // records).
  IsolationLevel: int8 // v2+
  // Topics is an array of topics to get offsets for.
  Topics: [=>]
    // Topic is a topic to get offsets for.
    Topic: string
    // Partitions is an array of partitions in a topic to get offsets for.
    Partitions: [=>]
      // Partition is a partition of a topic to get offsets for.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be determined from a MetadataResponse.
      // To skip log truncation checking, use -1.
      CurrentLeaderEpoch: int32 // v4+
      // Timestamp controls which offset to return in a response for this
      // partition.
      //
      // The offset returned will be the one of the message whose timestamp is
      // the first timestamp greater than or equal to this requested timestamp.
      //
      // If no such message is found, the log end offset is returned.
      //
      // There exist two special timestamps: -2 corresponds to the earliest
      // timestamp, and -1 corresponds to the latest.
      Timestamp: int64
      // MaxNumOffsets is the maximum number of offsets to report.
      // This was removed after v0.
      MaxNumOffsets: int32 // v0-v0

// ListOffsetsResponse is returned from a ListOffsetsRequest.
ListOffsetsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v2+
  // Topics is an array of topic / partition responses corresponding to
  // the requested topics and partitions.
  Topics: [=>]
    // Topic is the topic this array slot is for.
    Topic: string
    // Partitions is an array of partition responses corresponding to
    // the requested partitions for a topic.
    Partitions: [=>]
      // Partition is the partition this array slot is for.
      Partition: int32
      // ErrorCode is any error for a topic partition in a ListOffsets request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to describe the topic.
      //
      // INVALID_REQUEST is returned if the requested topic partitions had
      // contained duplicates.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the topic / partition is in
      // an offline log directory.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if the broker is using
      // Kafka 0.10.0 messages and the requested timestamp was not -1 nor -2.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      // If the request used the debug replica ID, the returned error will
      // be REPLICA_NOT_AVAILABLE.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know
      // of the requested topic or partition.
      //
      // FENCED_LEADER_EPOCH is returned if the broker has a higher leader
      // epoch than what the request sent.
      //
      // UNKNOWN_LEADER_EPOCH is returned if the request used a leader epoch
      // that the broker does not know about.
      //
      // OFFSET_NOT_AVAILABLE, introduced in Kafka 2.2.0 with produce request
      // v5+, is returned when talking to a broker that is a new leader while
      // that broker's high water mark catches up. This avoids situations where
      // the old broker returned higher offsets than the new broker would. Note
      // that if unclean leader election is allowed, you could still run into
      // the situation where offsets returned from list offsets requests are
      // not monotonically increasing. This error is only returned if the
      // request used the consumer replica ID (-1). If the client did not use
      // a v5+ list offsets request, LEADER_NOT_AVAILABLE is returned.
      // See KIP-207 for more details.
      ErrorCode: int16
      // OldStyleOffsets is a list of offsets. This was removed after
      // version 0 and, since it is so historic, is undocumented.
      OldStyleOffsets: [int64] // v0-v0
      // If the request was for the earliest or latest timestamp (-2 or -1), or
      // if an offset could not be found after the requested one, this will be -1.
      Timestamp: int64
      // Offset is the offset corresponding to the record on or after the
      // requested timestamp. If one could not be found, this will be -1.
      Offset: int64 // v1+
      // LeaderEpoch is the leader epoch of the record at this offset,
      // or -1 if there was no leader epoch.
      LeaderEpoch: int32 // v4+

// MetadataRequest requests metadata from Kafka.
MetadataRequest => key 3, max version 9, flexible v9+
  // Topics is a list of topics to return metadata about. If this is null
  // in v1+, all topics are included. If this is empty, no topics are.
  // For v0 (<Kafka 0.10.0.0), if this is empty, all topics are included.
  Topics: nullable-v1+[=>]
    // Topic is the topic to request metadata for.
    Topic: string
  // AllowAutoTopicCreation, introduced in Kafka 0.11.0.0, allows topic
  // auto creation of the topics in this request if they do not exist.
  AllowAutoTopicCreation: bool // v4+
  // IncludeClusterAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on the cluster. See KIP-430 for more details.
  IncludeClusterAuthorizedOperations: bool // v8+
  // IncludeTopicAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on individual topics. See KIP-430 for more details.
  IncludeTopicAuthorizedOperations: bool // v8+

// MetadataResponse is returned from a MetdataRequest.
MetadataResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v3+
  // Brokers is a set of alive Kafka brokers.
  Brokers: [=>]
    // NodeID is the node ID of a Kafka broker.
    NodeID: int32
    // Host is the hostname of a Kafka broker.
    Host: string
    // Port is the port of a Kafka broker.
    Port: int32
    // Rack is the rack this Kafka broker is in.
    Rack: nullable-string // v1+
  // ClusterID, proposed in KIP-78 and introduced in Kafka 0.10.1.0, is a
  // unique string specifying the cluster that the replying Kafka belongs to.
  ClusterID: nullable-string // v2+
  // ControllerID is the ID of the controller broker (the admin broker).
  ControllerID: int32 // v1+
  // Topics contains metadata about each topic requested in the
  // MetadataRequest.
  Topics: [=>]
    // ErrorCode is any error for a topic in a metadata request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe the topic, or if the metadata request specified topic auto
    // creation, the topic did not exist, and the user lacks permission to create.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if a topic does not exist and
    // the request did not specify autocreation.
    //
    // LEADER_NOT_AVAILABLE is returned if a new topic is created successfully
    // (since there is no leader on an immediately new topic).
    //
    // There can be a myriad of other errors for unsuccessful topic creation.
    ErrorCode: int16
    // Topic is the topic this metadata corresponds to.
    Topic: string
    // IsInternal signifies whether this topic is a Kafka internal topic.
    IsInternal: bool // v1+
    // Partitions contains metadata about partitions for a topic.
    Partitions: [=>]
      // ErrorCode is any error for a partition in topic metadata.
      //
      // LEADER_NOT_AVAILABLE is returned if a leader is unavailable for this
      // partition. For v0 metadata responses, this is also returned if a
      // partition leader's listener does not exist.
      //
      // LISTENER_NOT_FOUND is returned if a leader ID is known but the
      // listener for it is not (v1+).
      //
      // REPLICA_NOT_AVAILABLE is returned in v0 responses if any replica is
      // unavailable.
      ErrorCode: int16
      // Partition is a partition number for a topic.
      Partition: int32
      // Leader is the broker leader for this partition. This will be -1
      // on leader / listener error.
      Leader: int32
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0 is the
      // epoch of the broker leader.
      LeaderEpoch: int32 // v7+
      // Replicas returns all broker IDs containing replicas of this partition.
      Replicas: [int32]
      // ISR returns all broker IDs of in-sync replicas of this partition.
      ISR: [int32]
      // OfflineReplicas, proposed in KIP-112 and introduced in Kafka 1.0,
      // returns all offline broker IDs that should be replicating this partition.
      OfflineReplicas: [int32] // v5+
    // AuthorizedOperations, proposed in KIP-430 and introduced in Kafka 2.3.0,
    // is a bitfield (corresponding to AclOperation) containing which operations
    // the client is allowed to perform on this topic.
    // This is only returned if requested.
    AuthorizedOperations: int32 // v8+
  // AuthorizedOperations is a bitfield containing which operations the client
  // is allowed to perform on this cluster.
  AuthorizedOperations: int32 // v8+

// LeaderAndISRRequestTopicPartition is a common struct that is used across
// different versions of LeaderAndISRRequest.
LeaderAndISRRequestTopicPartition => not top level, no encoding
  Topic: string // v0-v1
  Partition: int32
  ControllerEpoch: int32
  Leader: int32
  LeaderEpoch: int32
  ISR: [int32]
  ZKVersion: int32
  Replicas: [int32]
  AddingReplicas: [int32] // v3+
  RemovingReplicas: [int32] // v3+
  IsNew: bool // v1+


// LeaderAndISRRequest is an advanced request that controller brokers use
// to broadcast state to other brokers. Manually using this request is a
// great way to break your cluster.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 1.0.0 introduced version 1. Kafka 2.2.0 introduced version 2, proposed
// in KIP-380, which changed the layout of the struct to be more memory
// efficient. Kafka 2.4.0 introduced version 3 with KIP-455.
LeaderAndISRRequest => key 4, max version 4, flexible v4+, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v2+
  PartitionStates: [LeaderAndISRRequestTopicPartition] // v0-v1
  TopicStates: [=>] // v2+
    Topic: string
    PartitionStates: [LeaderAndISRRequestTopicPartition]
  LiveLeaders: [=>]
    BrokerID: int32
    Host: string
    Port: int32

// LeaderAndISRResponse is returned from a LeaderAndISRRequest.
LeaderAndISRResponse =>
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

// StopReplicaRequest is an advanced request that brokers use to stop replicas.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 2.2.0 introduced version 1, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
StopReplicaRequest => key 5, max version 2, flexible v2+, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v1+
  DeletePartitions: bool
  Topics: [=>]
    Topic: string
    Partition: int32 // v0-v0
    Partitions: [int32] // v1+

// StopReplicasResponse is returned from a StopReplicasRequest.
StopReplicaResponse =>
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

UpdateMetadataRequestTopicPartition => not top level, no encoding
  Topic: string // v0-v4
  Partition: int32
  ControllerEpoch: int32
  Leader: int32
  LeaderEpoch: int32
  ISR: [int32]
  ZKVersion: int32
  Replicas: [int32]
  OfflineReplicas: [int32]

// UpdateMetadataRequest is an advanced request that brokers use to
// issue metadata updates to each other.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Version 1 changed the layout of the live brokers.
//
// Kafka 2.2.0 introduced version 5, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
UpdateMetadataRequest => key 6, max version 6, flexible v6+, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v5+
  PartitionStates: [UpdateMetadataRequestTopicPartition] // v0-v4
  TopicStates: [=>] // v5+
    Topic: string
    PartitionStates: [UpdateMetadataRequestTopicPartition]
  LiveBrokers: [=>]
    ID: int32
    Host: string // v0-v0
    Port: int32 // v0-v0
    Endpoints: [=>] // v1+
      Port: int32
      Host: string
      ListenerName: string // v3+
      SecurityProtocol: int16
    Rack: nullable-string // v2+

// UpdateMetadataResponses is returned from an UpdateMetadataRequest.
UpdateMetadataResponse =>
  ErrorCode: int16

// ControlledShutdownRequest is an advanced request that can be used to
// sthudown a broker in a controlled manner.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented. However, the minimal amount of fields
// here makes the usage rather obvious.
//
// Kafka 2.2.0 introduced version 2, proposed in KIP-380.
//
// Note that version 0 of this request uses a special encoding format
// where the request does not include the client ID.
ControlledShutdownRequest => key 7, max version 3, flexible v3+, admin
  BrokerID: int32
  BrokerEpoch: int64 // v2+

// ControlledShutdownResponse is returned from a ControlledShutdownRequest.
ControlledShutdownResponse =>
  ErrorCode: int16
  PartitionsRemaining: [=>]
    Topic: string
    Partition: int32

// OffsetCommitKey is the key for the Kafka internal __consumer_offsets topic
// if the key starts with an int16 with a value of 0 or 1.
//
// This type was introduced in KAFKA-1012 commit a670537aa3 with release 0.8.2
// and has been in use ever since.
OffsetCommitKey => not top level, with version field
  // Version is which encoding version this value is using.
  Version: int16
  // Group is the group being committed.
  Group: string
  // Topic is the topic being committed.
  Topic: string
  // Partition is the partition being committed.
  Partition: int32

// OffsetCommitValue is the value for the Kafka internal __consumer_offsets
// topic if the key is of OffsetCommitKey type.
//
// Version 0 was introduced with the key version 0.
//
// KAFKA-1634 commit c5df2a8e3a in 0.9.0 released version 1.
//
// KAFKA-4682 commit 418a91b5d4, proposed in KIP-211 and included in 2.1.0
// released version 2.
//
// KAFKA-7437 commit 9f7267dd2f, proposed in KIP-320 and included in 2.1.0
// released version 3.
OffsetCommitValue => not top level, with version field
  // Version is which encoding version this value is using.
  Version: int16
  // Offset is the committed offset.
  Offset: int64
  // LeaderEpoch is the epoch of the leader committing this message.
  LeaderEpoch: int32 // v3+
  // Metadata is the metadata included in the commit.
  Metadata: string
  // CommitTimestamp is when this commit occurred.
  CommitTimestamp: int64
  // ExpireTimestamp, introduced in v1 and dropped in v2 with KIP-111,
  // is when this commit expires.
  ExpireTimestamp: int64 // v1-v1

// GroupMetadataKey is the key for the Kafka internal __consumer_offsets topic
// if the key starts with an int16 with a value of 2.
//
// This type was introduced in KAFKA-2017 commit 7c33475274 with release 0.9.0
// and has been in use ever since.
GroupMetadataKey => not top level, with version field
  // Version is which encoding version this value is using.
  Version: int16
  // Group is the group this metadata is for.
  Group: string

// GroupMetadataValue is the value for the Kafka internal __consumer_offsets
// topic if the key is of GroupMetadataKey type.
//
// Version 0 was introduced with the key version 0.
//
// KAFKA-3888 commit 40b1dd3f49, proposed in KIP-62 and included in 0.10.1
// released version 1.
//
// KAFKA-4682 commit 418a91b5d4, proposed in KIP-211 and included in 2.1.0
// released version 2.
//
// KAFKA-7862 commit 0f995ba6be, proposed in KIP-345 and included in 2.3.0
// released version 3.
GroupMetadataValue => not top level, with version field
  // Version is the version of this value.
  Version: int16
  // ProtocolType is the type of protocol being used for the group
  // (i.e., "consumer").
  ProtocolType: string
  // Generation is the generation of this group.
  Generation: int32
  // Protocol is the agreed upon protocol all members are using to partition
  // (i.e., "sticky").
  Protocol: nullable-string
  // Leader is the group leader.
  Leader: nullable-string
  // CurrentStateTimestamp is the timestamp for this state of the group
  // (stable, etc.).
  CurrentStateTimestamp: int64 // v2+
  // Members are the group members.
  Members: [=>]
    // MemberID is a group member.
    MemberID: string
    // InstanceID is the instance ID of this member in the group (KIP-345).
    InstanceID: nullable-string // v3+
    // ClientID is the client ID of this group member.
    ClientID: string
    // ClientHost is the hostname of this group member.
    ClientHost: string
    // RebalanceTimeoutMillis is the rebalance timeout of this group member.
    RebalanceTimeoutMillis: int32 // v1+
    // SessionTimeoutMillis is the session timeout of this group member.
    SessionTimeoutMillis: int32
    // Subscription is the subscription of this group member.
    Subscription: bytes
    // Assignment is what the leader assigned this group member.
    Assignment: bytes

// TxnMetadataKey is the key for the Kafka internal __transaction_state topic
// if the key starts with an int16 with a value of 0.
TxnMetadataKey => not top level, with version field
  // Version is the version of this type.
  Version: int16
  // TransactionalID is the transactional ID this record is for.
  TransactionalID: string

// TxnMetadataValue is the value for the Kafka internal __transaction_state
// topic if the key is of TxnMetadataKey type.
TxnMetadataValue => not top level, with version field
  // Version is the version of this value.
  Version: int16
  // ProducerID is the ID in use by the transactional ID.
  ProducerID: int64
  // ProducerEpoch is the epoch associated with the producer ID.
  ProducerEpoch: int16
  // TimeoutMillis is the timeout of this transaction in milliseconds.
  TimeoutMillis: int32
  // State is the state this transaction is in,
  // 0 is Empty, 1 is Ongoing, 2 is PrepareCommit, 3 is PrepareAbort, 4 is
  // CompleteCommit, 5 is CompleteAbort, 6 is Dead, and 7 is PrepareEpochFence.
  State: int8
  // Topics are topics that are involved in this transaction.
  Topics: [=>]
    // Topic is a topic involved in this transaction.
    Topic: string
    // Partitions are partitions in this topic involved in the transaction.
    Partitions: [int32]
  // LastUpdateTimestamp is the timestamp in millis of when this transaction
  // was last updated.
  LastUpdateTimestamp: int64
  // StartTimestamp is the timestamp in millis of when this transaction started.
  StartTimestamp: int64

// OffsetCommitRequest commits offsets for consumed topics / partitions in
// a group.
OffsetCommitRequest => key 8, max version 8, flexible v8+, group coordinator
  // Group is the group this request is committing offsets to.
  Group: string
  // Generation being -1 and group being empty means the group is being used
  // to store offsets only. No generation validation, no rebalancing.
  Generation: int32 // v1+
  // MemberID is the ID of the client issuing this request in the group.
  MemberID: string // v1+
  // InstanceID is the instance ID of this member in the group (KIP-345).
  InstanceID: nullable-string // v7+
  // RetentionTimeMillis is how long this commit will persist in Kafka.
  //
  // This was introduced in v2, replacing an individual topic/partition's
  // Timestamp from v1, and was removed in v5 with Kafka 2.1.0.
  //
  // This was removed because rarely committing consumers could have their
  // offsets expired before committing, even though the consumer was still
  // active. After restarting or rebalancing, the consumer would now not know
  // the last committed offset and would have to start at the beginning or end,
  // leading to duplicates or log loss.
  //
  // Post 2.1.0, if this field is empty, offsets are only deleted once the
  // group is empty. Read KIP-211 for more details.
  RetentionTimeMillis: int64 // v2-v4
  // Topics is contains topics and partitions for which to commit offsets.
  Topics: [=>]
    // Topic is a topic to commit offsets for.
    Topic: string
    // Partitions contains partitions in a topic for which to commit offsets.
    Partitions: [=>]
      // Partition if a partition to commit offsets for.
      Partition: int32
      // Offset is an offset to commit.
      Offset: int64
      // Timestamp is the first iteration of tracking how long offset commits
      // should persist in Kafka. This field only existed for v1.
      // The expiration would be timestamp + offset.retention.minutes, or, if
      // timestamp was zero, current time + offset.retention.minutes.
      Timestamp: int64 // v1-v1
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // is the leader epoch of the record this request is committing.
      //
      // The initial leader epoch can be determined from a MetadataResponse.
      // To skip log truncation checking, use -1.
      LeaderEpoch: int32 // v6+
      // Metadata is optional data to include with committing the offset. This
      // can contain information such as which node is doing the committing, etc.
      Metadata: nullable-string

// OffsetCommitResponse is returned from an OffsetCommitRequest.
OffsetCommitResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v3+
  // Topics contains responses for each topic / partition in the commit request.
  Topics: [=>]
    // Topic is the topic this offset commit response corresponds to.
    Topic: string
    // Partitions contains responses for each requested partition in
    // a topic.
    Partitions: [=>]
      // Partition is the partition in a topic this array slot corresponds to.
      Partition: int32
      // ErrorCode is the error for this partition response.
      //
      // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
      // for the group.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // for the topic / partition.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic / partition does
      // not exist.
      //
      // OFFSET_METADATA_TOO_LARGE is returned if the request metadata is
      // larger than the brokers offset.metadata.max.bytes.
      //
      // INVALID_GROUP_ID is returned in the requested group ID is invalid.
      //
      // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
      // (due to the requested broker shutting down or it has not completed startup).
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
      //
      // NOT_COORDINATOR is returned if the requested broker is not the coordinator
      // for the requested group.
      //
      // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
      //
      // UNKNOWN_MEMBER_ID is returned if the group is dead or the group does not
      // know of the request's member ID.
      //
      // REBALANCE_IN_PROGRESS is returned if the group is finishing a rebalance.
      //
      // INVALID_COMMIT_OFFSET_SIZE is returned if the offset commit results in
      // a record batch that is too large (likely due to large metadata).
      ErrorCode: int16

// OffsetFetchRequest requests the most recent committed offsets for topic
// partitions in a group.
OffsetFetchRequest => key 9, max version 6, flexible v6+, group coordinator
  // Group is the group to fetch offsets for.
  Group: string
  // Topics contains topics to fetch offets for. Version 2+ allows this to be
  // null to return all topics the client is authorized to describe in the group.
  Topics: nullable-v2+[=>]
    // Topic is a topic to fetch offsets for.
    Topic: string
    // Partitions in a list of partitions in a group to fetch offsets for.
    Partitions: [int32]

// OffsetFetchResponse is returned from an OffsetFetchRequest.
OffsetFetchResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v3+
  // Topics contains responses for each requested topic/partition.
  Topics: [=>]
    // Topic is the topic this offset fetch response corresponds to.
    Topic: string
    // Partitions contains responses for each requested partition in
    // a topic.
    Partitions: [=>]
      // Partition is the partition in a topic this array slot corresponds to.
      Partition: int32
      // Offset is the most recently committed offset for this topic partition
      // in a group.
      Offset: int64
      // LeaderEpoch is the leader epoch of the last consumed record.
      //
      // This was proposed in KIP-320 and introduced in Kafka 2.1.0 and allows
      // clients to detect log truncation. See the KIP for more details.
      LeaderEpoch: int32 // v5+
      // Metadata is client provided metadata corresponding to the offset commit.
      // This can be useful for adding who made the commit, etc.
      Metadata: nullable-string
      // ErrorCode is the error for this partition response.
      //
      // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to the group.
      //
      // INVALID_GROUP_ID is returned in the requested group ID is invalid.
      //
      // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
      // (due to the requested broker shutting down or it has not completed startup).
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
      //
      // NOT_COORDINATOR is returned if the requested broker is not the coordinator
      // for the requested group.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the requested topic or partition
      // is unknown.
      ErrorCode: int16
  // ErrorCode is a top level error code that applies to all topic/partitions.
  // This will be any group error.
  ErrorCode: int16 // v2+

// FindCoordinatorRequest requests the coordinator for a group or transaction.
//
// This coordinator is different from the broker leader coordinator. This
// coordinator is the partition leader for the partition that is storing
// the group or transaction ID.
FindCoordinatorRequest => key 10, max version 3, flexible v3+
  // CoordinatorKey is the ID to use for finding the coordinator. For groups,
  // this is the group name, for transactional producer, this is the
  // transactional ID.
  CoordinatorKey: string // v0+
  // CoordinatorType is the type that key is. Groups are type 0,
  // transactional IDs are type 1.
  CoordinatorType: int8 // v1+

// FindCoordinatorResponse is returned from a FindCoordinatorRequest.
FindCoordinatorResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is the error returned for the request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if for a group ID request and the
  // client is not authorized to describe groups.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for a transactional ID
  // request and the client is not authorized to describe transactional IDs.
  //
  // INVALID_REQUEST is returned if not asking for a known type (group,
  // or transaction).
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // for the requested ID, or if the requested ID does not exist.
  ErrorCode: int16
  // ErrorMessage is an informative message if the request errored.
  ErrorMessage: nullable-string // v1+
  // NodeID is the broker ID of the coordinator.
  NodeID: int32
  // Host is the host of the coordinator.
  Host: string
  // Port is the port of the coordinator.
  Port: int32

// StickyMemberMetadata is is what is encoded in UserData for
// GroupMemberMetadata in group join requests with the sticky partitioning
// strategy.
//
// V1 added generation, which fixed a bug with flaky group members joining
// repeatedly. See KIP-341 for more details.
//
// Note that clients should always try decoding as v1 and, if that fails,
// fall back to v0. This is necessary due to there being no version number
// anywhere in this type.
StickyMemberMetadata => not top level, no encoding
  // CurrentAssignment is the assignment that a group member has when
  // issuing a join.
  CurrentAssignment: [=>]
    // Topic is a topic the group member is currently assigned.
    Topic: string
    // Partitions are the partitions within a topic that a group member is
    // currently assigned.
    Partitions: [int32]
  // Generation is the generation of this join. This is incremented every join.
  Generation: int32 // v1+

// GroupMemberMetadata is the metadata that is usually sent with a join group
// request.
GroupMemberMetadata => not top level, with version field
  // Version is either version 0 or version 1.
  Version: int16
  // Topics is the list of topics in the group that this member is interested
  // in consuming.
  Topics: [string]
  // UserData is arbitrary client data for a given client in the group.
  // For sticky assignment, this is StickyMemberMetadata.
  UserData: bytes
  // OwnedPartitions, introduced for KIP-429, are the partitions that this
  // member currently owns.
  OwnedPartitions: [=>] // v1+
    Topic: string
    Partitions: [int32]

// GroupMemberAssignment is the assignment data that is usually sent with a
// sync group request.
GroupMemberAssignment => not top level
  // Verson is currently version 0.
  Version: int16
  // Topics contains topics in the assignment.
  Topics: [=>]
    // Topic is a topic in the assignment.
    Topic: string
    // Partitions contains partitions in the assignment.
    Partitions: [int32]
  // UserData is arbitrary client data for a given client in the group.
  UserData: bytes

// JoinGroupRequest issues a request to join a Kafka group. This will create a
// group if one does not exist. If joining an existing group, this may trigger
// a group rebalance.
//
// This will trigger a group rebalance if the request is from the group leader,
// or if the request is from a group member with different metadata, or if the
// request is with a new group member.
//
// Version 4 introduced replying to joins of existing groups with
// MEMBER_ID_REQUIRED, which requires re-issuing the join group with the
// returned member ID. See KIP-394 for more details.
//
// Version 5 introduced InstanceID, allowing for more "static" membership.
// See KIP-345 for more details.
JoinGroupRequest => key 11, max version 6, flexible v6+, group coordinator
  // Group is the group to join.
  Group: string
  // SessionTimeoutMillis is how long a member in the group can go between
  // heartbeats. If a member does not send a heartbeat within this timeout,
  // the broker will remove the member from the group and initiate a rebalance.
  SessionTimeoutMillis: int32
  // RebalanceTimeoutMillis is how long the broker waits for members to join a group
  // once a rebalance begins. Kafka waits for the longest rebalance of all
  // members in the group. Member sessions are still alive; heartbeats will be
  // replied to with REBALANCE_IN_PROGRESS. Those members must transition to
  // joining within this rebalance timeout. Members that do not rejoin within
  // this timeout will be removed from the group. Members must commit offsets
  // within this timeout.
  //
  // The first join for a new group has a 3 second grace period for other
  // members to join; this grace period is extended until the RebalanceTimeoutMillis
  // is up or until 3 seconds lapse with no new members.
  RebalanceTimeoutMillis: int32 // v1+
  // MemberID is the member ID to join the group with. When joining a group for
  // the first time, use the empty string. The response will contain the member
  // ID that should be used going forward.
  MemberID: string
  // InstanceID is a user configured ID that is used for making a group
  // member "static", allowing many rebalances to be avoided.
  InstanceID: nullable-string // v5+
  // ProtocolType is the "type" of protocol being used for the join group.
  // The initial group creation sets the type; all additional members must
  // have the same type or they will be rejected.
  //
  // This is completely arbitrary, but the Java client and everything else
  // uses "consumer" as the protocol type.
  ProtocolType: string
  // Protocols contains arbitrary information that group members use
  // for rebalancing. All group members must agree on at least one protocol
  // name.
  Protocols: [=>]
    // Name is a name of a protocol. This is arbitrary, but is used
    // in the official client to agree on a partition balancing strategy.
    //
    // The official client uses range, roundrobin, or sticky (which was
    // introduced in KIP-54).
    Name: string
    // Metadata is arbitrary information to pass along with this
    // protocol name for this member.
    //
    // Note that while this is not documented in any protocol page,
    // this is usually a serialized GroupMemberMetadata as described in
    // https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal.
    //
    // The protocol metadata is where group members will communicate which
    // topics they collectively as a group want to consume.
    Metadata: bytes

// JoinGroupResponse is returned from a JoinGroupRequest.
JoinGroupResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v2+
  // ErrorCode is the error for the join group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // INVALID_SESSION_TIMEOUT is returned if the requested SessionTimeout is
  // not within the broker's group.{min,max}.session.timeout.ms.
  //
  // INCONSISTENT_GROUP_PROTOCOL is returned if the requested protocols are
  // incompatible with the existing group member's protocols, or if the join
  // was for a new group but contained no protocols.
  //
  // UNKNOWN_MEMBER_ID is returned is the requested group is dead (likely
  // just migrated to another coordinator or the group is temporarily unstable),
  // or if the request was for a new group but contained a non-empty member ID,
  // or if the group does not have the requested member ID (and the client must
  // do the new-join-group dance).
  //
  // MEMBER_ID_REQUIRED is returned on the initial join of an existing group.
  // This error was proposed in KIP-394 and introduced in Kafka 2.2.0 to
  // prevent flaky clients from continually triggering rebalances and prevent
  // these clients from consuming RAM with metadata. If a client sees
  // this error, it should re-issue the join with the MemberID in the response.
  // Non-flaky clients will join with this new member ID, but flaky clients
  // will not join quickly enough before the pending member ID is rotated out
  // due to hitting the session.timeout.ms.
  //
  // GROUP_MAX_SIZE_REACHED is returned as of Kafka 2.2.0 if the group has
  // reached a broker's group.max.size.
  ErrorCode: int16
  // Generation is the current "generation" of this group.
  Generation: int32
  // Protocol is the agreed upon protocol name.
  Protocol: string
  // LeaderID is the leader member.
  LeaderID: string
  // MemberID is the member of the receiving client.
  MemberID: string
  // Members contains all other members of this group. Only the group leader
  // receives the members. The leader is responsible for balancing subscribed
  // topic partitions and replying appropriately in a SyncGroup request.
  Members: [=>]
    // MemberID is a member in this group.
    MemberID: string
    // InstanceID is an instance ID of a member in this group (KIP-345).
    InstanceID: nullable-string // v5+
    // ProtocolMetadata is the metadata for this member for this protocol.
    // This is usually of type GroupMemberMetadata.
    ProtocolMetadata: bytes

// HeartbeatRequest issues a heartbeat for a member in a group, ensuring that
// Kafka does not expire the member from the group.
HeartbeatRequest => key 12, max version 4, flexible v4+, group coordinator
  // Group is the group ID this heartbeat is for.
  Group: string
  // Generation is the group generation this heartbeat is for.
  Generation: int32
  // MemberID is the member ID this member is for.
  MemberID: string
  // InstanceID is the instance ID of this member in the group (KIP-345).
  InstanceID: nullable-string // v3+

// HeartbeatResponse is returned from a HeartbeatRequest.
HeartbeatResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is the error for the heartbeat request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  //
  // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
  //
  // REBALANCE_IN_PROGRESS is returned if the group is currently rebalancing.
  ErrorCode: int16

// LeaveGroupRequest issues a request for a group member to leave the group,
// triggering a group rebalance.
//
// Version 3 changed removed MemberID and added a batch instance+member ID
// way of leaving a group.
LeaveGroupRequest => key 13, max version 4, flexible v4+, group coordinator
  // Group is the group to leave.
  Group: string
  // MemberID is the member that is leaving.
  MemberID: string // v0-v2
  // Members are member and group instance IDs to cause to leave a group.
  Members: [=>] // v3+
    MemberID: string
    InstanceID: nullable-string

// LeaveGroupResponse is returned from a LeaveGroupRequest.
LeaveGroupResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is the error for the leave group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  ErrorCode: int16
  // Members are the list of members and group instance IDs that left the group.
  Members: [=>] // v3+
    MemberID: string
    InstanceID: nullable-string
    // An individual member's leave error code.
    ErrorCode: int16

// SyncGroupRequest is issued by all group members after they receive a a
// response for JoinGroup. The group leader is responsible for sending member
// assignments with the request; all other members do not.
//
// Once the leader sends the group assignment, all members will be replied to.
SyncGroupRequest => key 14, max version 4, flexible v4+, group coordinator
  // Group is the group ID this sync group is for.
  Group: string
  // Generation is the group generation this sync is for.
  Generation: int32
  // MemberID is the member ID this member is.
  MemberID: string
  // InstanceID is the instance ID of this member in the group (KIP-345).
  InstanceID: nullable-string // v3+
  // GroupAssignment, sent only from the group leader, is the topic partition
  // assignment it has decided on for all members.
  GroupAssignment: [=>]
    // MemberID is the member this assignment is for.
    MemberID: string
    // MemberAssignment is the assignment for this member. This is typically
    // of type GroupMemberAssignment.
    MemberAssignment: bytes

// SyncGroupResponse is returned from a SyncGroupRequest.
SyncGroupResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is the error for the sync group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  //
  // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
  //
  // REBALANCE_IN_PROGRESS is returned if the group switched back to rebalancing.
  //
  // UNKNOWN_SERVER_ERROR is returned if the store of the group assignment
  // resulted in a too large message.
  ErrorCode: int16
  // MemberAssignment is the assignment for this member that the leader
  // determined.
  MemberAssignment: bytes

// DescribeGroupsRequest requests metadata for group IDs.
DescribeGroupsRequest => key 15, max version 5, flexible v5+, group coordinator
  // Groups is an array of group IDs to request metadata for.
  // If this is empty, the response will include all groups.
  Groups: [string]
  // IncludeAuthorizedOperations, introduced in Kafka 2.3.0, specifies
  // whether to include a bitfield of AclOperations this client can perform
  // on the groups. See KIP-430 for more details.
  IncludeAuthorizedOperations: bool

// DescribeGroupsResponse is returned from a DescribeGroupsRequest.
DescribeGroupsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Groups is an array of group metadata.
  Groups: [=>]
    // ErrorCode is the error code for an individual group in a request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
    //
    // NOT_COORDINATOR is returned if the requested broker is not the
    // coordinator for this group.
    ErrorCode: int16
    // Group is the id of this group.
    Group: string
    // State is the state this group is in.
    State: string
    // ProtocolType is the "type" of protocol being used for this group.
    ProtocolType: string
    // Protocol is the agreed upon protocol for all members in this group.
    Protocol: string
    // Members contains members in this group.
    Members: [=>]
      // MemberID is the member ID of a member in this group.
      MemberID: string
      // InstanceID is the instance ID of this member in the group (KIP-345).
      InstanceID: nullable-string // v4+
      // ClientID is the client ID used by this member.
      ClientID: string
      // ClientHost is the host this client is running on.
      ClientHost: string
      // ProtocolMetadata is the metadata this member included when joining
      // the group. If using normal (Java-like) consumers, this will be of
      // type GroupMemberMetadata.
      ProtocolMetadata: bytes
      // MemberAssignment is the assignment for this member in the group.
      // If using normal (Java-like) consumers, this will be of type
      // GroupMemberAssignment.
      MemberAssignment: bytes
    // AuthorizedOperations is a bitfield containing which operations the
    // the client is allowed to perform on this group.
    // This is only returned if requested.
    AuthorizedOperations: int32 // v3+

// ListGroupsRequest issues a request to list all groups.
ListGroupsRequest => key 16, max version 3, flexible v3+, admin

// ListGroupsResponse is returned from a ListGroupsRequest.
ListGroupsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // ErrorCode is the error returned for the list groups request.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not yet active.
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group manager is loading.
  ErrorCode: int16
  // Groups is the list of groups Kafka knows of.
  Groups: [=>]
    // Group is a Kafka group.
    Group: string
    // ProtocolType is the protocol type in use by the group.
    ProtocolType: string

// SASLHandshakeRequest begins the sasl authentication flow. Note that Kerberos
// GSSAPI authentication has its own unique flow.
SASLHandshakeRequest => key 17, max version 1
  // Mechanism is the mechanism to use for the sasl handshake (e.g., "PLAIN").
  //
  // For version 0, if this mechanism is supported, it is expected that the
  // client immediately authenticates using this mechanism. Note that the
  // only mechanism exclusive to v0 is PLAIN.
  //
  // For version 1, if the mechanism is supported, the next request to issue
  // is SASLHandshakeRequest.
  Mechanism: string

// SASLHandshakeResponse is returned for a SASLHandshakeRequest.
SASLHandshakeResponse =>
  // ErrorCode is non-zero for ILLEGAL_SASL_STATE, meaning a sasl handshake
  // is not expected at this point in the connection, or UNSUPPORTED_SASL_MECHANISM,
  // meaning the requested mechanism is not supported.
  ErrorCode: int16
  // SupportedMechanisms is the list of mechanisms supported if this request
  // errored.
  SupportedMechanisms: [string]

// ApiVersionsRequest requests what API versions a Kafka broker supports.
//
// Note that the client does not know the version a broker supports before
// sending this request.
//
// Before Kafka 2.4.0, if the client used a version larger than the broker
// understands, the broker would reply with an UNSUPPORTED_VERSION error using
// the version 0 message format (i.e., 6 bytes long!). The client should retry
// with a lower version.
//
// After Kafka 2.4.0, if the client uses a version larger than the broker
// understands, the broker replies with UNSUPPORTED_VERSIONS using the version
// 0 message format but additionally includes the api versions the broker does
// support.
ApiVersionsRequest => key 18, max version 3, flexible v3+
  // ClientSoftwareName, added for KIP-511 with Kafka 2.4.0, is the name of the
  // client issuing this request. The broker can use this to enrich its own
  // debugging information of which version of what clients are connected.
  //
  // If using v3, this field is required and must match the following pattern:
  //
  //     [a-zA-Z0-9](?:[a-zA-Z0-9\\-.]*[a-zA-Z0-9])?
  //
  ClientSoftwareName: string // v3+
  // ClientSoftwareVersion is the version of the software name in the prior
  // field. It must match the same regex (thus, this is also required).
  ClientSoftwareVersion: string // v3+

// ApiVersionsResponse is returned from an ApiVersionsRequest.
ApiVersionsResponse =>
  // ErrorCode is UNSUPPORTED_VERSION if the request was issued with a higher
  // version than the broker supports. Before Kafka 2.4.0, if this error is
  // returned, the rest of this struct will be empty.
  //
  // Starting in Kafka 2.4.0 (with version 3), even with an UNSUPPORTED_VERSION
  // error, the broker still replies with the ApiKeys it supports.
  ErrorCode: int16
  // ApiKeys is an array corresponding to API keys the broker supports
  // and the range of supported versions for each key.
  ApiKeys: [=>]
    // ApiKey is the key of a message request.
    ApiKey: int16
    // MinVersion is the min version a broker supports for an API key.
    MinVersion: int16
    // MaxVersion is the max version a broker supports for an API key.
    MaxVersion: int16
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+

// CreateTopicsRequest creates Kafka topics.
//
// Version 4, introduced in Kafka 2.4.0, implies client support for
// creation defaults. See KIP-464.
//
// Version 5, also in 2.4.0, returns topic configs in the response (KIP-525).
CreateTopicsRequest => key 19, max version 5, flexible v5+, admin
  // Topics is an array of topics to attempt to create.
  Topics: [=>]
    // Topic is a topic to create.
    Topic: string
    // NumPartitions is how many partitions to give a topic. This must
    // be -1 if specifying partitions manually (see ReplicaAssignment)
    // or, starting v4+, to use the broker default partitions.
    NumPartitions: int32
    // ReplicationFactor is how many replicas every partition must have.
    // This must be -1 if specifying partitions manually (see ReplicaAssignment)
    // or, starting v4+, to use the broker default replication factor.
    ReplicationFactor: int16
    // ReplicaAssignment is an array to manually dicate replicas and their
    // partitions for a topic. If using this, both ReplicationFactor and
    // NumPartitions must be -1.
    ReplicaAssignment: [=>]
      // Partition is a partition to create.
      Partition: int32
      // Replicas are broker IDs the partition must exist on.
      Replicas: [int32]
    // Configs is an array of key value config pairs for a topic.
    // These correspond to Kafka Topic-Level Configs: http://kafka.apache.org/documentation/#topicconfigs.
    Configs: [=>]
      // Name is a topic level config key (e.g. segment.bytes).
      Name: string
      // Value is a topic level config value (e.g. 1073741824)
      Value: nullable-string
  // TimeoutMillis is how long to allow for this request.
  TimeoutMillis: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no topics are actually created.
  ValidateOnly: bool // v1+

// CreateTopicsResponse is returned from a CreateTopicsRequest.
CreateTopicsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v2+
  // Topics contains responses to the requested topic creations.
  Topics: [=>]
    // Topic is the topic this response corresponds to.
    Topic: string
    // ErrorCode is the error code for an individual topic creation.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    //
    // INVALID_REQUEST is returned if the same topic occurred multiple times
    // in the request.
    //
    // POLICY_VIOLATION is returned if the broker is using a
    // create.topic.policy.class.name that returns a policy violation.
    //
    // INVALID_TOPIC_EXCEPTION if the topic collides with another topic when
    // both topic's names' periods are replaced with underscores (e.g.
    // topic.foo and topic_foo collide).
    //
    // TOPIC_ALREADY_EXISTS is returned if the topic already exists.
    //
    // INVALID_PARTITIONS is returned if the requested number of partitions is
    // <= 0.
    //
    // INVALID_REPLICATION_FACTOR is returned if the requested replication
    // factor is <= 0.
    //
    // INVALID_REPLICA_ASSIGNMENT is returned if not all partitions have the same
    // number of replicas, or duplica replicas are assigned, or the partitions
    // are not consecutive starting from 0.
    //
    // INVALID_CONFIG is returned if the requested topic config is invalid.
    // to create a topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string // v1+
    // ConfigErrorCode is non-zero if configs are unable to be returned.
    //
    // This is the first tagged field, introduced in version 5. As such, it is
    // only possible to be present in v5+.
    ConfigErrorCode: int16 // tag 0
    // NumPartitions is how many partitions were created for this topic.
    NumPartitions: int32 // v5+
    // ReplicationFactor is how many replicas every partition has for this topic.
    ReplicationFactor: int16 // v5+
    // Configs contains this topic's configuration.
    Configs: nullable[=>] // v5+
      // Name is the configuration name (e.g. segment.bytes).
      Name: string
      // Value is the value for this config key. If the key is sensitive,
      // the value will be null.
      Value: nullable-string
      // ReadOnly signifies whether this is not a dynamic config option.
      ReadOnly: bool
      // Source is where this config entry is from. See the documentation
      // on DescribeConfigsRequest's Source for more details.
      Source: int8
      // IsSensitive signifies whether this is a sensitive config key, which
      // is either a password or an unknown type.
      IsSensitive: bool

// DeleteTopicsRequest deletes Kafka topics.
DeleteTopicsRequest => key 20, max version 4, flexible v4+, admin
  // Topics is an array of topics to delete.
  Topics: [string]
  // TimeoutMillis is the millisecond timeout of this request.
  TimeoutMillis: int32

// DeleteTopicsResponse is returned from a DeleteTopicsRequest.
// Version 3 added the TOPIC_DELETION_DISABLED error proposed in KIP-322
// and introduced in Kafka 2.1.0. Prior, the request timed out.
DeleteTopicsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32 // v1+
  // Topics contains responses for each topic requested for deletion.
  Topics: [=>]
    // Topic is the topic requested for deletion.
    Topic: string
    // ErrorCode is the error code returned for an individual topic in
    // deletion request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a topic.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_DELETION_DISABLED is returned for deletion requests version 3+
    // and brokers >= 2.1.0. INVALID_REQUEST is issued for request versions
    // 0-2 against brokers >= 2.1.0. Otherwise, the request hangs until it
    // times out.
    ErrorCode: int16

// DeleteRecordsRequest is an admin request to delete records from Kafka.
// This was added for KIP-107.
//
// To delete records, Kafka sets the LastStableOffset for partitions to
// the requested offset. All segments whose max partition is before the
// requested offset are deleted, and any records within the segment before
// the requested offset can no longer be read.
DeleteRecordsRequest => key 21, max version 1
  // Topics contains topics for which to delete records from.
  Topics: [=>]
    // Topic is a topic to delete records from.
    Topic: string
    // Partitions contains partitions to delete records from.
    Partitions: [=>]
      // Partition is a partition to delete records from.
      Partition: int32
      // Offset is the offset to set the partition's low watermark (start
      // offset) to. After a successful response, all records before this
      // offset are considered deleted and are no longer readable.
      //
      // To delete all records, use -1, which is mapped to the partition's
      // current high watermark.
      Offset: int64
  // TimeoutMillis is how long to wait for a response before Kafka will return.
  // Kafka waits for all replicas to respond to the delete reords request;
  // any partition that all replicas do not reply to within this limit will
  // have a timeout error.
  TimeoutMillis: int32

// DeleteRecordsResponse is returned from a DeleteRecordsRequest.
DeleteRecordsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Topics contains responses for each topic in the delete records request.
  Topics: [=>]
    // Topic is the topic this response corresponds to.
    Topic: string
    // Partitions contains responses for each partition in a requested topic
    // in the delete records request.
    Partitions: [=>]
      // Partition is the partition this response corresponds to.
      Partition: int32
      // LowWatermark is the new earliest offset for this partition.
      LowWatermark: int64
      // ErrorCode is the error code returned for a given partition in
      // the delete request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all partitions if the
      // client is not authorized to delete records.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned for all partitions that
      // the requested broker does not know of.
      //
      // NOT_LEADER_FOR_PARTITION is returned for partitions that the
      // requested broker is not a leader of.
      //
      // OFFSET_OUT_OF_RANGE is returned if the requested offset is
      // negative or higher than the current high watermark.
      //
      // POLICY_VIOLATION is returned if records cannot be deleted due to
      // broker configuration.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the partition is in an
      // offline log directory.
      ErrorCode: int16

// InitProducerIDRequest initializes a producer ID for idempotent transactions,
// and if using transactions, a producer epoch. This is the first request
// necessary to begin idempotent producing or transactions.
InitProducerIDRequest => key 22, max version 2, flexible v2+, txn coordinator
  // TransactionalID is the ID to use for transactions if using transactions.
  TransactionalID: nullable-string
  // TransactionTimeoutMillis is how long a transaction is allowed before
  // EndTxn is required.
  //
  // Note that this timeout only begins on the first AddPartitionsToTxn
  // request.
  TransactionTimeoutMillis: int32

// InitProducerIDResponse is returned for an InitProducerIDRequest.
InitProducerIDResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // CLUSTER_AUTHORIZATION_FAILED is returned when not using transactions if
  // the client is not authorized for idempotent_write on cluster.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned when using transactions
  // if the client is not authorized to write on transactional_id.
  //
  // INVALID_REQUEST is returned if using transactions and the transactional id
  // is an empty, non-null string
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the coordinator for this
  // transactional ID is still loading.
  //
  // NOT_COORDINATOR is returned if the broker is not the coordinator for
  // this transactional ID.
  //
  // INVALID_TRANSACTION_TIMEOUT is returned if using transactions and the timeout
  // is equal to over over transaction.max.timeout.ms or under 0.
  //
  // CONCURRENT_TRANSACTIONS is returned if there is an ongoing transaction
  // that is completing at the time this init is called.
  ErrorCode: int16
  // ProducerID is the next producer ID that Kafka generated. This ID is used
  // to ensure repeated produce requests do not result in duplicate records.
  ProducerID: int64
  // ProducerEpoch is the producer epoch to use for transactions.
  ProducerEpoch: int16

// OffsetForLeaderEpochRequest requests log end offsets for partitions.
//
// Version 2, proposed in KIP-320 and introduced in Kafka 2.1.0, can be used by
// consumers to perform more accurate offset resetting in the case of data loss.
//
// In support of version 2, this requires DESCRIBE on TOPIC.
OffsetForLeaderEpochRequest => key 23, max version 3
  // ReplicaID, added in support of KIP-392, is the broker ID of the follower,
  // or -1 if this request is from a consumer.
  ReplicaID: int32 // v3+
  // Topics are topics to fetch leader epoch offsets for.
  Topics: [=>]
    // Topic is the name of a topic.
    Topic: string
    // Partitions are partitions within a topic to fetch leader epoch offsets for.
    Partitions: [=>]
      // Partition is the number of a partition.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or if the client is ahead of the broker.
      //
      // The initial leader epoch can be determined from a MetadataResponse.
      CurrentLeaderEpoch: int32 // v2+
      // LeaderEpoch is the epoch to fetch the end offset for.
      LeaderEpoch: int32

// OffsetForLeaderEpochResponse is returned from an OffsetForLeaderEpochRequest.
OffsetForLeaderEpochResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  ThrottleMillis: int32 // v2+
  // Topics are responses to topics in the request.
  Topics: [=>]
    // Topic is the topic this response corresponds to.
    Topic: string
    // Partitions are responses to partitions in a topic in the request.
    Partitions: [=>]
      // ErrorCode is the error code returned on request failure.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client does not have
      // the necessary permissions to issue this request.
      //
      // KAFKA_STORAGE_ERROR is returned if the partition is offline.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker knows of the partition
      // but does not own it.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of the
      // partition.
      //
      // FENCED_LEADER_EPOCH is returned if the client is using a current leader epoch
      // older than the actual leader epoch.
      //
      // UNKNOWN_LEADER_EPOCH if returned if the client is using a current leader epoch
      // that the actual leader does not know of. This could occur when the client
      // has newer metadata than the broker when the broker just became the leader for
      //  a replica.
      ErrorCode: int16
      // Partition is the partition this response is for.
      Partition: int32
      // LeaderEpoch is similar to the requested leader epoch, but pairs with the
      // next field. If the requested leader epoch is unknown, this is -1. If the
      // requested epoch had no records produced during the requested epoch, this
      // is the first prior epoch that had records.
      LeaderEpoch: int32
      // EndOffset is either (1) just past the last recorded offset in the
      // current partition if the broker leader has the same epoch as the
      // leader epoch in the request, or (2) the beginning offset of the next
      // epoch if the leader is past the requested epoch. The second scenario
      // can be seen as equivalent to the first: the beginning offset of the
      // next epoch is just past the final offset of the prior epoch.
      //
      // (2) allows consumers to detect data loss: if the consumer consumed
      // past the end offset that is returned, then the consumer should reset
      // to the returned offset and the consumer knows everything past the end
      // offset was lost.
      //
      // With the prior field, consumers know that at this offset, the broker
      // either has no more records (consumer is caught up), or the broker
      // transitioned to a new epoch.
      EndOffset: int64

// AddPartitionsToTxnRequest begins the producer side of a transaction for all
// partitions in the request. Before producing any records to a partition in
// the transaction, that partition must have been added to the transaction with
// this request.
AddPartitionsToTxnRequest => key 24, max version 1, txn coordinator
  // TransactionalID is the transactional ID to use for this request.
  TransactionalID: string
  // ProducerID is the producer ID of the client for this transactional ID
  // as received from InitProducerID.
  ProducerID: int64
  // ProducerEpoch is the producer epoch of the client for this transactional ID
  // as received from InitProducerID.
  ProducerEpoch: int16
  // Topics are topics to add as part of the producer side of a transaction.
  Topics: [=>]
    // Topic is a topic name.
    Topic: string
    // Partitions are partitions within a topic to add as part of the producer
    // side of a transaction.
    Partitions: [int32]

// AddPartitionsToTxnResponse is a response to an AddPartitionsToTxnRequest.
AddPartitionsToTxnResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Topics are responses to topics in the request.
  Topics: [=>]
    // Topic is a topic being responded to.
    Topic: string
    // Partitions are responses to partitions in the request.
    Partitions: [=>]
      // Partition is a partition being responded to.
      Partition: int32
      // ErrorCode is any error for this topic/partition commit.
      //
      // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned if the client is
      // not authorized for write with transactional IDs with the requested
      // transactional ID.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all topics that the client
      // is not authorized to write to.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned for all topics or partitions
      // that the broker does not know of.
      //
      // OPERATION_NOT_ATTEMPTED is returned if any of the above errors occur
      // for all partitions that did not have the above errors.
      //
      // INVALID_REQUEST is returned if the transactional ID is invalid.
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the coordinator for this
      // transactional ID is still loading.
      //
      // NOT_COORDINATOR is returned if the broker is not the coordinator for
      // this transactional ID.
      //
      // INVALID_PRODUCER_ID_MAPPING is returned if the produce request used
      // a producer ID that is not tied to the transactional ID (i.e., mismatch
      // from what was returned from InitProducerID).
      //
      // INVALID_PRODUCER_EPOCH is returned if the requested epoch does not match
      // the broker epoch for this transactional ID.
      //
      // CONCURRENT_TRANSACTIONS is returned if there is an ongoing transaction for
      // this transactional ID, if the producer ID and epoch matches the broker's.
      ErrorCode: int16

// AddOffsetsToTxnRequest is a request that ties produced records to what group
// is being consumed for the transaction.
//
// This request must be called before TxnOffsetCommitRequest.
//
// Internally, this request simply adds the __consumer_offsets topic as a
// partition for this transaction with AddPartitionsToTxn for the partition
// in that topic that contains the group.
AddOffsetsToTxnRequest => key 25, max version 1, txn coordinator
  // TransactionalID is the transactional ID to use for this request.
  TransactionalID: string
  // ProducerID is the producer ID of the client for this transactional ID
  // as received from InitProducerID.
  ProducerID: int64
  // ProducerEpoch is the producer epoch of the client for this transactional ID
  // as received from InitProducerID.
  ProducerEpoch: int16
  // Group is the group to tie this transaction to.
  Group: string

// AddOffsetsToTxnResponse is a response to an AddOffsetsToTxnRequest.
AddOffsetsToTxnResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // ErrorCode is any error for this topic/partition commit.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned if the client is
  // not authorized for write with transactional IDs with the requested
  // transactional ID.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to read group with the requested group id.
  //
  // This also can return any error that AddPartitionsToTxn returns.
  ErrorCode: int16

// EndTxnRequest ends a transaction. This should be called after
// TxnOffsetCommitRequest.
EndTxnRequest => key 26, max version 1, txn coordinator
  // TransactionalID is the transactional ID to use for this request.
  TransactionalID: string
  // ProducerID is the producer ID of the client for this transactional ID
  // as received from InitProducerID.
  ProducerID: int64
  // ProducerEpoch is the producer epoch of the client for this transactional ID
  // as received from InitProducerID.
  ProducerEpoch: int16
  // Commit is whether to commit this transaction: true for yes, false for abort.
  Commit: bool

// EndTxnResponse is a response for an EndTxnRequest.
EndTxnResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // ErrorCode is any error for this topic/partition commit.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned if the client is
  // not authorized for write with transactional IDs with the requested
  // transactional ID.
  //
  // INVALID_REQUEST is returned if the transactional ID is invalid.
  //
  // INVALID_PRODUCER_ID_MAPPING is returned if the produce request used
  // a producer ID that is not tied to the transactional ID (i.e., mismatch
  // from what was returned from InitProducerID).
  //
  // INVALID_PRODUCER_EPOCH is returned if the requested epoch does not match
  // the broker epoch for this transactional ID.
  //
  // CONCURRENT_TRANSACTIONS is returned if there is an ongoing transaction for
  // this transactional ID, if the producer ID and epoch matches the broker's.
  //
  // INVALID_TXN_STATE is returned if this request is attempted at the wrong
  // time (given the order of how transaction requests should go).
  ErrorCode: int16

// WriteTxnMarkersRequest is a broker-to-broker request that Kafka uses to
// finish transactions. Since this is specifically for inter-broker
// communication, this is left undocumented.
WriteTxnMarkersRequest => key 27, max version 0
  Markers: [=>]
    ProducerID: int64
    ProducerEpoch: int16
    Committed: bool
    Topics: [=>]
      Topic: string
      Partitions: [int32]
    CoordinatorEpoch: int32

// WriteTxnMarkersResponse is a response to a WriteTxnMarkersRequest.
WriteTxnMarkersResponse =>
  Markers: [=>]
    ProducerID: int64
    Topics: [=>]
      Topic: string
      Partitions: [=>]
        Partition: int32
        ErrorCode: int16

// TxnOffsetCommitRequest sends offsets that are a part of this transaction
// to be committed once the transaction itself finishes. This effectively
// replaces OffsetCommitRequest for when using transactions.
TxnOffsetCommitRequest => key 28, max version 2, group coordinator
  // TransactionalID is the transactional ID to use for this request.
  TransactionalID: string
  // Group is the group consumed in this transaction and to be used for
  // committing.
  Group: string
  // ProducerID is the producer ID of the client for this transactional ID
  // as received from InitProducerID.
  ProducerID: int64
  // ProducerEpoch is the producer epoch of the client for this transactional ID
  // as received from InitProducerID.
  ProducerEpoch: int16
  // Topics are topics to add for pending commits.
  Topics: [=>]
    // Topic is a topic to add for a pending commit.
    Topic: string
    // Partitions are partitions to add for pending commits.
    Partitions: [=>]
      // Partition is a partition to add for a pending commit.
      Partition: int32
      // Offset is the offset within partition to commit once EndTxnRequest is
      // called (with commit; abort obviously aborts).
      Offset: int64
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be determined from a MetadataResponse.
      // To skip log truncation checking, use -1.
      LeaderEpoch: int32 // v2+
      // Metadata is optional metadata the client wants to include with this
      // commit.
      Metadata: nullable-string

// TxnOffsetCommitResponse is a response to a TxnOffsetCommitRequest.
TxnOffsetCommitResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Topics contains responses to the topics in the request.
  Topics: [=>]
    // Topic is the topic this response is for.
    Topic: string
    // Partitions contains responses to the partitions in this topic.
    Partitions: [=>]
      // Partition is the partition this response is for.
      Partition: int32
      // ErrorCode is any error for this topic/partition commit.
      //
      // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned if the client is
      // not authorized for write with transactional IDs with the requested
      // transactional ID.
      //
      // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to read group with the requested group id.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all topics that the client
      // is not authorized to read.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned for all topics or partitions
      // that the broker does not know of.
      //
      // INVALID_GROUP_ID is returned if the requested group does not exist.
      //
      // COORDINATOR_NOT_AVAILABLE is returned if the broker is not yet fully
      // started or is shutting down, or if the group was just deleted or is
      // migrating to another broker.
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is still loading.
      //
      // NOT_COORDINATOR is returned if the broker is not the coordinator for
      // the group.
      //
      // FENCED_INSTANCE_ID is returned if the member is fenced (another newer
      // transactional member is using the same instance ID).
      //
      // UNKNOWN_MEMBER_ID is returned if the consumer group does not know of
      // this member.
      //
      // ILLEGAL_GENERATION is returned if the consumer group's generation is
      // different than the requested generation.
      //
      // OFFSET_METADATA_TOO_LARGE is returned if the commit metadata is too
      // large.
      //
      // REBALANCE_IN_PROGRESS is returned if the group is completing a rebalance.
      ErrorCode: int16

// DescribeACLsRequest describes ACLs. Describing ACLs works on a filter basis:
// anything that matches the filter is described. Note that there are two
// "types" of filters in this request: the resource filter and the entry
// filter, with entries corresponding to users. The first three fields form the
// resource filter, the last four the entry filter.
DescribeACLsRequest => key 29, max version 1, admin
  // ResourceType is the type of resource to describe.
  //
  // UNKNOWN, 0, is unknown; you do not describe unknown types. Kafka replies
  // with unknown if it does not understand your type. ANY, 1 will match any
  // other type.
  //
  // Past these two, the following types filter for an individual type:
  // TOPIC is 2, GROUP is 3, CLUSTER is 4, TRANSACTIONAL_ID is 5, and
  // DELEGATION_TOKEN is 6.
  ResourceType: int8
  // ResourceName is the name to filter out. For the CLUSTER resource type,
  // this must be "kafka-cluster".
  ResourceName: nullable-string
  // ResourcePatternType is how ResourceName is understood. UNKNOWN is 0 and is
  // meaningless in the request.
  //
  // MATCH is 1, which will match anything.
  //
  // LITERAL is 2, meaning the name must be an exact match.
  //
  // PREFIXED is 3, meaning a resource name must have our requested resource
  // name as a prefix. That is, topic "foobar" will match "foo".
  //
  // This field was added with Kafka 2.0.0 for KIP-290; the default during
  // creating is 2.
  ResourcePatternType: int8 // v1+
  // Principal is the user to filter for. In Kafka with the simple authorizor,
  // all principals begin with "User:". Pluggable authorizors are allowed, but
  // Kafka still expects principals to lead with a principal type ("User") and
  // have a colon separating the principal name ("bob" in "User:bob").
  Principal: nullable-string
  // Host is a host to filter for.
  Host: nullable-string
  // Operation is an operation to filter for. UNKNOWN is 0.
  //
  // ANY is 1 and matches anything, otherwise... ALL is 2 and matches anything
  // granted ALL permissions, READ is 3, WRITE is 4, CREATE is 5, DELETE is 6,
  // ALTER is 7 DESCRIBE is 8, CLUSTER_ACTION is 9, DESCRIBE_CONFIGS is 10,
  // ALTER_CONFIGS is 11, and IDEMPOTENT_WRITE is 12.
  //
  // Note that READ, WRITE, DELETE, and ALTER imply DESCRIBE, and ALTER_CONFIGS
  // implies DESCRIBE_CONFIGS.
  Operation: int8
  // PermissionType is the permission type to filter for. UNKNOWN is 0.
  //
  // ANY is 1 and matches anything, otherwise DENY (2) matches all deny
  // permissions and ALLOW (3) matches all allow permissions.
  PermissionType: int8

// DescribeACLsResponse is a response to a describe acls request.
DescribeACLsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // ErrorCode is the error code returned on request failure.
  //
  // SECURITY_DISABLED is returned if there is no authorizer configured on the
  // broker.
  //
  // There can be other authorization failures.
  ErrorCode: int16
  // ErrorMessage is a message for an error.
  ErrorMessage: nullable-string
  // Resources are the describe resources.
  Resources: [=>]
    // ResourceType is the resource type being described.
    ResourceType: int8
    // ResourceName is the resource name being described.
    ResourceName: string
    // ResourcePatternType is the pattern type being described.
    ResourcePatternType: int8 // v1+
    // ACLs contains users / entries being described.
    ACLs: [=>]
      // Principal is who this ACL applies to.
      Principal: string
      // Host is on which host this ACL applies.
      Host: string
      // Operation is the operation being described.
      Operation: int8
      // PermissionType is the permission being described.
      PermissionType: int8

// CreateACLsRequest creates acls. Creating acls can be done as a batch; each
// "creation" will be an acl entry.
//
// See the DescribeACLsRequest documentation for more descriptions of what
// valid values for the fields in this request are.
CreateACLsRequest => key 30, max version 1, admin
  Creations: [=>]
    // ResourceType is the type of resource this acl entry will be on.
    // It is invalid to use UNKNOWN or ANY.
    ResourceType: int8
    // ResourceName is the name of the resource this acl entry will be on.
    // For CLUSTER, this must be "kafka-cluster".
    ResourceName: string
    // ResourcePatternType is the pattern type to use for the resource name.
    // This cannot be UNKNOWN or MATCH (i.e. this must be LITERAL or PREFIXED).
    // The default for pre-Kafka 2.0.0 is effectively LITERAL.
    ResourcePatternType: int8 // v1+
    // Principal is the user to apply this acl for. With the Kafka simple
    // authorizer, this must begin with "User:".
    Principal: string
    // Host is the host address to use for this acl. Yes, each host to allow
    // the principal access from must be specified as a new creation. KIP-252
    // might solve this someday. The special wildcard host "*" allows all hosts.
    Host: string
    // Operation is the operation this acl is for. This must not be UNKNOWN or
    // ANY.
    Operation: int8
    // PermissionType is the permission of this acl. This must be either ALLOW
    // or DENY.
    PermissionType: int8

// CreateACLsResponse is a response for a CreateACLsRequest.
CreateACLsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // Results contains responses to each creation request.
  Results: [=>]
    // ErrorCode is an error for this particular creation (index wise).
    ErrorCode: int16
    // ErrorMessage is a message for this error.
    ErrorMessage: nullable-string

// DeleteACLsRequest deletes acls. This request works on filters the same way
// that DescribeACLsRequest does. See DescribeACLsRequest for documentation of
// the fields.
DeleteACLsRequest => key 31, max version 1, admin
  // Filters are filters for acls to delete.
  Filters: [=>]
    ResourceType: int8
    ResourceName: nullable-string
    ResourcePatternType: int8 // v1+
    Principal: nullable-string
    Host: nullable-string
    Operation: int8
    PermissionType: int8

// DeleteACLsResponse is a response for a DeleteACLsRequest.
DeleteACLsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // Results contains a response to each requested filter.
  Results: [=>]
    // ErrorCode is the overall error code for this individual filter.
    ErrorCode: int16
    // ErrorMessage is a message for this error.
    ErrorMessage: nullable-string
    // MatchingACLs contains all acls that were matched for this filter.
    MatchingACLs: [=>]
      // ErrorCode contains an error for this individual acl for this filter.
      ErrorCode: int16
      // ErrorMessage is a message for this error.
      ErrorMessage: nullable-string
      ResourceType: int8
      ResourceName: string
      ResourcePatternType: int8 // v1+
      Principal: string
      Host: string
      Operation: int8
      PermissionType: int8

// DescribeConfigsRequest issues a request to describe configs that Kafka
// currently has. These are the key/value pairs that one uses to configure
// brokers and topics.
DescribeConfigsRequest => key 32, max version 2, admin
  // Resources is a list of resources to describe.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to describe.
    // Valid values are 2 (topic), 4 (broker), or 8 (broker logger).
    ResourceType: int8
    // ResourceName is the name of config to describe.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // returns all broker configs, but only the dynamic configuration values.
    // If a specific ID, this returns all broker config values.
    ResourceName: string
    // ConfigNames is a list of config entries to return. Null requests all.
    ConfigNames: nullable[string]
  // IncludeSynonyms signifies whether to return config entry synonyms for
  // all config entries.
  IncludeSynonyms: bool // v1+

// DescribeConfigsResponse is returned from a DescribeConfigsRequest.
DescribeConfigsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Resources are responses for each resource in the describe config request.
  Resources: [=>]
    // ErrorCode is the error code returned for describing configs.
    //
    // INVALID_REQUEST is returned if asking to descibe an invalid resource
    // type.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to describe broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to describe topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the describe config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of described config.
    ResourceType: int8
    // ResourceName is the name corresponding to the describe config request.
    ResourceName: string
    // Configs contains information about key/value config pairs for
    // the requested resource.
    Configs: [=>]
      // Name is a key this entry corresponds to (e.g. segment.bytes).
      Name: string
      // Value is the value for this config key. If the key is sensitive,
      // the value will be null.
      Value: nullable-string
      // ReadOnly signifies whether this is not a dynamic config option.
      ReadOnly: bool
      // IsDefault is whether this is a default config option. This has been
      // replaced in favor of Source.
      IsDefault: bool // v0-v0
      // Source is where this config entry is from. Note that if there
      // are no config synonyms, the source is DEFAULT_CONFIG. The values of
      // this enum are as follows.
      //
      // UNKNOWN (0): unknown; e.g. an altar request was issued with no source set
      //
      // DYNAMIC_TOPIC_CONFIG (1): dynamic topic config for a specific topic
      //
      // DYNAMIC_BROKER_CONFIG (2): dynamic broker config for a specific broker
      //
      // DYNAMIC_DEFAULT_BROKER_CONFIG (3): dynamic broker config used as the default for all brokers in a cluster
      //
      // STATIC_BROKER_CONFIG (4): static broker config provided at start up
      //
      // DEFAULT_CONFIG (5): built-in default configuration for those that have defaults
      //
      // DYNAMIC_BROKER_LOGGER_CONFIG (6): broker logger; see KIP 412.
      Source: int8 // v1+
      // IsSensitive signifies whether this is a sensitive config key, which
      // is either a password or an unknown type.
      IsSensitive: bool
      // ConfigSynonyms contains config key/value pairs that can be used in
      // place of this config entry, in order of preference.
      ConfigSynonyms: [=>] // v1+
        Name: string
        Value: nullable-string
        Source: int8

// AlterConfigsRequest issues a request to alter either topic or broker
// configs.
//
// Note that to alter configs, you must specify the whole config on every
// request. All existing non-static values will be removed. This means that
// to add one key/value to a config, you must describe the config and then
// issue an alter request with the current config with the new key value.
// This also means that dynamic sensitive values, which are not returned
// in describe configs, will be lost.
//
// To fix this problem, the AlterConfigs request / response was deprecated
// in Kafka 2.3.0 in favor of the new IncrementalAlterConfigs request / response.
// See KIP-339 for more details.
AlterConfigsRequest => key 33, max version 1, admin
  // Resources is an array of configs to alter.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to alter.
    // The possible valid values are 2 (for topic), 4 (for broker),
    // and 8 (for broker logger).
    ResourceType: int8
    // ResourceName is the name of config to alter.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // updates all broker configs. If a specific ID, this updates just the
    // broker. Using a specific ID also ensures that brokers reload config
    // or secret files even if the file path has not changed. Lastly, password
    // config options can only be defined on a per broker basis.
    //
    // If the type is broker logger, this must be a broker ID.
    ResourceName: string
    // Configs contains key/value config pairs to set on the resource.
    Configs: [=>]
      // Name is a key to set (e.g. segment.bytes).
      //
      // For broker loggers, see KIP-412 section "Request/Response Overview"
      // for details on how to change per logger log levels.
      Name: string
      // Value is a value to set for the key (e.g. 10).
      Value: nullable-string
  // ValidateOnly validates the request but does not apply it.
  ValidateOnly: bool

// AlterConfigsResponse is returned from an AlterConfigsRequest.
AlterConfigsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Resources are responses for each resource in the alter request.
  Resources: [=>]
    // ErrorCode is the error code returned for altering configs.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    //
    // INVALID_REQUEST is returned if the requested config is invalid or if
    // asking Kafka to alter an invalid resource.
    ErrorCode: int16
    // ErrorMessage is an informative message if the alter config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of altered config.
    ResourceType: int8
    // ResourceName is the name corresponding to the alter config request.
    ResourceName: string

// AlterReplicaLogDirsRequest requests for log directories to be moved
// within Kafka.
//
// This is primarily useful for moving directories between disks.
AlterReplicaLogDirsRequest => key 34, max version 1, admin
  // Dirs contains absolute paths of where you want things to end up.
  Dirs: [=>]
    // Dir is an absolute path where everything listed below should
    // end up.
    Dir: string
    // Topics contains topics to move to the above log directory.
    Topics: [=>]
      // Topic is a topic to move.
      Topic: string
      // Partitions contains partitions for the topic to move.
      Partitions: [int32]

// AlterReplicaLogDirsResponse is returned from an AlterReplicaLogDirsRequest.
AlterReplicaLogDirsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Topics contains responses to each topic that had partitions requested
  // for moving.
  Topics: [=>]
    // Topic is the topic this array slot corresponds to.
    Topic: string
    // Partitions contains responses to each partition that was requested
    // to move.
    Partitions: [=>]
      // Partition is the partition this array slot corresponds to.
      Partition: int32
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to alter replica dirs.
      //
      // LOG_DIR_NOT_FOUND is returned when the requested log directory
      // is not in the broker config.
      //
      // KAFKA_STORAGE_EXCEPTION is returned when destination directory or
      // requested replica is offline.
      //
      // REPLICA_NOT_AVAILABLE is returned if the replica does not exist
      // yet.
      ErrorCode: int16

// DescribeLogDirsRequest requests directory information for topic partitions.
// This request was added in support of KIP-113.
DescribeLogDirsRequest => key 35, max version 1, admin
  // Topics is an array of topics to describe the log dirs of. If this is
  // null, the response includes all topics and all of their partitions.
  Topics: nullable[=>]
    // Topic is a topic to describe the log dir of.
    Topic: string
    // Partitions contains topic partitions to describe the log dirs of.
    Partitions: [int32]

// DescribeLogDirsResponse is returned from a DescribeLogDirsRequest.
DescribeLogDirsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Dirs pairs log directories with the topics and partitions that are
  // stored in those directores.
  Dirs: [=>]
    // ErrorCode is the error code returned for descrbing log dirs.
    //
    // KAFKA_STORAGE_ERROR is returned if the log directoy is offline.
    ErrorCode: int16
    // Dir is the absolute path of a log directory.
    Dir: string
    // Topics is an array of topics within a log directory.
    Topics: [=>]
      // Topic is the name of a Kafka topic.
      Topic: string
      // Partitions is the set of queried partitions for a topic that are
      // within a log directory.
      Partitions: [=>]
        // Partition is a partition ID.
        Partition: int32
        // Size is the total size of the log sements of this partition, in bytes.
        Size: int64
        // OffsetLag is how far behind the log end offset is compared to
        // the partition's high watermark (if this is the current log for
        // the partition) or compared to the current replica's log end
        // offset (if this is the future log for the patition).
        //
        // The math is,
        //
        // if IsFuture, localLogEndOffset - futurelogEndOffset.
        //
        // otherwise, max(localHighWatermark - logEndOffset, 0).
        OffsetLag: int64
        // IsFuture is true if this replica was created by an
        // AlterReplicaLogDirsRequest and will replace the current log of the
        // replica in the future.
        IsFuture: bool

// SASLAuthenticate continues a sasl authentication flow. Prior to Kafka 1.0.0,
// authenticating with sasl involved sending raw blobs of data back and forth.
// After, those blobs are wrapped in a SASLAuthenticateRequest The benefit of
// this wrapping is that Kafka can indicate errors in the response, rather than
// just closing the connection. Additionally, the response allows for further
// extension fields.
SASLAuthenticateRequest => key 36, max version 1
  // SASLAuthBytes contains bytes for a SASL client request.
  SASLAuthBytes: bytes

// SASLAuthenticateResponse is returned for a SASLAuthenticateRequest.
SASLAuthenticateResponse =>
  // ErrorCode is a potential error.
  ErrorCode: int16
  // ErrorMessage can contain a message for an error.
  ErrorMessage: nullable-string
  // SASLAuthBytes is the server challenge continuing SASL flow.
  SASLAuthBytes: bytes
  // SessionLifetimeMillis, added in Kafka 2.2.0, is how long the SASL
  // authentication is valid for. This timeout is only enforced if the request
  // was v1. After this timeout, Kafka expects the next bytes on the wire to
  // begin reauthentication. Otherwise, Kafka closes the connection.
  SessionLifetimeMillis: int64 // v1+

// CreatePartitionsRequest creates additional partitions for topics.
CreatePartitionsRequest => key 37, max version 1, admin
  // Topics contains topics to create partitions for.
  Topics: [=>]
    // Topic is a topic for which to create additional partitions for.
    Topic: string
    // Count is the final count of partitions this topic must have after this
    // request. This must be greater than the current number of partitions.
    Count: int32
    // Assignment is a two-level array, the first corresponding to new
    // partitions, the second contining broker IDs for where new partition
    // replicas should live.
    //
    // The second level, the replicas, cannot have duplicate broker IDs (i.e.
    // you cannot replicate a single partition twice on the same broker).
    // Additionally, the number of replicas must match the current number of
    // replicas per partition on the topic.
    //
    // The first level's length must be equal to the delta of Count and the
    // current number of partitions.
    Assignment: nullable[=>]
      // Replicas are replicas to assign a new partition to.
      Replicas: [int32]
  // TimeoutMillis is how long to allow for this request.
  TimeoutMillis: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no partitions are actually created.
  ValidateOnly: bool

// CreatePartitionsResponse is returned from a CreatePartitionsRequest.
CreatePartitionsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Topics is a response to each topic in the creation request.
  Topics: [=>]
    // Topic is the topic that partitions were requested to be made for.
    Topic: string
    // ErrorCode is the error code returned for each topic in the request.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to create partitions for a topic.
    //
    // INVALID_REQUEST is returned for duplicate topics in the request.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the topic is queued for deletion.
    //
    // REASSIGNMENT_IN_PROGRESS is returned if the request was issued while
    // partitions were being reassigned.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic for which to create partitions.
    //
    // INVALID_PARTITIONS is returned if the request would drop the total
    // count of partitions down, or if the request would not add any more
    // partitions, or if the request uses unknown brokers, or if the request
    // assigns a different number of brokers than the increase in the
    // partition count.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string

// CreateDelegationTokenRequest issues a request to create a delegation token.
//
// Creating delegation tokens allows for an (ideally) quicker and easier method
// of enabling authorization for a wide array of clients. Rather than having to
// manage many passwords external to Kafka, you only need to manage a few
// accounts and use those to create delegation tokens per client.
//
// Note that delegation tokens inherit the same ACLs as the user creating the
// token. Thus, if you want to properly scope ACLs, you should not create
// delegation tokens with admin accounts.
//
// Delegation tokens live inside of Kafka and use SASL SCRAM-SHA-256 for
// authorization.
CreateDelegationTokenRequest => key 38, max version 2, flexible v2+, admin
  // Renewers is a list of who can renew this delegation token. If empty, the
  // default is the principal (user) who created the token.
  Renewers: [=>]
    // PrincipalType is the "type" this principal is. This must be "User".
    PrincipalType: string
    // PrincipalName is the user name allowed to renew the returned token.
    PrincipalName: string
  // MaxLifetimeMillis is how long this delegation token will be valid for.
  // If -1, the default will be the server's delegation.token.max.lifetime.ms.
  MaxLifetimeMillis: int64

// CreateDelegationTokenResponse is a response to a CreateDelegationTokenRequest.
CreateDelegationTokenResponse =>
  // ErrorCode is any error that caused the request to fail.
  ErrorCode: int16
  // PrincipalType is the type of principal that granted this delegation token.
  // This will always be "User" with the simple authorizer.
  PrincipalType: string
  // PrincipalName is the name of the principal that granted this delegation
  // token.
  PrincipalName: string
  // IssueTimestamp is the millisecond timestamp this delegation token was
  // issued.
  IssueTimestamp: int64
  // ExpiryTimestamp is the millisecond timestamp this token will expire. The
  // token can be renewed up to MaxTimestamp, past which point, it will be
  // invalid. The Kafka default is 24h.
  ExpiryTimestamp: int64
  // MaxTimestamp is the millisecond timestamp past which this token cannot
  // be renewed.
  MaxTimestamp: int64
  // TokenID is the ID of this token; this will be used as the username for
  // scram authentication.
  TokenID: string
  // HMAC is the password of this token; this will be used as the password for
  // scram authentication.
  HMAC: bytes
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32

// RenewDelegationTokenRequest is a request to renew a delegation token that
// has not yet hit its max timestamp. Note that a client using a token cannot
// renew its own token.
RenewDelegationTokenRequest => key 39, max version 1, admin
  // HMAC is the HMAC of the token to be renewed.
  HMAC: bytes
  // RenewTimeMillis is how long to renew the token for. If -1, Kafka uses its
  // delegation.token.max.lifetime.ms.
  RenewTimeMillis: int64

// RenewDelegationTokenResponse is a response to a RenewDelegationTokenRequest.
RenewDelegationTokenResponse =>
  // ErrorCode is any error that caused the request to fail.
  ErrorCode: int16
  // ExpiryTimestamp is the millisecond timestamp this token will expire. The
  // token can be renewed up to MaxTimestamp, past which point, it will be
  // invalid. The Kafka default is 24h.
  ExpiryTimestamp: int64
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32

// ExpireDelegationTokenRequest is a request to change the expiry timestamp
// of a delegation token. Note that a client using a token cannot expire its
// own token.
ExpireDelegationTokenRequest => key 40, max version 1, admin
  // HMAC is the HMAC of the token to change the expiry timestamp of.
  HMAC: bytes
  // ExpiryPeriodMillis changes the delegation token's expiry timestamp to
  // now + expiry time millis. This can be used to force tokens to expiry
  // quickly, or to allow tokens a grace period before expiry. This can only
  // change the final expiry timestamp down; you cannot add enough time that
  // would increase the expiry timestamp.
  //
  // Note that you can change the expiry timestamp down and then back up, so
  // long as you change it back up before the timestamp expires.
  ExpiryPeriodMillis: int64

// ExpireDelegationTokenResponse is a response to an ExpireDelegationTokenRequest.
ExpireDelegationTokenResponse =>
  // ErrorCode is any error that caused the request to fail.
  ErrorCode: int16
  // ExpiryTimestamp is the new timestamp at which the delegation token will
  // expire.
  ExpiryTimestamp: int64
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32

// DescribeDelegationTokenRequest is a request to describe delegation tokens.
DescribeDelegationTokenRequest => key 41, max version 1, admin
  // Owners contains owners to describe delegation tokens for, or null for all.
  // If non-null, only tokens created from a matching principal type, name
  // combination are printed.
  Owners: nullable[=>]
    // PrincipalType is a type to match to describe delegation tokens created
    // with this principal. This would be "User" with the simple authorizer.
    PrincipalType: string
    // PrincipalName is the name to match to describe delegation tokens created
    // with this principal.
    PrincipalName: string

// DescribeDelegationTokenResponsee is a response to a DescribeDelegationTokenRequest.
DescribeDelegationTokenResponse =>
  // ErrorCode is any error that caused the request to fail.
  ErrorCode: int16
  // TokenDetails shows information about each token created from any principal
  // in the request.
  TokenDetails: [=>]
    // PrincipalType is the principal type of who created this token.
    PrincipalType: string
    // PrincipalName is the principal name of who created this token.
    PrincipalName: string
    // IssueTimestamp is the millisecond timestamp of when this token was issued.
    IssueTimestamp: int64
    // ExpiryTimestamp is the millisecond timestamp of when this token will expire.
    ExpiryTimestamp: int64
    // MaxTimestamp is the millisecond timestamp past which whis token cannot
    // be renewed.
    MaxTimestamp: int64
    // TokenID is the ID (scram username) of this token.
    TokenID: string
    // HMAC is the password of this token.
    HMAC: bytes
    // Renewers is a list of users that can renew this token.
    Renewers: [=>]
      PrincipalType: string
      PrincipalName: string
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32

// DeleteGroupsRequest deletes consumer groups. This request was added for
// Kafka 1.1.0 corresponding to the removal of RetentionTimeMillis from
// OffsetCommitRequest. See KIP-229 for more details.
DeleteGroupsRequest => key 42, max version 2, flexible v2+, group coordinator
  // Groups is a list of groups to delete.
  Groups: [string]

// DeleteGroupsResponse is returned from a DeleteGroupsRequest.
DeleteGroupsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleMillis: int32
  // Groups are the responses to each group requested for deletion.
  Groups: [=>]
    // Group is a group ID requested for deletion.
    Group: string
    // ErrorCode is the error code returned for this group's deletion request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // GROUP_ID_NOT_FOUND is returned if the group ID does not exist.
    //
    // NON_EMPTY_GROUP is returned if attempting to delete a group that is
    // not in the empty state.
    ErrorCode: int16

// ElectLeadersRequest begins a leader election for all given topic
// partitions. This request was added in Kafka 2.2.0 to replace the zookeeper
// only option of triggering leader elections before. See KIP-183 for more
// details. KIP-460 introduced the ElectionType field with Kafka 2.4.0.
ElectLeadersRequest => key 43, max version 2, flexible v2+, admin
  // ElectionType is the type of election to conduct. 0 elects the preferred
  // replica, 1 elects the first live replica if there are no in-sync replicas
  // (i.e., unclean leader election).
  ElectionType: int8 // v1+
  // Topics is an array of topics and corresponding partitions to
  // trigger leader elections for, or null for all.
  Topics: nullable[=>]
    // Topic is a topic to trigger leader elections for (but only for the
    // partitions below).
    Topic: string
    // Partitions is an array of partitions in a topic to trigger leader
    // elections for.
    Partitions: [int32]
  // TimeoutMillis is how long to wait for the response. This limits how long to
  // wait since responses are not sent until election results are complete.
  TimeoutMillis: int32

// ElectLeadersResponse is a response for an ElectLeadersRequest.
ElectLeadersResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // ErrorCode is any error that applies to all partitions.
  //
  // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
  // authorized to reassign partitions.
  ErrorCode: int16 // v1+
  // Topics contains leader election results for each requested topic.
  Topics: [=>]
    // Topic is topic for the given partition results below.
    Topic: string
    // Partitions contains election results for a topic's partitions.
    Partitions: [=>]
      // Partition is the partition for this result.
      Partition: int32
      // ErrorCode is the error code returned for this topic/partition leader
      // election.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to trigger leader elections.
      //
      // NOT_CONTROLLER is returned if the request was not issued to a Kafka
      // controller.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic/partition does
      // not exist on any broker in the cluster (this is slightly different
      // from the usual meaning of a single broker not knowing of the topic
      // partition).
      //
      // PREFERRED_LEADER_NOT_AVAILABLE is returned if the preferred leader
      // could not be elected (for example, the preferred leader was not in
      // the ISR).
      ErrorCode: int16
      // ErrorMessage is an informative message if the leader election failed.
      ErrorMessage: nullable-string

// IncrementalAlterConfigsRequest issues ar equest to alter either topic or
// broker configs.
//
// This API was added in Kafka 2.3.0 to replace AlterConfigs. The key benefit
// of this API is that consumers do not need to know the full config state
// to add or remove new config options. See KIP-339 for more details.
IncrementalAlterConfigsRequest => key 44, max version 1, flexible v1+, admin
  // Resources is an array of configs to alter.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to alter.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to alter.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // updates all broker configs. If a specific ID, this updates just the
    // broker. Using a specific ID also ensures that brokers reload config
    // or secret files even if the file path has not changed. Lastly, password
    // config options can only be defined on a per broker basis.
    ResourceName: string
    // Configs contains key/value config pairs to set on the resource.
    Configs: [=>]
      // Name is a key to modify (e.g. segment.bytes).
      Name: string
      // Op is the type of operation to perform for this config name.
      //
      // SET (0) is to set a configuration value; the value must not be null.
      //
      // DELETE (1) is to delete a configuration key.
      //
      // APPEND (2) is to add a value to the list of values for a key (if the
      // key is for a list of values).
      //
      // SUBTRACT (3) is to remove a value from a list of values (if the key
      // is for a list of values).
      Op: int8
      // Value is a value to set for the key (e.g. 10).
      Value: nullable-string
  // ValidateOnly validates the request but does not apply it.
  ValidateOnly: bool

// IncrementalAlterConfigsResponse is returned from an IncrementalAlterConfigsRequest.
IncrementalAlterConfigsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // Resources are responses for each resources in the alter request.
  Resources: [=>]
    // ErrorCode is the error code returned for incrementally altering configs.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    //
    // INVALID_REQUEST is returned if the requested config is invalid or if
    // asking Kafka to alter an invalid resource.
    ErrorCode: int16
    // ErrorMessage is an informative message if the incremental alter config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of altered config.
    ResourceType: int8
    // ResourceName is the name corresponding to the incremental alter config
    // request.
    ResourceName: string

// AlterPartitionAssignmentsRequest, proposed in KIP-455 and implemented in
// Kafka 2.4.0, is a request to reassign partitions to certain brokers.
//
// ACL wise, this requires ALTER on CLUSTER.
AlterPartitionAssignmentsRequest => key 45, max version 0, flexible v0+, admin
  // TimeoutMillis is how long to wait for the response.
  TimeoutMillis: int32
  // Topics are topics for which to reassign partitions of.
  Topics: [=>]
    // Topic is a topic to reassign the partitions of.
    Topic: string
    // Partitions contains partitions to reassign.
    Partitions: [=>]
      // Partition is a partition to reassign.
      Partition: int32
      // Replicas are replicas to place the partition on, or null to
      // cancel a pending reassignment of this partition.
      Replicas: nullable[int32]

// AlterPartitionAssignmentsResponse is returned for an AlterPartitionAssignmentsRequest.
AlterPartitionAssignmentsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // ErrorCode is any global (applied to all partitions) error code.
  ErrorCode: int16
  // ErrorMessage is any global (applied to all partitions) error message.
  ErrorMessage: nullable-string
  // Topics contains responses for each topic requested.
  Topics: [=>]
    // Topic is the topic being responded to.
    Topic: string
    // Partitions contains responses for partitions.
    Partitions: [=>]
      // Partition is the partition being responded to.
      Partition: int32
      // ErrorCode is the error code returned for partition reassignments.
      //
      // REQUEST_TIMED_OUT is returned if the request timed out.
      //
      // NOT_CONTROLLER is returned if the request was not issued to a Kafka
      // controller.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to reassign partitions.
      //
      // NO_REASSIGNMENT_IN_PROGRESS is returned for partition reassignment
      // cancellations when the partition was not being reassigned.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
      // the requested topic or the topic is being deleted.
      ErrorCode: int16
      // ErrorMessage is an informative message if the partition reassignment failed.
      ErrorMessage: nullable-string

// ListPartitionReassignmentsRequest, proposed in KIP-455 and implemented in
// Kafka 2.4.0, is a request to list in progress partition reassignments.
//
// ACL wise, this requires DESCRIBE on CLUSTER.
ListPartitionReassignmentsRequest => key 46, max version 0, flexible v0+, admin
  // TimeoutMillis is how long to wait for the response.
  TimeoutMillis: int32
  // Topics are topics to list in progress partition reassignments of, or null
  // to list everything.
  Topics: nullable[=>]
    // Topic is a topic to list in progress partition reassingments of.
    Topic: string
    // Partitions are partitions to list in progress reassignments of.
    Partitions: [int32]

// ListPartitionReassignmentsResponse is returned for a ListPartitionReassignmentsRequest.
ListPartitionReassignmentsResponse =>
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // ErrorCode is the error code returned for listing reassignments.
  //
  // REQUEST_TIMED_OUT is returned if the request timed out.
  //
  // NOT_CONTROLLER is returned if the request was not issued to a Kafka
  // controller.
  //
  // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
  // authorized to reassign partitions.
  ErrorCode: int16
  // ErrorMessage is any global (applied to all partitions) error message.
  ErrorMessage: nullable-string
  // Topics contains responses for each topic requested.
  Topics: [=>]
    // Topic is the topic being responded to.
    Topic: string
    // Partitions contains responses for partitions.
    Partitions: [=>]
      // Partition is the partition being responded to.
      Partition: int32
      // Replicas is the partition's current replicas.
      Replicas: [int32]
      // AddingReplicas are replicas currently being added to the partition.
      AddingReplicas: [int32]
      // RemovingReplicas are replicas currently being removed from the partition.
      RemovingReplicas: [int32]

// OffsetDeleteRequest, proposed in KIP-496 and implemented in Kafka 2.4.0, is
// a request to delete group offsets.
//
// ACL wise, this requires DELETE on GROUP for the group and READ on TOPIC for
// each topic.
OffsetDeleteRequest => key 47, max version 0, admin
  // Group is the group to delete offsets in.
  Group: string
  // Topics are topics to delete offsets in.
  Topics: [=>]
    // Topic is a topic to delete offsets in.
    Topic: string
    // Partitions are partitions to delete offsets for.
    Partitions: [=>]
      // Partition is a partition to delete offsets for.
      Partition: int32

// OffsetDeleteResponse is a response to an offset delete request.
OffsetDeleteResponse =>
  // ErrorCode is any group wide error.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // for the group.
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available.
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // GROUP_ID_NOT_FOUND is returned if the group ID does not exist.
  ErrorCode: int16
  // ThrottleMillis is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleMillis: int32
  // Topics are responses to requested topics.
  Topics: [=>]
    // Topic is the topic being responded to.
    Topic: string
    // Partitions are partitions being responded to.
    Partitions: [=>]
      // Partition is the partition being responded to.
      Partition: int32
      // ErrorCode is any per partition error code.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // for the topic / partition.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
      // the requested topic.
      //
      // GROUP_SUBSCRIBED_TO_TOPIC is returned if the topic is still subscribed to.
      ErrorCode: int16

// Header is user provided metadata for a record. Kafka does not look at
// headers at all; they are solely for producers and consumers.
Header => not top level
  Key: varint-string
  Value: varint-bytes

// A Record is a Kafka v0.11.0.0 record. It corresponds to an individual
// message as it is written on the wire.
Record => not top level
  // Length is the length of this record on the wire of everything that
  // follows this field. It is an int32 encoded as a varint.
  Length: varint
  // Attributes are record level attributes. This field currently is unused.
  Attributes: int8
  // TimestampDelta is the millisecond delta of this record's timestamp
  // from the record's RecordBatch's FirstTimestamp.
  TimestampDelta: varint
  // OffsetDelta is the delta of this record's offset from the record's
  // RecordBatch's FirstOffset.
  //
  // For producing, this is usually equal to the index of the record in
  // the record batch.
  OffsetDelta: varint
  // Key is an blob of data for a record.
  //
  // Key's are usually used for hashing the record to specific Kafka partitions.
  Key: varint-bytes
  // Value is  a blob of data. This field is the main "message" portion of a
  // record.
  Value: varint-bytes
  // Headers are optional user provided metadata for records. Unlike normal
  // arrays, the number of headers is encoded as a varint.
  Headers: varint[Header]

// RecordBatch is a Kafka concept that groups many individual records together
// in a more optimized format.
RecordBatch => not top level
  // FirstOffset is the first offset in a record batch.
  //
  // For producing, this is usually 0.
  FirstOffset: int64
  // Length is the wire length of everything that follows this field.
  Length: int32
  // PartitionLeaderEpoch is a number that Kafka uses for cluster
  // communication. Clients generally do not need to worry about this
  // field and producers should set it to -1.
  PartitionLeaderEpoch: int32
  // Magic is the current "magic" number of this message format.
  // The current magic number is 2.
  Magic: int8
  // CRC is the crc of everything that follows this field using the
  // Castagnoli polynomial.
  CRC: int32
  // Attributes describe the records array of this batch.
  //
  // Bits 0 thru 3 correspond to compression:
  //   - 000 is no compression
  //   - 001 is snappy compression
  //   - 010 is lz4 compression
  //   - 011 is zstd compression (produce request version 7+)
  //
  // Bit 4 is the timestamp type, with 0 meaning CreateTime corresponding
  // to the timestamp being from the producer, and 1 meaning LogAppendTime
  // corresponding to the timestamp being from the broker.
  // Setting this to LogAppendTime will cause batches to be rejected.
  //
  // Bit 5 indicates whether the batch is part of a transaction (1 is yes).
  //
  // Bit 6 indicates if the batch includes a control message (1 is yes).
  // Control messages are used to enable transactions and are generated from
  // the broker. Clients should not return control batches to applications.
  Attributes: int16
  // LastOffsetDelta is the offset of the last message in a batch. This is
  // by the broker to ensure correct behavior even with batch compaction.
  LastOffsetDelta: int32
  // FirstTimestamp is the timestamp (in milliseconds) of the first record
  // in a batch.
  FirstTimestamp: int64
  // MaxTimestamp is the timestamp (in milliseconds) of the last record
  // in a batch. Similar to LastOffsetDelta, this is used to ensure correct
  // behavior with compacting.
  MaxTimestamp: int64
  // ProducerID is the broker assigned producerID from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  ProducerID: int64
  // ProducerEpoch is the broker assigned producerEpoch from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  ProducerEpoch: int16
  // FirstSequence is the producer assigned sequence number used by the
  // broker to deduplicate messages.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  //
  // The sequence number for each record in a batch is OffsetDelta + FirstSequence.
  FirstSequence: int32
  // NumRecords is the number of records in the array below.
  //
  // This is separate from Records due to the potential for records to be
  // compressed.
  NumRecords: int32
  // Records contains records, either compressed or uncompressed.
  //
  // For uncompressed records, this is an array of records ([Record]).
  //
  // For compressed records, the length of the uncompressed array is kept
  // but everything that follows is compressed.
  //
  // The number of bytes is expected to be the Length field minus 48.
  Records: length-field-minus => Length - 49

// ProduceRequest issues records to be created to Kafka.
//
// The min version of this type is currently 2, released with Kafka 0.11.0.0.
// Prior, the RecordBatch format was completely different (and was called a
// MessageSet).
//
// Note that the special client ID "__admin_client" will allow you to produce
// records to internal topics. This is generally recommended if you want to
// break your Kafka cluster.
ProduceRequest => key 0, max version 7, min version 2
  TransactionID: nullable-string // v3+
  // Acks specifies the number of acks that the partition leaders must receive
  // from in sync replicas before considering a record batch fully written.
  //
  // Valid values are -1, 0, or 1 corresponding to all, none, or one.
  //
  // Note that if no acks are requested, Kafka will close the connection
  // if any topic or partition errors to trigger a client metadata refresh.
  Acks: int16
  // Timeout is the millisecond timeout of this request.
  Timeout: int32
  // TopicData is an array of topics to send record batches to.
  TopicData: [=>]
    // Topic is a topic to send record batches to.
    Topic: string
    // Data is an array of partitions to send record batches to.
    Data: [=>]
      // Partition is a partition to send a record batch to.
      Partition: int32
      // Records is a batch of records to write to a topic's partition.
      // The size of the batch is prefixed with an int32 length.
      Records: sized-struct => RecordBatch

// ProduceResponse is returned from a ProduceRequest.
ProduceResponse => from ProduceRequest
  // Responses is an array of responses for the topic's that batches were sent
  // to.
  Responses: [=>]
    // Topic is the topic this response pertains to.
    Topic: string
    // PartitionResponses is an array of responses for the partition's that
    // batches were sent to.
    PartitionResponses: [=>]
      // Partition is the partition this response pertains to.
      Partition: int32
      // ErrorCode is any error for a topic/partition in the request.
      // There are many error codes for produce requests.
      //
      // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for all topics and
      // partitions if the request had a transactional ID but the client
      // is not authorized for transactions.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned for all topics and partitions
      // if the request was idempotent but the client is not authorized
      // for idempotent requests.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all topics the client
      // is not authorized to talk to.
      //
      // INVALID_REQUIRED_ACKS is returned if the request contained an invalid
      // number for "acks".
      //
      // CORRUPT_MESSAGE is returned for many reasons, generally related to
      // problems with messages (invalid magic, size mismatch, etc.).
      //
      // MESSAGE_TOO_LARGE is returned if a record batch is larger than the
      // broker's configured max.message.size.
      //
      // RECORD_LIST_TOO_LARGE is returned if the record batch is larger than
      // the broker's segment.bytes.
      //
      // INVALID_TIMESTAMP is returned if the record batch uses LogAppendTime
      // or if the timestamp delta from when the broker receives the message
      // is more than the broker's log.message.timestamp.difference.max.ms.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if using a Kafka v2 message
      // format (i.e. RecordBatch) feature (idempotence) while sending v1
      // messages (i.e. a MessageSet).
      //
      // KAFKA_STORAGE_ERROR is returned if the log directory for a partition
      // is offline.
      //
      // NOT_ENOUGH_REPLICAS is returned if all acks are required, but there
      // are not enough in sync replicas yet.
      //
      // NOT_ENOUGH_REPLICAS_AFTER_APPEND is returned on old Kafka versions
      // (pre 0.11.0.0) when a message was written to disk and then Kafka
      // noticed not enough replicas existed to replicate the message.
      //
      // DUPLICATE_SEQUENCE_NUMBER is returned for Kafka <1.1.0 when a
      // sequence number is detected as a duplicate. After, out of order
      // is returned.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
      // is unknown.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      //
      // INVALID_PRODUCER_EPOCH is returned if the produce request was
      // attempted with an old epoch. Either there is a newer producer using
      // the same transaction ID, or the transaction ID used has expired.
      //
      // UNKNOWN_PRODUCER_ID, added in Kafka 1.0.0 (message format v5+) is
      // returned if the producer used an ID that Kafka does not know about.
      // The LogStartOffset must be checked in this case. If the offset is
      // greater than the last acknowledged offset, then no data loss has
      // occurred; the client just sent data so long ago that Kafka rotated
      // the partition out of existence and no longer knows of this producer
      // ID. In this case, initialize a new ID. If the log start offset is
      // equal to or less than what the client sent prior, then data loss
      // has occurred. This See KAFKA-5793 for more details.
      //
      // OUT_OF_ORDER_SEQUENCE_NUMBER is sent if the batch's FirstSequence was
      // not what it should be (the last FirstSequence, plus the number of
      // records in the last batch, plus one). After 1.0.0, this generally
      // means data loss. Before, there could be confusion on if the broker
      // actually rotated the partition out of existence (this is why
      // UNKNOWN_PRODUCER_ID was introduced).
      ErrorCode: int16
      // BaseOffset is the offset that the records in the produce request began
      // at in the partition.
      BaseOffset: int64
      // LogAppendTime is the time that records were appended to the partition
      // inside Kafka. This is only not -1 if records were written with the log
      // append time flag (which producers cannot do).
      LogAppendTime: int64 // v2+
      // LogStartOffset, introduced in Kafka 1.0.0,  can be used to see if an
      // UNKNOWN_PRODUCER_ID means Kafka rotated records containing the used
      // producer ID out of existence, or if Kafka lost data.
      LogStartOffset: int64 // v5+
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32

// FetchRequest is a long-poll request of records from Kafka.
FetchRequest => key 1, max version 10
  // ReplicaID is the broker ID of performing the fetch request. Standard
  // clients should use -1. To be a "debug" replica, use -2. The debug
  // replica can be used to fetch messages from non-leaders.
  ReplicaID: int32
  // MaxWaitTime is how long to wait for MinBytes to be hit before a broker
  // responds to a fetch request.
  MaxWaitTime: int32
  // MinBytes is the minimum amount of bytes to attempt to read before a broker
  // responds to a fetch request.
  MinBytes: int32
  // MaxBytes is the maximum amount of bytes to read in a fetch request. The
  // response can exceed MaxBytes if the first record in the first non-empty
  // partition is larger than MaxBytes.
  MaxBytes: int32 // v3+
  // IsolationLevel changes which messages are fetched. Follower replica ID's
  // (non-negative, non-standard-client) fetch from the end.
  //
  // Standard clients fetch from the high watermark, which corresponds to
  // IsolationLevel 0, READ_UNCOMMITTED.
  //
  // To only read committed records, use IsolationLevel 1, corresponding to
  // READ_COMMITTED.
  IsolationLevel: int8 // v4+
  // SessionID is used for broker-to-broker communication.
  //
  // Because this is not needed in general clients, documentation is elided.
  // Read KIP-227 for more details. Use -1 as a general client.
  SessionID: int32 // v7+
  // SessionEpoch is used for broker-to-broker communication.
  //
  // Because this is not needed in general clients, documentation is elided.
  // Read KIP-227 for more details. Use -1 as a general client.
  SessionEpoch: int32 // v7+
  // Topic contains topics to try to fetch records for.
  Topics: [=>]
    // Topic is a topic to try to fetch records for.
    Topic: string
    // Partitions contains partitions in a topic to try to fetch records for.
    Partitions: [=>]
      // Partition is a partition in a topic to try to fetch records for.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be gleaned from a MetadataResponse.
      // To skip log truncation checking, use -1.
      CurrentLeaderEpoch: int32 // v9+
      // FetchOffset is the offset to begin the fetch from. Kafka will
      // return records at and after this offset.
      FetchOffset: int64
      // LogStartOffset is a broker-follower only field added for KIP-107.
      // This is the start offset of the partition in a follower.
      LogStartOffset: int64 // v5+
      // PartitionMaxBytes is the maximum bytes to return for this partition.
      // This can be used to limit how many bytes an individual partition in
      // a request is allotted so that it does not dominate all of MaxBytes.
      PartitionMaxBytes: int32
  // ForgottenTopicsData contains topics and partitions that a fetch session
  // wants to remove from its session. This is generally only needed for
  // brokers; see KIP-227 for more details.
  ForgottenTopicsData: [=>] // v7+
    // Topic is a topic to remove from being tracked (with the partitions below).
    Topic: string
    // Partitions are partitions to remove from tracking for a topic.
    Partitions: [int32]

// FetchResponse is returned from a FetchRequest.
FetchResponse => from FetchRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is a full-response error code for a fetch request. This was
  // added in support of KIP-227. This error is only non-zero if using fetch
  // sessions (clients should not).
  //
  // FETCH_SESSION_ID_NOT_FOUND is returned if the request used a
  // session ID that the broker does not know of.
  //
  // INVALID_FETCH_SESSION_EPOCH is returned if the request used an
  // invalid session epoch.
  ErrorCode: int16 // v7+
  // SessionID is for broker to broker communication. See KIP-227 for more details.
  SessionID: int32 // v7+
  // Responses contains an array of topic partitions and the records received
  // for them.
  Responses: [=>]
    // Topic is a topic that records may have been received for.
    Topic: string
    // PartitionResponses contains partitions in a topic that records may have
    // been received for.
    PartitionResponses: [=>]
      // Partition is a partition in a topic that records may have been
      // received for.
      Partition: int32
      // ErrorCode is an error returned for an individual partition in a
      // fetch request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to read the partition.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
      // does not exist on this broker.
      //
      // UNSUPPORTED_COMPRESSION_TYPE is returned if the request version was
      // under 10 and the batch is compressed with zstd.
      //
      // UNSUPPORTED_VERSION is returned if the broker has records newer than
      // the client can support (magic value) and the broker has disabled
      // message downconversion.
      //
      // NOT_LEADER_FOR_PARTITION is returned if requesting data for this
      // partition as a follower (non-negative ReplicaID) and the broker
      // is not the leader for this partition.
      //
      // REPLICA_NOT_AVAILABLE is returned if the partition exists but
      // the requested broker is not the leader for it.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the requested partition is
      // offline.
      //
      // UNKNOWN_LEADER_EPOCH is returned if the request used a larger leader
      // epoch than the broker knows of.
      //
      // FENCED_LEADER_EPOCH is returned if the request used a smaller leader
      // epoch than the broker is at (see KIP-320).
      //
      // OFFSET_OUT_OF_RANGE is returned if requesting an offset past the
      // current end offset or before the beginning offset.
      ErrorCode: int16
      // HighWatermark is the current high watermark for this partition,
      // that is, the current offset that is on all in sync replicas.
      HighWatermark: int64
      // LastStableOffset is the offset at which all prior offsets have
      // been "decided". Non transactional records are always decided
      // immediately, but transactional records are only decided once
      // they are commited or aborted.
      //
      // The LastStableOffset will always be at or under the HighWatermark.
      LastStableOffset: int64 // v4+
      // LogStartOffset is the beginning offset for this partition.
      // This field was added for KIP-107.
      LogStartOffset: int64 // v5+
      // AbortedTransactions is an array of aborted transactions within the
      // returned offset range. This is only returned if the requested
      // isolation level was READ_COMMITTED.
      AbortedTransactions: [=>] // v4+
        // ProducerID is the producer ID that caused this aborted transaction.
        ProducerID: int64
        // FirstOffset is the offset where this aborted transaction began.
        FirstOffset: int64
      // RecordBatches is an array of record batches for a topic partition.
      // The size prefixing the array is the byte size of all the batches,
      // NOT the number of record batches. Kafka may include a partial record
      // batch at the end of the array; this partial batch should be discarded.
      // This is an optimization in Kafka that the clients must deal with.
      RecordBatches: as-many-that-fit[RecordBatch]

// ListOffsetsRequest requests partition offsets from Kafka for use in
// consuming records.
ListOffsetsRequest => key 2, max version 4, min version 1, admin
  // ReplicaID is the broker ID to get offsets from. As a Kafka client, use -1.
  // The consumer replica ID (-1) causes requests to only succeed if issued
  // against the leader broker.
  ReplicaID: int32
  // IsolationLevel configures which record offsets are visible in the
  // response. READ_UNCOMMITTED (0) makes all records visible. READ_COMMITTED
  // (1) makes non-transactional and committed transactional records visible.
  // READ_COMMITTED means all offsets smaller than the last stable offset and
  // includes aborted transactions (allowing consumers to discard aborted
  // records).
  IsolationLevel: int8 // v2+
  // Topics is an array of topics to get offsets for.
  Topics: [=>]
    // Topic is a topic to get offsets for.
    Topic: string
    // Partitions is an array of partitions in a topic to get offsets for.
    Partitions: [=>]
      // Partition is a partition of a topic to get offsets for.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be gleaned from a MetadataResponse.
      // To skip log truncation checking, use -1.
      CurrentLeaderEpoch: int32 // v4+
      // Timestamp controls which offset to return in a response for this
      // partition.
      //
      // The offset returned will be the one of the message whose timestamp is
      // the first timestamp greater than or equal to this requested timestamp.
      //
      // If no such message is found, the log end offset is returned.
      //
      // There exist two special timestamps: -2 corresponds to the earliest
      // timestamp, and -1 corresponds to the latest.
      Timestamp: int64

// ListOffsetsResponse is returned from a ListOffsetsRequest.
ListOffsetsResponse => from ListOffsetsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v2+
  // Responses is an array of topic / partition responses corresponding to
  // the requested topics and partitions.
  Responses: [=>]
    // Topic is the topic this array slot is for.
    Topic: string
    // PartitionResponses is an array of partition responses corresponding to
    // the requested partitions for a topic.
    PartitionResponses: [=>]
      // Partition is the partition this array slot is for.
      Partition: int32
      // ErrorCode is any error for a topic partition in a ListOffsets request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to describe the topic.
      //
      // INVALID_REQUEST is returned if the requested topic partitions had
      // contained duplicates.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the topic / partition is in
      // an offline log directory.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if the broker is using
      // Kafka 0.10.0 messages and the requested timestamp was not -1 nor -2.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      // If the request used the debug replica ID, the returned error will
      // be REPLICA_NOT_AVAILABLE.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know
      // of the requested topic or partition.
      //
      // FENCED_LEADER_EPOCH is returned if the broker has a higher leader
      // epoch than what the request sent.
      //
      // UNKNOWN_LEADER_EPOCH is returned if the request used a leader epoch
      // that the broker does not know about.
      //
      // OFFSET_NOT_AVAILABLE, introduced in Kafka 2.2.0 with produce request
      // v5+, is returned when talking to a broker that is a new leader while
      // that broker's high water mark catches up. This avoids situations where
      // the old broker returned higher offsets than the new broker would. Note
      // that if unclean leader election is allowed, you could still run into
      // the situation where offsets returned from list offsets requests are
      // not monotonically increasing. This error is only returned if the
      // request used the consumer replica ID (-1). If the client did not use
      // a v5+ list offsets request, LEADER_NOT_AVAILABLE is returned.
      // See KIP-207 for more details.
      ErrorCode: int16
      // If the request was for the earliest or latest timestamp (-2 or -1), or
      // if an offset could not be found after the requested one, this will be -1.
      Timestamp: int64
      // Offset is the offset corresponding to the record on or after the
      // requested timestamp. If one could not be found, this will be -1.
      Offset: int64 // v1+
      // LeaderEpoch is the leader epoch of the record at this offset,
      // or -1 if there was no leader epoch.
      LeaderEpoch: int32 // v4+

// MetadataRequest requests metadata from Kafka.
MetadataRequest => key 3, max version 8
  // Topics is a list of topics to return metadata about. If this is null,
  // all topics are included. If this is empty, no topics are.
  // For v0 (<Kafka 0.10.0.0), if this is empty, all topics are included.
  Topics: nullable[string]
  // AllowAutoTopicCreation, introduced in Kafka 0.11.0.0, allows topic
  // auto creation of the topics in this request if they do not exist.
  AllowAutoTopicCreation: bool // v4+
  // IncludeClusterAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on the cluster. See KIP-430 for more details.
  IncludeClusterAuthorizedOperations: bool // v8+
  // IncludeTopicAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on individual topics. See KIP-430 for more details.
  IncludeTopicAuthorizedOperations: bool // v8+

// MetadataResponse is returned from a MetdataRequest.
MetadataResponse => from MetadataRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v3+
  // Brokers is a set of alive Kafka brokers.
  Brokers: [=>]
    // NodeID is the node ID of a Kafka broker.
    NodeID: int32
    // Host is the hostname of a Kafka broker.
    Host: string
    // Port is the port of a Kafka broker.
    Port: int32
    // Rack is the rack this Kafka broker is in.
    Rack: nullable-string // v1+
  // ClusterID, proposed in KIP-78 and introduced in Kafka 0.10.1.0, is a
  // unique string specifying the cluster that the replying Kafka belongs to.
  ClusterID: nullable-string // v2+
  // ControllerID is the ID of the controller broker (the admin broker).
  ControllerID: int32 // v1+
  // TopicMetadata contains metadata about each topic requested in the
  // MetadataRequest.
  TopicMetadata: [=>]
    // ErrorCode is any error for a topic in a metadata request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe the topic, or if the metadata request specified topic auto
    // creation, the topic did not exist, and the user lacks permission to create.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if a topic does not exist and
    // the request did not specify autocreation.
    //
    // LEADER_NOT_AVAILABLE is returned if a new topic is created successfully
    // (since there is no leader on an immediately new topic).
    //
    // There can be a myriad of other errors for unsuccessful topic creation.
    ErrorCode: int16
    // Topic is the topic this metadata corresponds to.
    Topic: string
    // IsInternal signifies whether this topic is a Kafka internal topic.
    IsInternal: bool // v1+
    // PartitionMetadata contains metadata about partitions for a topic.
    PartitionMetadata: [=>]
      // ErrorCode is any error for a partition in topic metadata.
      //
      // LEADER_NOT_AVAILABLE is returned if a leader is unavailable for this
      // partition. For v0 metadata responses, this is also returned if a
      // partition leader's listener does not exist.
      //
      // LISTENER_NOT_FOUND is returned if a leader ID is known but the
      // listener for it is not (v1+).
      //
      // REPLICA_NOT_AVAILABLE is returned in v0 responses if any replica is
      // unavailable.
      ErrorCode: int16
      // Partition is a partition number for a topic.
      Partition: int32
      // Leader is the broker leader for this partition. This will be -1
      // on leader / listener error.
      Leader: int32
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0 is the
      // epoch of the broker leader.
      LeaderEpoch: int32 // v7+
      // Replicas returns all broker IDs containing replicas of this partition.
      Replicas: [int32]
      // ISR returns all broker IDs of in-sync replicas of this partition.
      ISR: [int32]
      // OfflineReplicas, proposed in KIP-112 and introduced in Kafka 1.0,
      // returns all offline broker IDs that should be replicating this partition.
      OfflineReplicas: [int32] // v5+
    // AuthorizedOperations, proposed in KIP-430 and introduced in Kafka 2.3.0,
    // is a bitfield (corresponding to AclOperation) containing which operations
    // the client is allowed to perform on this topic.
    // This is only returned if requested.
    AuthorizedOperations: int32 // v8+
  // AuthorizedOperations is a bitfield containing which operations the client
  // is allowed to perform on this cluster.
  AuthorizedOperations: int32 // v8+

// LeaderAndISRRequest is an advanced request that controller brokers use
// to broadcast state to other brokers. Manually using this request is a
// great way to break your cluster.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 1.0.0 introduced version 1. Kafka 2.2.0 introduced version 2, proposed
// in KIP-380, which changed the layout of the struct to be more memory
// efficient.
LeaderAndISRRequest => key 4, max version 2, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v2+
  PartitionStates: [=>] // v0-v1
    Topic: string
    Partition: int32
    ControllerEpoch: int32
    Leader: int32
    LeaderEpoch: int32
    ISR: [int32]
    ZKVersion: int32
    Replicas: [int32]
    IsNew: bool // v1+
  TopicStates: [=>] // v2+
    Topic: string
    PartitionStates: [=>]
      Partition: int32
      ControllerEpoch: int32
      Leader: int32
      LeaderEpoch: int32
      ISR: [int32]
      ZKVersion: int32
      Replicas: [int32]
      IsNew: bool
  LiveLeaders: [=>]
    ID: int32
    Host: string
    Port: int32

// LeaderAndISRResponse is returned from a LeaderAndISRRequest.
LeaderAndISRResponse => from LeaderAndISRRequest
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

// StopReplicaRequest is an advanced request that brokers use to stop replicas.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 2.2.0 introduced version 1, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
StopReplicaRequest => key 5, max version 1, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v1+
  DeletePartitions: bool
  Partitions: [=>]
    Topic: string
    Partition: int32 // v0-v0
    PartitionIDs: [int32] // v1+

// StopReplicasResponse is returned from a StopReplicasRequest.
StopReplicaResponse => from StopReplicaRequest
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

// UpdateMetadataRequest is an advanced request that brokers use to
// issue metadata updates to each other.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Version 1 changed the layout of the live brokers.
//
// Kafka 2.2.0 introduced version 5, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
UpdateMetadataRequest => key 6, max version 5, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v5+
  PartitionStates: [=>] // v0-v4
    Topic: string
    Partition: int32
    ControllerEpoch: int32
    Leader: int32
    LeaderEpoch: int32
    ISR: [int32]
    ZKVersion: int32
    Replicas: [int32]
    OfflineReplicas: [int32]
  TopicStates: [=>] // v5+
    Topic: string
    PartitionStates: [=>]
      Partition: int32
      ControllerEpoch: int32
      Leader: int32
      LeaderEpoch: int32
      ISR: [int32]
      ZKVersion: int32
      Replicas: [int32]
      OfflineReplicas: [int32]
  LiveBrokers: [=>]
    ID: int32
    Host: string // v0-v0
    Port: int32 // v0-v0
    Endpoints: [=>] // v1+
      Port: int32
      Host: string
      ListenerName: string // v3+
      SecurityProtocolType: int16
    Rack: nullable-string // v2+

// UpdateMetadataResponses is returned from an UpdateMetadataRequest.
UpdateMetadataResponse => from UpdateMetadataRequest
  ErrorCode: int16

// ControlledShutdownRequest is an advanced request that can be used to
// sthudown a broker in a controlled manner.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented. However, the minimal amount of fields
// here makes the usage rather obvious.
//
// Kafka 2.2.0 introduced version 2, proposed in KIP-380.
ControlledShutdownRequest => key 7, max version 2, admin
  BrokerID: int32
  BrokerEpoch: int64 // v2+

// ControlledShutdownResponse is returned from a ControlledShutdownRequest.
ControlledShutdownResponse => from ControlledShutdownRequest
  ErrorCode: int16
  PartitionsRemaining: [=>]
    Topic: string
    Partition: int32

// OffsetCommitRequest commits offsets for consumed topics / partitions in
// a group.
OffsetCommitRequest => key 8, max version 6, group coordinator
  // GroupID is the group this request is committing offsets to.
  GroupID: string
  // GenerationID being -1 and group being empty means the group is being used
  // to store offsets only. No generation validation, no rebalancing.
  GenerationID: int32 // v1+
  // MemberID is the ID of the client issuing this request in the group.
  MemberID: string // v1+
  // RetentionTime is how long this commit will persist in Kafka.
  //
  // This was introduced in v2, replacing an individual topic/partition's
  // Timestamp from v1, and was removed in v5 with Kafka 2.1.0.
  //
  // This was removed because rarely committing consumers could have their
  // offsets expired before committing, even though the consumer was still
  // active. After restarting or rebalancing, the consumer would now not know
  // the last committed offset and would have to start at the beginning or end,
  // leading to duplicates or log loss. Read KIP-211 for more details.
  RetentionTime: int64 // v2-v4
  // Topics is contains topics and partitions for which to commit offsets.
  Topics: [=>]
    // Topic is a topic to commit offsets for.
    Topic: string
    // Partitions contains partitions in a topic for which to commit offsets.
    Partitions: [=>]
      // Partition if a partition to commit offsets for.
      Partition: int32
      // Offset is an offset to commit.
      Offset: int64
      // Timestamp is the first iteration of tracking how long offset commits
      // should persist in Kafka. This field only existed for v1.
      // The expiration would be timestamp + offset.retention.minutes, or, if
      // timestamp was zero, current time + offset.retention.minutes.
      Timestamp: int64 // v1-v1
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // is the leader epoch of the record this request is committing.
      //
      // The initial leader epoch can be gleaned from a MetadataResponse.
      // To skip log truncation checking, use -1.
      LeaderEpoch: int32 // v6+
      // Metadata is optional data to include with committing the offset. This
      // can contain information such as which node is doing the committing, etc.
      Metadata: nullable-string

// OffsetCommitResponse is returned from an OffsetCommitRequest.
OffsetCommitResponse => from OffsetCommitRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v3+
  // Responses contains responses for each topic / partition in the commit request.
  Responses: [=>]
    // Topic is the topic this offset commit response corresponds to.
    Topic: string
    // PartitionResponses contains responses for each requested partition in
    // a topic.
    PartitionResponses: [=>]
      // Partition is the partition in a topic this array slot corresponds to.
      Partition: int32
      // ErrorCode is the error for this partition response.
      //
      // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
      // for the group.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // for the topic / partition.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic / partition does
      // not exist.
      //
      // OFFSET_METADATA_TOO_LARGE is returned if the request metadata is
      // larger than the brokers offset.metadata.max.bytes.
      //
      // INVALID_GROUP_ID is returned in the requested group ID is invalid.
      //
      // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
      // (due to the requested broker shutting down or it has not completed startup).
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
      //
      // NOT_COORDINATOR is returned if the requested broker is not the coordinator
      // for the requested group.
      //
      // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
      //
      // UNKNOWN_MEMBER_ID is returned if the group is dead or the group does not
      // know of the request's member ID.
      //
      // REBALANCE_IN_PROGRESS is returned if the group is finishing a rebalance.
      //
      // INVALID_COMMIT_OFFSET_SIZE is returned if the offset commit results in
      // a record batch that is too large (likely due to large metadata).
      ErrorCode: int16

// OffsetFetchRequest requests the most recent committed offsets for topic
// partitions in a group.
OffsetFetchRequest => key 9, max version 5, group coordinator
  // GroupID is the group to fetch offsets for.
  GroupID: string
  // Topics contains topics to fetch offets for. Version 2+ allows this to be
  // null to return all topics the client is authorized to describe in the group.
  Topics: nullable[=>]
    // Topic is a topic to fetch offsets for.
    Topic: string
    // Partitions in a list of partitions in a group to fetch offsets for.
    Partitions: [=>]
      // Partition is a partition to fetch offsets for in a topic.
      Partition: int32

// OffsetFetchResponse is returned from an OffsetFetchRequest.
OffsetFetchResponse => from OffsetFetchRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v3+
  // Responses contains responses for each requested topic/partition.
  Responses: [=>]
    // Topic is the topic this offset fetch response corresponds to.
    Topic: string
    // PartitionResponses contains responses for each requested partition in
    // a topic.
    PartitionResponses: [=>]
      // Partition is the partition in a topic this array slot corresponds to.
      Partition: int32
      // Offset is the most recently committed offset for this topic partition
      // in a group.
      Offset: int64
      // LeaderEpoch is the leader epoch of the last consumed record.
      //
      // This was proposed in KIP-320 and introduced in Kafka 2.1.0 and allows
      // clients to detect log truncation. See the KIP for more details.
      LeaderEpoch: int32 // v5+
      // Metadata is client provided metadata corresponding to the offset commit.
      // This can be useful for adding who made the commit, etc.
      Metadata: nullable-string
      // ErrorCode is the error for this partition response.
      //
      // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to the group.
      //
      // INVALID_GROUP_ID is returned in the requested group ID is invalid.
      //
      // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
      // (due to the requested broker shutting down or it has not completed startup).
      //
      // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
      //
      // NOT_COORDINATOR is returned if the requested broker is not the coordinator
      // for the requested group.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the requested topic or partition
      // is unknown.
      ErrorCode: int16
  // ErrorCode is a top level error code that applies to all topic/partitions.
  // This will be any group error.
  ErrorCode: int16 // v2+

// FindCoordinatorRequest requests the coordinator for a group or transaction.
//
// This coordinator is different from the broker leader coordinator. This
// coordinator is the partition leader for the partition that is storing
// the group or transaction ID.
FindCoordinatorRequest => key 10, max version 2
  // CoordinatorKey is the ID to use for finding the coordinator. For groups,
  // this is the group ID, for transactional producer, this is the
  // transactional ID.
  //
  // In v0 this was called GroupID.
  CoordinatorKey: string // v0+
  // CoordinatorType is the type that key is. GroupIDs are type 0,
  // transactional IDs are type 1.
  CoordinatorType: int8 // v1+

// FindCoordinatorResponse is returned from a FindCoordinatorRequest.
FindCoordinatorResponse => from FindCoordinatorRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error returned for the request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if for a group ID request and the
  // client is not authorized to describe groups.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for a transactional ID
  // request and the client is not authorized to describe transactional IDs.
  //
  // INVALID_REQUEST is returned if not asking for a known type (group,
  // or transaction).
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // for the requested ID, or if the requested ID does not exist.
  ErrorCode: int16
  // ErrorMessage is an informative message if the request errored.
  ErrorMessage: nullable-string // v1+
  // Coordinator is the coordinator for the requested ID if the request did
  // not error.
  Coordinator: =>
    // NodeID is the broker ID of the coordinator.
    NodeID: int32
    // Host is the host of the coordinator.
    Host: string
    // Port is the port of the coordinator.
    Port: int32

// GroupMemberMetadata is the metadata that is usually sent with a join group
// request.
GroupMemberMetadata => not top level, with encoding
  // Version is currently version 0.
  Version: int16
  // Topics is the list of topics in the group.
  Topics: [string]
  // UserData is arbitrary client data for a given client in the group.
  UserData: bytes

// GroupMemberAssignment is the assignment data that is usually sent with a
// sync group request.
GroupMemberAssignment => not top level, with encoding
  // Verson is currently version 0.
  Version: int16
  // Topics contains topics in the assignment.
  Topics: [=>]
    // Topic is a topic in the assignment.
    Topic: string
    // Partitions contains partitions in the assignment.
    Partitions: [int32]
  // UserData is arbitrary client data for a given client in the group. This
  // was added for the sticky assignment with KIP-341.
  UserData: bytes

// JoinGroupRequest issues a request to join a Kafka group. This will create a
// group if one does not exist. If joining an existing group, this may trigger
// a group rebalance.
//
// This will trigger a group rebalance if the request is from the group leader,
// or if the request is from a group member with different metadata, or if the
// request is with a new group member.
//
// Version 4 introduced replying to joins of existing groups with
// MEMBER_ID_REQUIRED, which requires re-issuing the join group with the
// returned member ID. See KIP-394 for more details.
JoinGroupRequest => key 11, max version 4, group coordinator
  // GroupID is the group to join.
  GroupID: string
  // SessionTimeoutMs is how long a member in the group can go between
  // heartbeats. If a member does not send a heartbeat within this timeout,
  // the broker will remove the member from the group and initiate a rebalance.
  SessionTimeout: int32
  // RebalanceTimeout is how long the broker waits for members to join a group
  // once a rebalance begins. Kafka waits for the longest rebalance of all
  // members in the group. Member sessions are still alive; heartbeats will be
  // replied to with REBALANCE_IN_PROGRESS. Those members must transition to
  // joining within this rebalance timeout. Members that do not rejoin within
  // this timeout will be removed from the group. Members must commit offsets
  // within this timeout.
  //
  // The first join for a new group has a 3 second grace period for other
  // members to join; this grace period is extended until the RebalanceTimeout
  // is up or until 3 seconds lapse with no new members.
  RebalanceTimeout: int32 // v1+
  // MemberID is the member ID to join the group with. When joining a group for
  // the first time, use the empty string. The response will contain the member
  // ID that should be used going forward.
  MemberID: string
  // ProtocolType is the "type" of protocol being used for the join group.
  // The initial group creation sets the type; all additional members must
  // have the same type or they will be rejected.
  //
  // This is completely arbitrary, but the Java client and everything else
  // uses "consumer" as the protocol type.
  ProtocolType: string
  // GroupProtocols contains arbitrary information that group members use
  // for rebalancing. All group members must agree on at least one protocol
  // name.
  GroupProtocols: [=>]
    // ProtocolName is a name of a protocol. This is arbitrary, but is used
    // in the official client to agree on a partition balancing strategy.
    //
    // The official client uses range, roundrobin, or sticky (which was
    // introduced in KIP-54).
    ProtocolName: string
    // ProtocolMetadata is arbitrary information to pass along with this
    // protocol name for this member.
    //
    // Note that while this is not documented in any protocol page,
    // this is usually a serialized GroupMemberMetadata as described in
    // https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal.
    //
    // The protocol metadata is where group members will communicate which
    // topics they collectively as a group want to consume.
    ProtocolMetadata: bytes

// JoinGroupResponse is returned from a JoinGroupRequest.
JoinGroupResponse => from JoinGroupRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v2+
  // ErrorCode is the error for the join group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // INVALID_SESSION_TIMEOUT is returned if the requested SessionTimeout is
  // not within the broker's group.{min,max}.session.timeout.ms.
  //
  // INCONSISTENT_GROUP_PROTOCOL is returned if the requested protocols are
  // incompatible with the existing group member's protocols, or if the join
  // was for a new group but contained no protocols.
  //
  // UNKNOWN_MEMBER_ID is returned is the requested group is dead (likely
  // just migrated to another coordinator or the group is temporarily unstable),
  // or if the request was for a new group but contained a non-empty member ID,
  // or if the group does not have the requested member ID (and the client must
  // do the new-join-group dance).
  //
  // MEMBER_ID_REQUIRED is returned on the initial join of an existing group.
  // This error was proposed in KIP-394 and introduced in Kafka 2.2.0 to
  // prevent flaky clients from continually triggering rebalances and prevent
  // these clients from consuming RAM with metadata. If a client sees
  // this error, it should re-issue the join with the MemberID in the response.
  // Non-flaky clients will join with this new member ID, but flaky clients
  // will not join quickly enough before the pending member ID is rotated out
  // due to hitting the session.timeout.ms.
  //
  // GROUP_MAX_SIZE_REACHED is returned as of Kafka 2.2.0 if the group has
  // reached a broker's group.max.size.
  ErrorCode: int16
  // GenerationID is the current "generation" of this group.
  GenerationID: int32
  // GroupProtocol is the agreed upon protocol name.
  GroupProtocol: string
  // LeaderID is the leader member.
  LeaderID: string
  // MemberID is the member of the receiving client.
  MemberID: string
  // Members contains all other members of this group. Only the group leader
  // receives the members. The leader is responsible for balancing subscribed
  // topic partitions and replying appropriately in a SyncGroup request.
  Members: [=>]
    // MemberID is a member in this group.
    MemberID: string
    // MemberMetadata is the metadata for this member.
    MemberMetadata: bytes

// HeartbeatRequest issues a heartbeat for a member in a group, ensuring that
// Kafka does not expire the member from the group.
HeartbeatRequest => key 12, max version 2, group coordinator
  // GroupID is the group ID this heartbeat is for.
  GroupID: string
  // GenerationID is the group generation this heartbeat is for.
  GenerationID: int32
  // MemberID is the member ID this member is for.
  MemberID: string

// HeartbeatResponse is returned from a HeartbeatRequest.
HeartbeatResponse => from HeartbeatRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error for the heartbeat request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  //
  // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
  //
  // REBALANCE_IN_PROGRESS is returned if the group is currently rebalancing.
  ErrorCode: int16

// LeaveGroupRequest issues a request for a group member to leave the group,
// triggering a group rebalance.
LeaveGroupRequest => key 13, max version 2, group coordinator
  // GroupID is the group to leave.
  GroupID: string
  // MemberID is the member that is leaving.
  MemberID: string

// LeaveGroupResponse is returned from a LeaveGroupRequest.
LeaveGroupResponse => from LeaveGroupRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error for the leave group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // (due to the requested broker shutting down or it has not completed startup).
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  ErrorCode: int16

// SyncGroupRequest is issued by all group members after they receive a a
// response for JoinGroup. The group leader is responsible for sending member
// assignments with the request; all other members do not.
//
// Once the leader sends the group assignment, all members will be replied to.
SyncGroupRequest => key 14, max version 2, group coordinator
  // GroupID is the group ID this sync group is for.
  GroupID: string
  // GenerationID is the group generation this sync is for.
  GenerationID: int32
  // MemberID is the member ID this member is.
  MemberID: string
  // GroupAssignment, sent only from the group leader, is the topic partition
  // assignment it has decided on for all members.
  GroupAssignment: [=>]
    // MemberID is the member this assignment is for.
    MemberID: string
    // MemberAssignment is the assignment for this member. This is typically
    // of type GroupMemberAssignment.
    MemberAssignment: bytes

// SyncGroupResponse is returned from a SyncGroupRequest.
SyncGroupResponse => from SyncGroupRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error for the sync group request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to the group (no read perms).
  //
  // INVALID_GROUP_ID is returned in the requested group ID is invalid.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available.
  //
  // NOT_COORDINATOR is returned if the requested broker is not the coordinator
  // for the requested group.
  //
  // UNKNOWN_MEMBER_ID is returned if the member ID is not a part of the group,
  // or if the group is empty or dead.
  //
  // ILLEGAL_GENERATION is returned if the request's generation ID is invalid.
  //
  // REBALANCE_IN_PROGRESS is returned if the group switched back to rebalancing.
  //
  // UNKNOWN_SERVER_ERROR is returned if the store of the group assignment
  // resulted in a too large message.
  ErrorCode: int16
  // MemberAssignment is the assignment for this member that the leader
  // determined.
  MemberAssignment: bytes

// DescribeGroupsRequest requests metadata for group IDs.
DescribeGroupsRequest => key 15, max version 3, group coordinator
  // GroupIDs is an array of group IDs to request metadata for.
  // If this is empty, the response will include all groups.
  GroupIDs: [string]
  // IncludeAuthorizedOperations, introduced in Kafka 2.3.0, specifies
  // whether to include a bitfield of AclOperations this client can perform
  // on the groups. See KIP-430 for more details.
  IncludeAuthorizedOperations: bool

// DescribeGroupsResponse is returned from a DescribeGroupsRequest.
DescribeGroupsResponse => from DescribeGroupsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Groups is an array of group metadata.
  Groups: [=>]
    // ErrorCode is the error code for an individual group in a request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
    //
    // NOT_COORDINATOR is returned if the requested broker is not the
    // coordinator for this group.
    ErrorCode: int16
    // GroupID is the id of this group.
    GroupID: string
    // State is the state this group is in.
    State: string
    // ProtocolType is the "type" of protocol being used for this group.
    ProtocolType: string
    // Protocol is the agreed upon protocol for all members in this group.
    Protocol: string
    // Members contains members in this group.
    Members: [=>]
      // MemberID is the member ID of a member in this group.
      MemberID: string
      // ClientID is the client ID used by this member.
      ClientID: string
      // ClientHost is the host this client is running on.
      ClientHost: string
      // MemberMetadata is the metadata this member included when joining
      // the group. If using normal (Java-like) consumers, this will be of
      // type GroupMemberMetadata.
      MemberMetadata: bytes
      // MemberAssignment is the assignment for this member in the group.
      // If using normal (Java-like) consumers, this will be of type
      // GroupMemberAssignment.
      MemberAssignment: bytes
    // AuthorizedOperations is a bitfield containing which operations the
    // the client is allowed to perform on this group.
    // This is only returned if requested.
    AuthorizedOperations: int32 // v3+

// ListGroupsRequest issues a request to list all groups.
ListGroupsRequest => key 16, max version 2

// ListGroupsResponse is returned from a ListGroupsRequest.
ListGroupsResponse => from ListGroupsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error returned for the list groups request.
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not yet active.
  //
  // COORDINATOR_LOAD_IN_PROGRESS is returned if the group manager is loading.
  ErrorCode: int16
  // Groups is the list of groups Kafka knows of.
  Groups: [=>]
    // GroupID is a Kafka group.
    GroupID: string
    // ProtocolType is the protocol type in use by the group.
    ProtocolType: string

SASLHandshakeRequest => key 17, max version 1
  Mechanism: string

SASLHandshakeResponse => from SASLHandshakeRequest
  ErrorCode: int16
  EnabledMechanisms: [string]

// ApiVersionsRequest requests what API versions a Kafka broker supports.
//
// Because a client does not know what version of ApiVersionsRequest a broker
// supports, Kafka responds to versions with the highest version it supports.
// This allows clients to always use the latest version of ApiVersionsRequest.
// If the broker supports only a lower version of the request, it will reply
// with an UNSUPPORTED_VERSION error.
ApiVersionsRequest => key 18, max version 2

// ApiVersionsResponse is returned from an ApiVersionsRequest.
ApiVersionsResponse => from ApiVersionsRequest
  // ErrorCode is UNSUPPORTED_VERSION if the request was issued with a higher
  // version than the broker supports. Regardless of the error, the broker
  // replies with the ApiVersions it supports.
  ErrorCode: int16
  // ApiVersions is an array corresponding to API keys the broker supports
  // and the range of supported versions for each key.
  ApiVersions: [=>]
    // ApiKey is the key of a message request.
    ApiKey: int16
    // MinVersion is the min version a broker supports for an API key.
    MinVersion: int16
    // MaxVersion is the max version a broker supports for an API key.
    MaxVersion: int16
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+

// CreateTopicsRequest creates Kafka topics.
CreateTopicsRequest => key 19, max version 3, admin
  // Topics is an array of topics to attempt to create.
  Topics: [=>]
    // Topic is a topic to create.
    Topic: string
    // NumPartitions is how many partitions to give a topic.
    NumPartitions: int32
    // ReplicationFactor is how many replicas every partition must have.
    ReplicationFactor: int16
    // ReplicaAssignment is an array to manually dicate replicas and their
    // partitions for a topic. If using this, both ReplicationFactor and
    // NumPartitions must be -1.
    ReplicaAssignment: [=>]
      // Partition is a partition to create.
      Partition: int32
      // Replicas are broker IDs the partition must exist on.
      Replicas: [int32]
    // ConfigEntries is an array of key value config pairs for a topic.
    // These correspond to Kafka Topic-Level Configs: http://kafka.apache.org/documentation/#topicconfigs.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a topic level config key (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is a topic level config value (e.g. 1073741824)
      ConfigValue: nullable-string
  // Timeout is how long to allow for this request.
  Timeout: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no topics are actually created.
  ValidateOnly: bool // v1+

// CreateTopicsResponse is returned from a CreateTopicsRequest.
CreateTopicsResponse => from CreateTopicsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v2+
  // TopicErrors is an the array of requested topics for creation and their
  // creation errors.
  TopicErrors: [=>]
    // Topic is the topic this error response corresponds to.
    Topic: string
    // ErrorCode is the error code for an individual topic creation.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    //
    // INVALID_REQUEST is returned if the same topic occurred multiple times
    // in the request.
    //
    // POLICY_VIOLATION is returned if the broker is using a
    // create.topic.policy.class.name that returns a policy violation.
    //
    // INVALID_TOPIC_EXCEPTION if the topic collides with another topic when
    // both topic's names' periods are replaced with underscores (e.g.
    // topic.foo and topic_foo collide).
    //
    // TOPIC_ALREADY_EXISTS is returned if the topic already exists.
    //
    // INVALID_PARTITIONS is returned if the requested number of partitions is
    // <= 0.
    //
    // INVALID_REPLICATION_FACTOR is returned if the requested replication
    // factor is <= 0.
    //
    // INVALID_REPLICA_ASSIGNMENT is returned if not all partitions have the same
    // number of replicas, or duplica replicas are assigned, or the partitions
    // are not consecutive starting from 0.
    //
    // INVALID_CONFIG is returned if the requested topic config is invalid.
    // to create a topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string // v1+

// DeleteTopicsRequest deletes Kafka topics.
DeleteTopicsRequest => key 20, max version 3, admin
  // Topics is an array of topics to delete.
  Topics: [string]
  // Timeout is the millisecond timeout of this request.
  Timeout: int32

// DeleteTopicsResponse is returned from a DeleteTopicsRequest.
// Version 3 added the TOPIC_DELETION_DISABLED error proposed in KIP-322
// and introduced in Kafka 2.1.0. Prior, the request timed out.
DeleteTopicsResponse => from DeleteTopicsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // TopicErrorCodes is contains the error codes for each topic requested
  // for deletion (or no error code).
  TopicErrorCodes: [=>]
    // Topic is the topic requested for deletion.
    Topic: string
    // ErrorCode is the error code returned for an individual topic in
    // deletion request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a topic.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_DELETION_DISABLED is returned for deletion requests version 3+
    // and brokers >= 2.1.0. INVALID_REQUEST is issued for request versions
    // 0-2 against brokers >= 2.1.0. Otherwise, the request hangs until it
    // times out.
    ErrorCode: int16

// DeleteRecordsRequest is an admin request to delete records from Kafka.
// This was added for KIP-107.
//
// To delete records, Kafka sets the LastStableOffset for partitions to
// the requested offset. All segments whose max partition is before the
// requested offset are deleted, and any records within the segement before
// the requested offset can no longer be read.
DeleteRecordsRequest => key 21, max version 1, admin
  // Topics contains topics for which to delete records from.
  Topics: [=>]
    // Topic is a topic to delete records from.
    Topic: string
    // Partitions contains partitions to delete records from.
    Partitions: [=>]
      // Partition is a partition to delete records from.
      Partition: int32
      // Offset is the offset to set the partition's low watermark (start
      // offset) to. After a successful response, all records before this
      // offset are considered deleted and are no longer readable.
      //
      // To delete all records, use -1, which is mapped to the partition's
      // current high watermark.
      Offset: int64
  // Timeout is how long to wait for a response before Kafka will return.
  // Kafka waits for all replicas to respond to the delete reords request;
  // any partition that all replicas do not reply to within this limit will
  // have a timeout error.
  Timeout: int32

// DeleteRecordsResponse is returned from a DeleteRecordsRequest.
DeleteRecordsResponse => from DeleteRecordsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Topics contains responses for each topic in the delete records request.
  Topics: [=>]
    // Topic is the topic this response corresponds to.
    Topic: string
    // Partitions contains responses for each partition in a requested topic
    // in the delete records request.
    Partitions: [=>]
      // Partition is the partition this response corresponds to.
      Partition: int32
      // LowWatermark is the new earliest offset for this partition.
      LowWatermark: int64
      // ErrorCode is the error code returned for a given partition in
      // the delete request.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all partitions if the
      // client is not authorized to delete records.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned for all partitions that
      // the requested broker does not know of.
      //
      // NOT_LEADER_FOR_PARTITION is returned for partitions that the
      // requested broker is not a leader of.
      //
      // OFFSET_OUT_OF_RANGE is returned if the requested offset is
      // negative or higher than the current high watermark.
      //
      // POLICY_VIOLATION is returned if records cannot be deleted due to
      // broker configuration.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the partition is in an
      // offline log directory.
      ErrorCode: int16

InitProducerIDRequest => key 22, max version 2, txn coordinator
  TransactionalID: nullable-string
  TransactionTimeoutMs: int32

InitProducerIDResponse => from InitProducerIDRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // CLUSTER_AUTHORIZATION_FAILED if idempotent and not authed
  //
  // transactional errors:
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED if transactional and not authed
  // INVALID_REQUEST if transactional id is an empty, non-null string
  // INVALID_TRANSACTION_TIMEOUT if timeout equal to over over transaction.max.timeout.ms or under 0
  // COORDINATOR_LOAD_IN_PROGRESS
  // NOT_COORDINATOR
  // COORDINATOR_NOT_AVAILABLE
  // CONCURRENT_TRANSACTIONS
  ErrorCode: int16
  // the generated producer ID
  ProducerID: int64
  // the current producer epoch
  ProducerEpoch: int16

OffsetForLeaderEpochRequest => key 23, max version 2
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be gleaned from a MetadataResponse.
      CurrentLeaderEpoch: int32 // v2+
      LeaderEpoch: int32

OffsetForLeaderEpochResponse => from OffsetForLeaderEpochRequest
  ThrottleTimeMs: int32
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      ErrorCode: int16
      Partition: int32
      LeaderEpoch: int32
      EndOffset: int64

AddPartitionsToTxnRequest => key 24, max version 1, txn coordinator
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  Topics: [=>]
    Topic: string
    Partitions: [int32]

AddPartitionsToTxnResponse => from AddPartitionsToTxnRequest
  ThrottleTimeMs: int32
  Errors: [=>]
    Topic: string
    PartitionErrors: [=>]
      Partition: int32
      ErrorCode: int16

AddOffsetsToTxnRequest => key 25, max version 1, txn coordinator
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  GroupID: string

AddOffsetsToTxnResponse => from AddOffsetsToTxnRequest
  ThrottleTimeMs: int32
  ErrorCode: int16

EndTxnRequest => key 26, max version 1, txn coordinator
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  TransactionalResult: bool

EndTxnResponse => from EndTxnRequest
  ThrottleTimeMs: int32
  ErrorCode: int16

WriteTxnMarkersRequest => key 27, max version 0
  TransactionMarkers: [=>]
    ProducerID: int64
    ProducerEpoch: int16
    TransactionResult: bool
    Topics: [=>]
      Topic: string
      Partitions: [int32]
    CoordinatorEpoch: int32

WriteTxnMarkersResponse => from WriteTxnMarkersRequest
  TransactionMarkers: [=>]
    ProducerID: int64
    Topics: [=>]
      Topic: string
      Partitions: [=>]
        Partition: int32
        ErrorCode: int16

TxnOffsetCommitRequest => key 28, max version 2, txn coordinator
  TransactionalID: string
  GroupID: string
  ProducerID: int64
  ProducerEpoch: int16
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      Offset: int64
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      //
      // The initial leader epoch can be gleaned from a MetadataResponse.
      // To skip log truncation checking, use -1.
      LeaderEpoch: int32 // v2+
      Metadata: nullable-string

TxnOffsetCommitResponse => from TxnOffsetCommitRequest
  ThrottleTimeMs: int32
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      ErrorCode: int16

// DescribeACLsRequest describes ACLs. Unfortunately, there exists little
// official documentation on this.
DescribeACLsRequest => key 29, max version 1, admin
  ResourceType: int8
  ResourceName: nullable-string
  ResourcePatternTypeFilter: int8
  Principal: nullable-string
  Host: nullable-string
  Operation: int8
  PermissionType: int8

DescribeACLsResponse => from DescribeACLsRequest
  ThrottleTimeMs: int32
  // ErrorCode is the error code returned on request failure.
  //
  // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to describe the cluster.
  //
  // SECURITY_DISABLED is returned if there is no authorizer configured on the
  // broker.
  ErrorCode: int16
  ErrorMessage: nullable-string
  Resources: [=>]
    ResourceType: int8
    ResourceName: string
    ResourcePatternType: int8 // v1+
    ACLs: [=>]
      // Principal is who this ACL applies to.
      Principal: string
      // Host is on which host this ACL applies.
      Host: string
      // Operation is a type of operation this ACL applies to.
      //
      // UNKNOWN (0) is an operation that we do not understand (old client).
      //
      // ANY (1) mathches any ACL operation in a filter.
      //
      // ALL (2) (implies everything)
      //
      // READ (3) (implies DESCRIBE)
      //
      // WRITE (4) (implies DESCRIBE)
      //
      // CREATE (5)
      //
      // DELETE (6) (implies DESCRIBE)
      //
      // ALTER (7) (implies DESCRIBE)
      //
      // DESCRIBE (8)
      //
      // CLUSTER_ACTION (9)
      //
      // DESCRIBE_CONFIGS (10)
      //
      // ALTER_CONFIGS (11) (implies DESCRIBE_CONFIGS)
      //
      // IDEMPOTENT_WRITE (12)
      Operation: int8
      // PermissionType is how this ACL is applied.
      //
      // UNKNOWN is a permission type we do not understand (old client).
      //
      // ANY allows anything.
      //
      // DENY disallows access.
      //
      // ALLOW allows access.
      PermissionType: int8

CreateACLsRequest => key 30, max version 1, admin
  Creations: [=>]
    ResourceType: int8
    ResourceName: string
    ResourcePatternType: int8 // v1+
    Principal: string
    Host: string
    Operation: int8
    PermissionType: int8

CreateACLsResponse => from CreateACLsRequest
  ThrottleTimeMs: int32
  CreationResponses: [=>]
    ErrorCode: int16
    ErrorMessage: nullable-string

DeleteACLsRequest => key 31, max version 1, admin
  Filters: [=>]
    ResourceType: int8
    ResourceName: nullable-string
    ResourcePatternTypeFilter: int8 // v1+
    Principal: nullable-string
    Host: nullable-string
    Operation: int8
    PermissionType: int8

DeleteACLsResponse => from DeleteACLsRequest
  ThrottleTimeMs: int32
  FilterResponses: [=>]
    ErrorCode: int16
    ErrorMessage: nullable-string
    MatchingACLs: [=>]
      ErrorCode: int16
      ErrorMessage: nullable-string
      ResourceType: int8
      ResourceName: string
      ResourcePatternType: int8 // v1+
      Principal: string
      Host: string
      Operation: int8
      PermissionType: int8

// DescribeConfigsRequest issues a request to describe configs that Kafka
// currently has. These are the key/value pairs that one uses to configure
// brokers and topics.
DescribeConfigsRequest => key 32, max version 2, admin
  // Resources is a list of resources to describe.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to describe.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to describe.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // returns all broker configs, but only the dynamic configuration values.
    // If a specific ID, this returns all broker config values.
    ResourceName: string
    // ConfigNames is a list of config entries to return. Null requests all.
    ConfigNames: nullable[string]
  // IncludeSynonyms signifies whether to return config entry synonyms for
  // all config entries.
  IncludeSynonyms: bool // v1+

// DescribeConfigsResponse is returned from a DescribeConfigsRequest.
DescribeConfigsResponse => from DescribeConfigsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Resources are responses for each resource in the describe config request.
  Resources: [=>]
    // ErrorCode is the error code returned for describing configs.
    //
    // INVALID_REQUEST is returned if asking to descibe an invalid resource
    // type.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to describe broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to describe topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the describe config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of described config.
    ResourceType: int8
    // ResourceName is the name corresponding to the describe config request.
    ResourceName: string
    // ConfigEntries contains information about key/value config pairs for
    // the requested resource.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a key this entry corresponds to (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is the value for this config key. If the key is sensitive,
      // the value will be null.
      ConfigValue: nullable-string
      // ReadOnly signifies whether this is not a dynamic config option.
      ReadOnly: bool
      // IsDefault is whether this is a default config option. This has been
      // replaced in favor of ConfigSource.
      IsDefault: bool // v0-v0
      // ConfigSource is where this config entry is from. Note that if there
      // are no config synonyms, the source is DEFAULT_CONFIG. The values of
      // this enum are as follows.
      //
      // UNKNOWN (0): unknown; e.g. an altar request was issued with no source set
      //
      // DYNAMIC_TOPIC_CONFIG (1): dynamic topic config for a specific topic
      //
      // DYNAMIC_BROKER_CONFIG (2): dynamic broker config for a specific broker
      //
      // DYNAMIC_DEFAULT_BROKER_CONFIG (3): dynamic broker config used as the default for all brokers in a cluster
      //
      // STATIC_BROKER_CONFIG (4): static broker config provided at start up
      //
      // DEFAULT_CONFIG (5): built-in default configuration for those that have defaults
      ConfigSource: int8 // v1+
      // IsSensitive signifies whether this is a sensitive config key, which
      // is either a password or an unknown type.
      IsSensitive: bool
      // ConfigSynonyms contains config key/value pairs that can be used in
      // place of this config entry, in order of preference.
      ConfigSynonyms: [=>] // v1+
        ConfigName: string
        ConfigValue: nullable-string
        ConfigSource: int8

// AlterConfigsRequest issues a request to alter either topic or broker
// configs.
//
// Note that to alter configs, you must specify the whole config on every
// request. All existing non-static values will be removed. This means that
// to add one key/value to a config, you must describe the config and then
// issue an alter request with the current config with the new key value.
// This also means that dynamic sensitive values, which are not returned
// in describe configs, will be lost.
//
// To fix this problem, the AlterConfigs request / response was deprecated
// in Kafka 2.3.0 in favor of the new IncrementalAlterConfigs request / response.
// See KIP-339 for more details.
AlterConfigsRequest => key 33, max version 1, admin
  // Resources is an array of configs to alter.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to alter.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to alter.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // updates all broker configs. If a specific ID, this updates just the
    // broker. Using a specific ID also ensures that brokers reload config
    // or secret files even if the file path has not changed. Lastly, password
    // config options can only be defined on a per broker basis.
    ResourceName: string
    // ConfigEntries contains key/value config pairs to set on the resource.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a key to set (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is a value to set for the key (e.g. 10).
      ConfigValue: nullable-string
  // ValidateOnly validates the request but does not apply it.
  ValidateOnly: bool

// AlterConfigsResponse is returned from an AlterConfigsRequest.
AlterConfigsResponse => from AlterConfigsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Resources are responses for each resource in the alter request.
  Resources: [=>]
    // ErrorCode is the error code returned for altering configs.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    //
    // INVALID_REQUEST is returned if the requested config is invalid or if
    // asking Kafka to alter an invalid resource.
    ErrorCode: int16
    // ErrorMessage is an informative message if the alter config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of altered config.
    ResourceType: int8
    // ResourceName is the name corresponding to the alter config request.
    ResourceName: string

// AlterReplicaLogDirsRequest requests for log directories to be moved
// within Kafka.
//
// This is primarily useful for moving directories between disks.
AlterReplicaLogDirsRequest => key 34, max version 1, admin
  // LogDirs contains absolute paths of where you want things to end up.
  LogDirs: [=>]
    // LogDir is an absolute path where everything listed below should
    // end up.
    LogDir: string
    // Topics contains topics to move to the above log directory.
    Topics: [=>]
      // Topic is a topic to move.
      Topic: string
      // Partitions contains partitions for the topic to move.
      Partitions: [int32]

// AlterReplicaLogDirsResponse is returned from an AlterReplicaLogDirsRequest.
AlterReplicaLogDirsResponse => from AlterReplicaLogDirsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Topics contains responses to each topic that had partitions requested
  // for moving.
  Topics: [=>]
    // Topic is the topic this array slot corresponds to.
    Topic: string
    // Partitions contains responses to each partition that was requested
    // to move.
    Partitions: [=>]
      // Partition is the partition this array slot corresponds to.
      Partition: int32
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to alter replica dirs.
      //
      // LOG_DIR_NOT_FOUND is returned when the requested log directory
      // is not in the broker config.
      //
      // KAFKA_STORAGE_EXCEPTION is returned when destination directory or
      // requested replica is offline.
      //
      // REPLICA_NOT_AVAILABLE is returned if the replica does not exist
      // yet.
      ErrorCode: int16

// DescribeLogDirsRequest requests directory information for topic partitions.
// This request was added in support of KIP-113.
DescribeLogDirsRequest => key 35, max version 1, admin
  // Topics is an array of topics to describe the log dirs of. If this is
  // empty, the response includes all topics and all of their partitions.
  Topics: nullable[=>]
    // Topic is a topic to describe the log dir of.
    Topic: string
    // Partitions contains topic partitions to describe the log dirs of.
    Partitions: [int32]

// DescribeLogDirsResponse is returned from a DescribeLogDirsRequest.
DescribeLogDirsResponse => from DescribeLogDirsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // LogDirs pairs log directories with the topics and partitions that are
  // stored in those directores.
  LogDirs: [=>]
    // ErrorCode is the error code returned for descrbing log dirs.
    //
    // KAFKA_STORAGE_ERROR is returned if the log directoy is offline.
    ErrorCode: int16
    // LogDir is the absolute path of a log directory.
    LogDir: string
    // Topics is an array of topics within a log directory.
    Topics: [=>]
      // Topic is the name of a Kafka topic.
      Topic: string
      // Partitions is the set of queried partitions for a topic that are
      // within a log directory.
      Partitions: [=>]
        // Partition is a partition ID.
        Partition: int32
        // Size is the total size of the log sements of this partition, in bytes.
        Size: int64
        // OffsetLag is how far behind the log end offset is compared to
        // the partition's high watermark (if this is the current log for
        // the partition) or compared to the current replica's log end
        // offset (if this is the future log for the patition).
        //
        // The math is,
        //
        // if IsFuture, localLogEndOffset - futurelogEndOffset.
        //
        // otherwise, max(localHighWatermark - logEndOffset, 0).
        OffsetLag: int64
        // IsFuture is true if this replica was created by an
        // AlterReplicaLogDirsRequest and will replace the current log of the
        // replica in the future.
        IsFuture: bool

SASLAuthenticateRequest => key 36, max version 1
  SASLAuthBytes: bytes

SASLAuthenticateResponse => from SASLAuthenticateRequest
  ErrorCode: int16
  ErrorMessage: nullable-string
  SASLAuthBytes: bytes
  SessionLifetimeMs: int64 // v1+

// CreatePartitionsRequest creates additional partitions for topics.
CreatePartitionsRequest => key 37, max version 1, admin
  // TopicPartitions paris topics with their partition creation requests.
  TopicPartitions: [=>]
    // Topic is a topic for which to create additional partitions for.
    Topic: string
    // NewPartitions contains the total number of partitions a topic must
    // have after this request, and the assignment of which brokers should
    // own new partitions and replicas.
    NewPartitions: =>
      // Count is the final count of partitions this topic must have. This
      // must be greater than the current number of partitions.
      Count: int32
      // Assignment is a two-level array, the first corresponding to new
      // partitions, the second contining broker IDs for where new partition
      // replicas should live.
      //
      // The second level, the replicas, cannot have duplicate broker IDs
      // (i.e. you cannot replicate a single partition twice on the same
      // broker). Additionally, the number of replicas must match the current
      // number of replicas per partition on the topic.
      //
      // The first level's length must be equal to the delta of Count and
      // the current number of partitions.
      Assignment: [[int32]]
  // Timeout is how long to allow for this request.
  Timeout: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no partitions are actually created.
  ValidateOnly: bool

// CreatePartitionsResponse is returned from a CreatePartitionsRequest.
CreatePartitionsResponse => from CreatePartitionsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // TopicErrors is an the array of requested topics with partition creations
  // and their creation errors.
  TopicErrors: [=>]
    // Topic is the topic that partitions were requested to be made for.
    Topic: string
    // ErrorCode is the error code returned for each topic in the request.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to create partitions for a topic.
    //
    // INVALID_REQUEST is returned for duplicate topics in the request.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the topic is queued for deletion.
    //
    // REASSIGNMENT_IN_PROGRESS is returned if the request was issued while
    // partitions were being reassigned.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic for which to create partitions.
    //
    // INVALID_PARTITIONS is returned if the request would drop the total
    // count of partitions down, or if the request would not add any more
    // partitions, or if the request uses unknown brokers, or if the request
    // assigns a different number of brokers than the increase in the
    // partition count.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string

CreateDelegationTokenRequest => key 38, max version 1, admin
  Renewers: [=>]
    PrincipalType: string
    Name: string
  MaxLifetime: int64

CreateDelegationTokenResponse => from CreateDelegationTokenRequest
  ErrorCode: int16
  Owner: =>
    PrincipalType: string
    Name: string
  IssueTimestamp: int64
  ExpiryTimestamp: int64
  MaxTimestamp: int64
  TokenID: string
  HMAC: bytes
  ThrottleTimeMs: int32

RenewDelegationTokenRequest => key 39, max version 1, admin
  HMAC: bytes
  RenewTimePeriod: int64

RenewDelegationTokenResponse => from RenewDelegationTokenRequest
  ErrorCode: int16
  ExpiryTimestamp: int64
  ThrottleTimeMs: int32

ExpireDelegationTokenRequest => key 40, max version 1, admin
  HMAC: bytes
  ExpiryTimePeriod: int64

ExpireDelegationTokenResponse => from ExpireDelegationTokenRequest
  ErrorCode: int16
  ExpiryTimestamp: int64
  ThrottleTimeMs: int32

DescribeDelegationTokenRequest => key 41, max version 1, admin
  Owners: [=>]
    PrincipalType: string
    Name: string

DescribeDelegationTokenResponnse => from DescribeDelegationTokenRequest
  ErrorCode: int16
  TokenDetails: [=>]
    Owner: =>
      PrincipalType: string
      Name: string
    IssueTimestamp: int64
    ExpiryTimestamp: int64
    MaxTimestamp: int64
    TokenID: string
    HMAC: bytes
    Renewers: [=>]
      PrincipalType: string
      Name: string
  ThrottleTimeMs: int32

// DeleteGroupsRequest deletes consumer groups. This request was added for
// Kafka 1.1.0 corresponding to the removal of RetentionTime from
// OffsetCommitRequest. See KIP-229 for more details.
DeleteGroupsRequest => key 42, max version 1, group coordinator
  // Groups is a list of groups to delete.
  Groups: [string]

// DeleteGroupsResponse is returned from a DeleteGroupsRequest.
DeleteGroupsResponse => from DeleteGroupsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // GroupErrorCodes are the responses to each group requested for deletion.
  GroupErrorCodes: [=>]
    // GroupID is a group ID requested for deletion.
    GroupID: string
    // ErrorCode is the error code returned for this group's deletion request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // GROUP_ID_NOT_FOUND is returned if the group ID does not exist.
    //
    // NON_EMPTY_GROUP is returned if attempting to delete a group that is
    // not in the empty state.
    ErrorCode: int16

// ElectPreferredLeadersRequest begins a leader election for all given topic
// partitions. This request was added in Kafka 2.2.0 to replace the zookeeper
// only option of triggering leader elections before. See KIP-183 for more
// details.
ElectPreferredLeadersRequest => key 43, max version 0, admin
  // TopicPartitions is an array of topics and corresponding partitions to
  // trigger leader elections for.
  TopicPartitions: [=>]
    // Topic is a topic to trigger leader elections for (but only for the
    // partitions below).
    Topic: string
    // Partitions is an array of partitions in a topic to trigger leader
    // elections for. If null, this triggers elections for all partitions.
    Partitions: nullable[int32]
  // TimeoutMs is how long to wait for the response. This limits how long to
  // wait since responses are not sent until election results are complete.
  TimeoutMs: int32

ElectPreferredLeadersResponse => from ElectPreferredLeadersRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleTimeMs: int32
  // ReplicaElectionResults is the leader election results for each requested
  // topic / partition.
  ReplicaElectionResults: [=>]
    // Topic is topic for the given partition results below.
    Topic: string
    // PartitionResults contains election results for a topic's partitions.
    PartitionResults: [=>]
      // PartitionID is the partition for this result.
      PartitionID: int32
      // ErrorCode is the error code returned for this topic/partition leader
      // election.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to trigger leader elections.
      //
      // NOT_CONTROLLER is returned if the request was not issued to a Kafka
      // controller.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic/partition does
      // not exist on any broker in the cluster (this is slightly different
      // from the usual meaning of a single broker not knowing of the topic
      // partition).
      //
      // PREFERRED_LEADER_NOT_AVAILABLE is returned if the preferred leader
      // could not be elected (for example, the preferred leader was not in
      // the ISR).
      ErrorCode: int16
      // ErrorMessage is an informative message if the leader election failed.
      ErrorMessage: nullable-string

// IncrementalAlterConfigsRequest issues ar equest to alter either topic or
// broker configs.
//
// This API was added in Kafka 2.3.0 to replace AlterConfigs. The key benefit
// of this API is that consumers do not need to know the full config state
// to add or remove new config options. See KIP-339 for more details.
IncrementalAlterConfigsRequest => key 44, max version 0, admin
  // Resources is an array of configs to alter.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to alter.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to alter.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // updates all broker configs. If a specific ID, this updates just the
    // broker. Using a specific ID also ensures that brokers reload config
    // or secret files even if the file path has not changed. Lastly, password
    // config options can only be defined on a per broker basis.
    ResourceName: string
    // ConfigEntries contains key/value config pairs to set on the resource.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a key to modify (e.g. segment.bytes).
      ConfigName: string
      // Op is the type of operation to perform for this config name.
      //
      // SET (0) is to set a configuration value; the value must not be null.
      //
      // DELETE (1) is to delete a configuration key.
      //
      // APPEND (2) is to add a value to the list of values for a key (if the
      // key is for a list of values).
      //
      // SUBTRACT (3) is to remove a value from a list of values (if the key
      // is for a list of values).
      Op: int8
      // ConfigValue is a value to set for the key (e.g. 10).
      ConfigValue: nullable-string
  // ValidateOnly validates the request but does not apply it.
  ValidateOnly: bool

// IncrementalAlterConfigsResponse is returned from an IncrementalAlterConfigsRequest.
IncrementalAlterConfigsResponse => from IncrementalAlterConfigsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleTimeMs: int32
  Responses: [=>]
    // ErrorCode is the error code returned for incrementally altering configs.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    //
    // INVALID_REQUEST is returned if the requested config is invalid or if
    // asking Kafka to alter an invalid resource.
    ErrorCode: int16
    // ErrorMessage is an informative message if the incremental alter config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of altered config.
    ResourceType: int8
    // ResourceName is the name corresponding to the incremental alter config
    // request.
    ResourceName: string

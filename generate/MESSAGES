// Header is user provided metadata for a record. Kafka does not look at
// headers at all; they are solely for producers and consumers.
Header => not top level
  Key: varint-string
  Value: varint-bytes

// A Record is a Kafka v0.11.0.0 record. It corresponds to an individual
// message as it is written on the wire.
Record => not top level
  // Length is the length of this record on the wire of everything that
  // follows this field. It is an int32 encoded as a varint.
  Length: varint
  // Attributes are record level attributes. This field currently is unused.
  Attributes: int8
  // TimestampDelta is the millisecond delta of this record's timestamp
  // from the record's RecordBatch's FirstTimestamp.
  TimestampDelta: varint
  // OffsetDelta is the delta of this record's offset from the record's
  // RecordBatch's FirstOffset.
  //
  // For producing, this is usually equal to the index of the record in
  // the record batch.
  OffsetDelta: varint
  // Key is an blob of data for a record.
  //
  // Key's are usually used for hashing the record to specific Kafka partitions.
  Key: varint-bytes
  // Value is  a blob of data. This field is the main "message" portion of a
  // record.
  Value: varint-bytes
  // Headers are optional user provided metadata for records. Unlike normal
  // arrays, the number of headers is encoded as a varint.
  Headers: varint[Header]

// RecordBatch is a Kafka concept that groups many individual records together
// in a more optimized format.
RecordBatch => not top level
  // NullableBytesLength is not officially a field in a RecordBatch, however,
  // RecordBatch is a special form of NULLABLE_BYTES. Since all nullable bytes
  // must be prefixed with a int32 length, we throw that here.
  // This length should not include itself, only data that follows.
  NullableBytesLength: int32
  // FirstOffset is the first offset in a record batch.
  //
  // For producing, this is usually 0.
  FirstOffset: int64
  // Length is the wire length of everything that follows this field.
  Length: int32
  // PartitionLeaderEpoch is a number that Kafka uses for cluster
  // communication. Clients generally do not need to worry about this
  // field and producers should set it to -1.
  PartitionLeaderEpoch: int32
  // Magic is the current "magic" number of this message format.
  // The current magic number is 2.
  Magic: int8
  // CRC is the crc of everything that follows this field using the
  // Castagnoli polynomial.
  CRC: int32
  // Attributes describe the records array of this batch.
  //
  // Bits 0 thru 3 correspond to compression:
  //   - 000 is no compression
  //   - 001 is snappy compression
  //   - 010 is lz4 compression
  //   - 011 is zstd compression (produce request version 7+)
  //
  // Bit 4 is the timestamp type, with 0 meaning CreateTime corresponding
  // to the timestamp being from the producer, and 1 meaning LogAppendTime
  // corresponding to the timestamp being from the broker.
  // Setting this to LogAppendTime will cause batches to be rejected.
  //
  // Bit 5 indicates whether the batch is part of a transaction (1 is yes).
  //
  // Bit 6 indicates if the batch includes a control message (1 is yes).
  // Control messages are used to enable transactions and are generated from
  // the broker. Clients should not return control batches to applications.
  Attributes: int16
  // LastOffsetDelta is the offset of the last message in a batch. This is
  // by the broker to ensure correct behavior even with batch compaction.
  LastOffsetDelta: int32
  // FirstTimestamp is the timestamp (in milliseconds) of the first record
  // in a batch.
  FirstTimestamp: int64
  // MaxTimestamp is the timestamp (in milliseconds) of the last record
  // in a batch. Similar to LastOffsetDelta, this is used to ensure correct
  // behavior with compacting.
  MaxTimestamp: int64
  // ProducerID is the broker assigned producerID from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  ProducerID: int64
  // ProducerEpoch is the broker assigned producerEpoch from an InitProducerID
  // request.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  ProducerEpoch: int16
  // FirstSequence is the producer assigned sequence number used by the
  // broker to deduplicate messages.
  //
  // Clients that wish to support idempotent messages and transactions must
  // set this field.
  //
  // The sequence number for each record in a batch is OffsetDelta + FirstSequence.
  FirstSequence: int32
  // Records are the batch of records to send.
  //
  // Note that to compress a batch, you compress the entire set of records
  // and then use that as the value for a single record.
  Records: [Record]

// ProduceRequest issues records to be created to Kafka.
//
// The min version of this type is currently 2, released with Kafka 0.11.0.0.
// Prior, the RecordBatch format was completely different (and was called a
// MessageSet).
//
// Note that the special client ID "__admin_client" will allow you to produce
// records to internal topics. This is generally recommended if you want to
// break your Kafka cluster.
ProduceRequest => key 0, max version 7, min version 2
  TransactionID: nullable-string // v3+
  // Acks specifies the number of acks that the partition leaders must receive
  // from in sync replicas before considering a record batch fully written.
  //
  // Valid values are -1, 0, or 1 corresponding to all, none, or one.
  //
  // Note that if no acks are requested, Kafka will close the connection
  // if any topic or partition errors to trigger a client metadata refresh.
  Acks: int16
  // Timeout is the millisecond timeout of this request.
  Timeout: int32
  // TopicData is an array of topics to send record batches to.
  TopicData: [=>]
    // Topic is a topic to send record batches to.
    Topic: string
    // Data is an array of partitions to send record batches to.
    Data: [=>]
      // Partition is a partition to send a record batch to.
      Partition: int32
      // Records is a batch of records to write to a topic's partition.
      Records: RecordBatch

// ProduceResponse is returned from a ProduceRequest.
ProduceResponse => from ProduceRequest
  // Responses is an array of responses for the topic's that batches were sent
  // to.
  Responses: [=>]
    // Topic is the topic this response pertains to.
    Topic: string
    // PartitionResponses is an array of responses for the partition's that
    // batches were sent to.
    PartitionResponses: [=>]
      // Partition is the partition this response pertains to.
      Partition: int32
      // ErrorCode is any error for a topic/partition in the request.
      // There are many error codes for produce requests.
      //
      // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for all topics and
      // partitions if the request had a transactional ID but the client
      // is not authorized for transactions.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned for all topics and partitions
      // if the request was idempotent but the client is not authorized
      // for idempotent requests.
      //
      // TOPIC_AUTHORIZATION_FAILED is returned for all topics the client
      // is not authorized to talk to.
      //
      // INVALID_REQUIRED_ACKS is returned if the request contained an invalid
      // number for "acks".
      //
      // CORRUPT_MESSAGE is returned for many reasons, generally related to
      // problems with messages (invalid magic, size mismatch, etc.).
      //
      // MESSAGE_TOO_LARGE is returned if a record batch is larger than the
      // broker's configured max.message.size.
      //
      // RECORD_LIST_TOO_LARGE is returned if the record batch is larger than
      // the broker's segment.bytes.
      //
      // INVALID_TIMESTAMP is returned if the record batch uses LogAppendTime
      // or if the timestamp delta from when the broker receives the message
      // is more than the broker's log.message.timestamp.difference.max.ms.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if using a Kafka v2 message
      // format (i.e. RecordBatch) feature (idempotence) while sending v1
      // messages (i.e. a MessageSet).
      //
      // KAFKA_STORAGE_ERROR is returned if the log directory for a partition
      // is offline.
      //
      // NOT_ENOUGH_REPLICAS is returned if all acks are required, but there
      // are not enough in sync replicas yet.
      //
      // NOT_ENOUGH_REPLICAS_AFTER_APPEND is returned on old Kafka versions
      // (pre 0.11.0.0) when a message was written to disk and then Kafka
      // noticed not enough replicas existed to replicate the message.
      //
      // DUPLICATE_SEQUENCE_NUMBER is returned for Kafka <1.1.0 when a
      // sequence number is detected as a duplicate. After, out of order
      // is returned.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic or partition
      // is unknown.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      //
      // INVALID_PRODUCER_EPOCH is returned if the produce request was
      // attempted with an old epoch. Either there is a newer producer using
      // the same transaction ID, or the transaction ID used has expired.
      //
      // UNKNOWN_PRODUCER_ID, added in Kafka 1.0.0 (message format v5+) is
      // returned if the producer used an ID that Kafka does not know about.
      // The LogStartOffset must be checked in this case. If the offset is
      // greater than the last acknowledged offset, then no data loss has
      // occurred; the client just sent data so long ago that Kafka rotated
      // the partition out of existence and no longer knows of this producer
      // ID. In this case, initialize a new ID. If the log start offset is
      // equal to or less than what the client sent prior, then data loss
      // has occurred. This See KAFKA-5793 for more details.
      //
      // OUT_OF_ORDER_SEQUENCE_NUMBER is sent if the batch's FirstSequence was
      // not what it should be (the last FirstSequence, plus the number of
      // records in the last batch, plus one). After 1.0.0, this generally
      // means data loss. Before, there could be confusion on if the broker
      // actually rotated the partition out of existence (this is why
      // UNKNOWN_PRODUCER_ID was introduced).
      ErrorCode: int16
      // BaseOffset is the offset that the records in the produce request began
      // at in the partition.
      BaseOffset: int64
      // LogAppendTime is the time that records were appended to the partition
      // inside Kafka. This is only not -1 if records were written with the log
      // append time flag (which producers cannot do).
      LogAppendTime: int64 // v2+
      // LogStartOffset, introduced in Kafka 1.0.0,  can be used to see if an
      // UNKNOWN_PRODUCER_ID means Kafka rotated records containing the used
      // producer ID out of existence, or if Kafka lost data.
      LogStartOffset: int64 // v5+
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32

FetchRequest => key 1, max version 10
  ReplicaID: int32
  MaxWaitTime: int32
  MinBytes: int32
  MaxBytes: int32 // v3+
  IsolationLevel: int8 // v4+
  SessionID: int32 // v7+
  SessionEpoch: int32 // v7+
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      CurrentLeaderEpoch: int32 // v9+
      FetchOffset: int64
      LogStartOffset: int64 // v5+
      PartitionMaxBytes: int32
  ForgottenTopicsData: [=>] // v7+
    Topic: string
    Partitions: [int32]

FetchResponse => from FetchRequest
  ThrottleTimeMs: int32 // v1+
  ErrorCode: int16 // v7+
  SessionID: int32 // v7+
  Responses: [=>]
    Topic: string
    PartitionResponses: [=>]
      PartitionHeader: =>
        Partition: int32
        ErrorCode: int16
        HighWatermark: int64
        LastStableOffset: int64 // v4+
        LogStartOffset: int64 // v5+
        AbortedTransactions: [=>] // v4+
          ProducerID: int64
          FirstOffset: int64
      RecordSet: [Record]

// ListOffsetsRequest requests partition offsets from Kafka for use in
// consuming records.
ListOffsetsRequest => key 2, max version 4, min version 1, admin
  // ReplicaID is the broker ID to get offsets from. As a Kafka client, use -1.
  // The consumer replica ID (-1) causes requests to only succeed if issued
  // against the leader broker.
  ReplicaID: int32
  // IsolationLevel configures which record offsets are visible in the
  // response. READ_UNCOMMITTED (0) makes all records visible. READ_COMMITTED
  // (1) makes non-transactional and committed transactional records visible.
  // READ_COMMITTED means all offsets smaller than the last stable offset and
  // includes aborted transactions (allowing consumers to discard aborted
  // records).
  IsolationLevel: int8 // v2+
  // Topics is an array of topics to get offsets for.
  Topics: [=>]
    // Topic is a topic to get offsets for.
    Topic: string
    // Partitions is an array of partitions in a topic to get offsets for.
    Partitions: [=>]
      // Partition is a partition of a topic to get offsets for.
      Partition: int32
      // CurrentLeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0,
      // allows brokers to check if the client is fenced (has an out of date
      // leader) or is using an unknown leader.
      CurrentLeaderEpoch: int32 // v4+
      // Timestamp controls which offset to return in a response for this
      // partition.
      //
      // The offset returned will be the one of the message whose timestamp is
      // the first timestamp greater than or equal to this requested timestamp.
      //
      // If no such message is found, the log end offset is returned.
      //
      // There exist two special timestamps: -2 corresponds to the earliest
      // timestamp, and -1 corresponds to the latest.
      Timestamp: int64

// ListOffsetsResponse is returned from a ListOffsetsRequest.
ListOffsetsResponse => from ListOffsetsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v2+
  // Responses is an array of topic / partition responses corresponding to
  // the requested topics and partitions.
  Responses: [=>]
    // Topic is the topic this array slot is for.
    Topic: string
    // PartitionResponses is an array of partition responses corresponding to
    // the requested partitions for a topic.
    PartitionResponses: [=>]
      // Partition is the partition this array slot is for.
      Partition: int32
      // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
      // to describe the topic.
      //
      // INVALID_REQUEST is returned if the requested topic partitions had
      // contained duplicates.
      //
      // KAFKA_STORAGE_EXCEPTION is returned if the topic / partition is in
      // an offline log directory.
      //
      // UNSUPPORTED_FOR_MESSAGE_FORMAT is returned if the broker is using
      // Kafka 0.10.0 messages and the requested timestamp was not -1 nor -2.
      //
      // NOT_LEADER_FOR_PARTITION is returned if the broker is not a leader
      // for this partition. This means that the client has stale metadata.
      // If the request used the debug replica ID, the returned error will
      // be REPLICA_NOT_AVAILABLE.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know
      // of the requested topic or partition.
      //
      // FENCED_LEADER_EPOCH is returned if the broker has a higher leader
      // epoch than what the request sent.
      //
      // UNKNOWN_LEADER_EPOCH is returned if the request used a leader epoch
      // that the broker does not know about.
      //
      // OFFSET_NOT_AVAILABLE, introduced in Kafka 2.2.0 with produce request
      // v5+, is returned when talking to a broker that is a new leader while
      // that broker's high water mark catches up. This avoids situations where
      // the old broker returned higher offsets than the new broker would. Note
      // that if unclean leader election is allowed, you could still run into
      // the situation where offsets returned from list offsets requests are
      // not monotonically increasing. This error is only returned if the
      // request used the consumer replica ID (-1). If the client did not use
      // a v5+ list offsets request, LEADER_NOT_AVAILABLE is returned.
      // See KIP-207 for more details.
      ErrorCode: int16
      // If the request was for the earliest or latest timestamp (-2 or -1), or
      // if an offset could not be found after the requested one, this will be -1.
      Timestamp: int64
      // Offset is the offset corresponding to the record on or after the
      // requested timestamp. If one could not be found, this will be -1.
      Offset: int64 // v1+
      // LeaderEpoch is the leader epoch of the record at this offset,
      // or -1 if there was no leader epoch.
      LeaderEpoch: int32 // v4+

// MetadataRequest requests metadata from Kafka.
MetadataRequest => key 3, max version 8
  // Topics is a list of topics to return metadata about. If this is null,
  // all topics are included. If this is empty, no topics are.
  // For v0 (<Kafka 0.10.0.0), if this is empty, all topics are included.
  Topics: nullable[string]
  // AllowAutoTopicCreation, introduced in Kafka 0.11.0.0, allows topic
  // auto creation of the topics in this request if they do not exist.
  AllowAutoTopicCreation: bool // v4+
  // IncludeClusterAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on the cluster.
  IncludeClusterAuthorizedOperations: bool // v8+
  // IncludeTopicAuthorizedOperations, introduced in Kakfa 2.3.0, specifies
  // whether to return a bitfield of AclOperations that this client can perform
  // on individual topics.
  IncludeTopicAuthorizedOperations: bool // v8+

// MetadataResponse is returned from a MetdataRequest.
MetadataResponse => from MetadataRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v3+
  // Brokers is a set of alive Kafka brokers.
  Brokers: [=>]
    // NodeID is the node ID of a Kafka broker.
    NodeID: int32
    // Host is the hostname of a Kafka broker.
    Host: string
    // Port is the port of a Kafka broker.
    Port: int32
    // Rack is the rack this Kafka broker is in.
    Rack: nullable-string // v1+
  // ClusterID, proposed in KIP-78 and introduced in Kafka 0.10.1.0, is a
  // unique string specifying the cluster that the replying Kafka belongs to.
  ClusterID: nullable-string // v2+
  // ControllerID is the ID of the controller broker (the admin broker).
  ControllerID: int32 // v1+
  // TopicMetadata contains metadata about each topic requested in the
  // MetadataRequest.
  TopicMetadata: [=>]
    // ErrorCode is any error for a topic in a metadata request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe the topic, or if the metadata request specified topic auto
    // creation, the topic did not exist, and the user lacks permission to create.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if a topic does not exist and
    // the request did not specify autocreation.
    //
    // LEADER_NOT_AVAILABLE is returned if a new topic is created successfully
    // (since there is no leader on an immediately new topic).
    //
    // There can be a myriad of other errors for unsuccessful topic creation.
    ErrorCode: int16
    // Topic is the topic this metadata corresponds to.
    Topic: string
    // IsInternal signifies whether this topic is a Kafka internal topic.
    IsInternal: bool // v1+
    // PartitionMetadata contains metadata about partitions for a topic.
    PartitionMetadata: [=>]
      // ErrorCode is any error for a partition in topic metadata.
      //
      // LEADER_NOT_AVAILABLE is returned if a leader is unavailable for this
      // partition. For v0 metadata responses, this is also returned if a
      // partition leader's listener does not exist.
      //
      // LISTENER_NOT_FOUND is returned if a leader ID is known but the
      // listener for it is not (v1+).
      //
      // REPLICA_NOT_AVAILABLE is returned in v0 responses if any replica is
      // unavailable.
      ErrorCode: int16
      // Partition is a partition number for a topic.
      Partition: int32
      // Leader is the broker leader for this partition. This will be -1
      // on leader / listener error.
      Leader: int32
      // LeaderEpoch, proposed in KIP-320 and introduced in Kafka 2.1.0  is the
      // epoch of the broker leader.
      LeaderEpoch: int32 // v7+
      // Replicas returns all broker IDs containing replicas of this partition.
      Replicas: [int32]
      // ISR returns all broker IDs of in-sync replicas of this partition.
      ISR: [int32]
      // OfflineReplicas, proposed in KIP-112 and introduced in Kafka 1.0,
      // returns all offline broker IDs that should be replicating this partition.
      OfflineReplicas: [int32] // v5+
    // AuthorizedOperations, proposed in KIP-430 and introduced in Kafka 2.3.0,
    // returns a bitfield (corresponding to AclOperation) containing which
    // operations the client is allowed to perform on this topic.
    // This is only returned if requested.
    AuthorizedOperations: int32 // v8+
  // AuthorizedOperations returns a bitfield containing which operations the
  // client is allowed to perform on this cluster.
  AuthorizedOperations: int32 // v8+

// LeaderAndISRRequest is an advanced request that controller brokers use
// to broadcast state to other brokers. Manually using this request is a
// great way to break your cluster.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 1.0.0 introduced version 1. Kafka 2.2.0 introduced version 2, proposed
// in KIP-380, which changed the layout of the struct to be more memory
// efficient.
LeaderAndISRRequest => key 4, max version 2, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v2+
  PartitionStates: [=>] // v0-v1
    Topic: string
    Partition: int32
    ControllerEpoch: int32
    Leader: int32
    LeaderEpoch: int32
    ISR: [int32]
    ZKVersion: int32
    Replicas: [int32]
    IsNew: bool // v1+
  TopicStates: [=>] // v2+
    Topic: string
    PartitionStates: [=>]
      Partition: int32
      ControllerEpoch: int32
      Leader: int32
      LeaderEpoch: int32
      ISR: [int32]
      ZKVersion: int32
      Replicas: [int32]
      IsNew: bool
  LiveLeaders: [=>]
    ID: int32
    Host: string
    Port: int32

// LeaderAndISRResponse is returned from a LeaderAndISRRequest.
LeaderAndISRResponse => from LeaderAndISRRequest
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

// StopReplicaRequest is an advanced request that brokers use to stop replicas.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Kafka 2.2.0 introduced version 1, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
StopReplicaRequest => key 5, max version 1, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v1+
  DeletePartitions: bool
  Partitions: [=>]
    Topic: string
    Partition: int32 // v0-v0
    PartitionIDs: [int32] // v1+

// StopReplicasResponse is returned from a StopReplicasRequest.
StopReplicaResponse => from StopReplicaRequest
  ErrorCode: int16
  Partitions: [=>]
    Topic: string
    Partition: int32
    ErrorCode: int16

// UpdateMetadataRequest is an advanced request that brokers use to
// issue metadata updates to each other.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented.
//
// Version 1 changed the layout of the live brokers.
//
// Kafka 2.2.0 introduced version 5, proposed in KIP-380, which changed the
// layout of the struct to be more memory efficient.
UpdateMetadataRequest => key 6, max version 5, admin
  ControllerID: int32
  ControllerEpoch: int32
  BrokerEpoch: int64 // v5+
  PartitionStates: [=>] // v0-v4
    Topic: string
    Partition: int32
    ControllerEpoch: int32
    Leader: int32
    LeaderEpoch: int32
    ISR: [int32]
    ZKVersion: int32
    Replicas: [int32]
    OfflineReplicas: [int32]
  TopicStates: [=>] // v5+
    Topic: string
    PartitionStates: [=>]
      Partition: int32
      ControllerEpoch: int32
      Leader: int32
      LeaderEpoch: int32
      ISR: [int32]
      ZKVersion: int32
      Replicas: [int32]
      OfflineReplicas: [int32]
  LiveBrokers: [=>]
    ID: int32
    Host: string // v0-v0
    Port: int32 // v0-v0
    Endpoints: [=>] // v1+
      Port: int32
      Host: string
      ListenerName: string // v3+
      SecurityProtocolType: int16
    Rack: nullable-string // v2+

// UpdateMetadataResponses is returned from an UpdateMetadataRequest.
UpdateMetadataResponse => from UpdateMetadataRequest
  ErrorCode: int16

// ControlledShutdownRequest is an advanced request that can be used to
// sthudown a broker in a controlled manner.
//
// As this is an advanced request and there is little reason to issue it as a
// client, this request is undocumented. However, the minimal amount of fields
// here makes the usage rather obvious.
//
// Kafka 2.2.0 introduced version 2, proposed in KIP-380.
ControlledShutdownRequest => key 7, max version 2, admin
  BrokerID: int32
  BrokerEpoch: int64 // v2+

// ControlledShutdownResponse is returned from a ControlledShutdownRequest.
ControlledShutdownResponse => from ControlledShutdownRequest
  ErrorCode: int16
  PartitionsRemaining: [=>]
    Topic: string
    Partition: int32

OffsetCommitRequest => key 8, max version 6
  GroupID: string
  GenerationID: int32 // v1+
  MemberID: string // v1+
  // replaces offset.retention.minutes and timestamp field below
  // removed, why? problem:
  // - rarely committing consumer's offset expired
  // - restart or rebalance, now does not know last committed offset
  // - now they have to restart from end or beginnig, leading to dups or loss.
  RetentionTime: int64 // v2-v4
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      Offset: int64
      // expiration is Timestamp + offset.retention.minutes.
      // if non-zero.
      // if zero, current time + offset.retention.minutes.
      // KIP-211
      Timestamp: int64 // v1-v1
      LeaderEpoch: int32 // v6+
      Metadata: nullable-string

OffsetCommitResponse => from OffsetCommitRequest
  ThrottleTimeMs: int32 // v3+
  Responses: [=>]
    Topic: string
    PartitionResponses: [=>]
      Partition: int32
      ErrorCode: int16

OffsetFetchRequest => key 9, max version 5
  GroupID: string
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32

OffsetFetchResponse => from OffsetFetchRequest
  ThrottleTimeMs: int32
  Responses: [=>]
    Topic: [=>]
      Topic: string
      PartitionResponses: [=>]
        Partition: int32
        Offset: int64
        LeaderEpoch: int32 // v5+
        Metadata: nullable-string
        ErrorCode: int16
  ErrorCode: int16 // v2+

// FindCoordinatorRequest requests the coordinator for a group or transaction.
FindCoordinatorRequest => key 10, max version 2
  // CoordinatorKey is the ID to use for finding the coordinator. For groups,
  // this is the group ID, for transactional producer, this is the
  // transactional ID.
  //
  // In v0 this was called GroupID.
  CoordinatorKey: string // v0+
  // CoordinatorType is the type that key is. GroupIDs are type 0,
  // transactional IDs are type 1.
  CoordinatorType: int8 // v1+

// FindCoordinatorResponse is returned from a FindCoordinatorRequest.
FindCoordinatorResponse => from FindCoordinatorRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // ErrorCode is the error returned for the request.
  //
  // GROUP_AUTHORIZATION_FAILED is returned if for a group ID request and the
  // client is not authorized to describe groups.
  //
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED is returned for a transactional ID
  // request and the client is not authorized to describe transactional IDs.
  //
  // INVALID_REQUEST is returned if not asking for a known type (group,
  // or transaction).
  //
  // COORDINATOR_NOT_AVAILABLE is returned if the coordinator is not available
  // for the requested ID, or if the requested ID does not exist.
  ErrorCode: int16
  // ErrorMessage is an informative message if the request errored.
  ErrorMessage: nullable-string // v1+
  // Coordinator is the coordinator for the requested ID if the request did
  // not error.
  Coordinator: =>
    // NodeID is the broker ID of the coordinator.
    NodeID: int32
    // Host is the host of the coordinator.
    Host: string
    // Port is the port of the coordinator.
    Port: int32

JoinGroupRequest => key 11, max version 4
  GroupID: string
  SessionTimeout: int32
  RebalanceTimeout: int32 // v1+
  MemberID: string
  ProtocolType: string
  GroupProtocols: [=>]
    ProtocolName: string
    ProtocolMetadata: bytes

JoinGroupResponse => from JoinGroupRequest
  ThrottleTimeMs: int32 // v2+
  ErrorCode: int16
  GenerationID: int32
  GroupProtocol: string
  LeaderID: string
  MemberID: string
  Members: [=>]
    MemberID: string
    MemberMetadata: bytes

HeartbeatRequest => key 12, max version 2
  GroupID: string
  GenerationID: int32
  MemberID: string

HeartbeatResponse => from HeartbeatRequest
  ThrottleTimeMs: int32 // v1+
  ErrorCode: int16

LeaveGroupRequest => key 13, max version 2
  GroupID: string
  MemberID: string

LeaveGroupResponse => from LeaveGroupRequest
  ThrottleTimeMs: int32 // v1+
  ErrorCode: int16

SyncGroupRequest => key 14, max version 2
  GroupID: string
  GenerationID: int32
  MemberID: string
  GroupAssignment: [=>]
    MemberID: string
    MemberAssignment: bytes

SyncGroupResponse => from SyncGroupRequest
  ThrottleTimeMs: int32 // v1+
  ErrorCode: int16
  MemberAssignment: bytes

// DescribeGroupsRequest requests metadata for group IDs.
DescribeGroupsRequest => key 15, max version 2, admin
  // GroupIDs is an array of group IDs to request metadata for.
  // If this is empty, the response will include all groups.
  GroupIDs: [string]

// DescribeGroupsResponse is returned from a DescribeGroupsRequest.
DescribeGroupsResponse => from DescribeGroupsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Groups is an array of group metadata.
  Groups: [=>]
    // ErrorCode is the error code for an individual group in a request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to describe a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // COORDINATOR_LOAD_IN_PROGRESS is returned if the group is loading.
    //
    // NOT_COORDINATOR is returned if the requested broker is not the
    // coordinator for this group.
    ErrorCode: int16
    // GroupID is the id of this group.
    GroupID: string
    State: string
    ProtocolType: string
    Protocol: string
    Members: [=>]
      MemberID: string
      ClientID: string
      ClientHost: string
      MemberMetadata: bytes
      MemberAssignment: bytes

ListGroupsRequest => key 16, max version 2

ListGroupsResponse => from ListGroupsRequest
  ThrottleTimeMs: int32 // v1+
  ErrorCode: int16
  Groups: [=>]
    GroupID: string
    ProtocolType: string

SASLHandshakeRequest => key 17, max version 1
  Mechanism: string

SASLHandshakeResponse => from SASLHandshakeRequest
  ErrorCode: int16
  EnabledMechanisms: [string]

// ApiVersionsRequest requests what API versions a Kafka broker supports.
//
// Because a client does not know what version of ApiVersionsRequest a broker
// supports, Kafka responds to versions with the highest version it supports.
// This allows clients to always use the latest version of ApiVersionsRequest.
// If the broker supports only a lower version of the request, it will reply
// with an UNSUPPORTED_VERSION error.
ApiVersionsRequest => key 18, max version 2

// ApiVersionsResponse is returned from an ApiVersionsRequest.
ApiVersionsResponse => from ApiVersionsRequest
  // ErrorCode is UNSUPPORTED_VERSION if the request was issued with a higher
  // version than the broker supports. Regardless of the error, the broker
  // replies with the ApiVersions it supports.
  ErrorCode: int16
  // ApiVersions is an array corresponding to API keys the broker supports
  // and the range of supported versions for each key.
  ApiVersions: [=>]
    // ApiKey is the key of a message request.
    ApiKey: int16
    // MinVersion is the min version a broker supports for an API key.
    MinVersion: int16
    // MaxVersion is the max version a broker supports for an API key.
    MaxVersion: int16
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+

// CreateTopicsRequest creates Kafka topics.
CreateTopicsRequest => key 19, max version 3, admin
  // Topics is an array of topics to attempt to create.
  Topics: [=>]
    // Topic is a topic to create.
    Topic: string
    // NumPartitions is how many partitions to give a topic.
    NumPartitions: int32
    // ReplicationFactor is how many replicas every partition must have.
    ReplicationFactor: int16
    // ReplicaAssignment is an array to manually dicate replicas and their
    // partitions for a topic. If using this, both ReplicationFactor and
    // NumPartitions must be -1.
    ReplicaAssignment: [=>]
      // Partition is a partition to create.
      Partition: int32
      // Replicas are broker IDs the partition must exist on.
      Replicas: [int32]
    // ConfigEntries is an array of key value config pairs for a topic.
    // These correspond to Kafka Topic-Level Configs: http://kafka.apache.org/documentation/#topicconfigs.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a topic level config key (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is a topic level config value (e.g. 1073741824)
      ConfigValue: nullable-string
  // Timeout is how long to allow for this request.
  Timeout: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no topics are actually created.
  ValidateOnly: bool // v1+

// CreateTopicsResponse is returned from a CreateTopicsRequest.
CreateTopicsResponse => from CreateTopicsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v2+
  // TopicErrors is an the array of requested topics for creation and their
  // creation errors.
  TopicErrors: [=>]
    // Topic is the topic this error response corresponds to.
    Topic: string
    // ErrorCode is the error code for an individual topic creation.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    //
    // INVALID_REQUEST is returned if the same topic occurred multiple times
    // in the request.
    //
    // POLICY_VIOLATION is returned if the broker is using a
    // create.topic.policy.class.name that returns a policy violation.
    //
    // INVALID_TOPIC_EXCEPTION if the topic collides with another topic when
    // both topic's names' periods are replaced with underscores (e.g.
    // topic.foo and topic_foo collide).
    //
    // TOPIC_ALREADY_EXISTS is returned if the topic already exists.
    //
    // INVALID_PARTITIONS is returned if the requested number of partitions is
    // <= 0.
    //
    // INVALID_REPLICATION_FACTOR is returned if the requested replication
    // factor is <= 0.
    //
    // INVALID_REPLICA_ASSIGNMENT is returned if not all partitions have the same
    // number of replicas, or duplica replicas are assigned, or the partitions
    // are not consecutive starting from 0.
    //
    // INVALID_CONFIG is returned if the requested topic config is invalid.
    // to create a topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string // v1+

// DeleteTopicsRequest deletes Kafka topics.
DeleteTopicsRequest => key 20, max version 3, admin
  // Topics is an array of topics to delete.
  Topics: [string]
  // Timeout is the millisecond timeout of this request.
  Timeout: int32

// DeleteTopicsResponse is returned from a DeleteTopicsRequest.
// Version 3 added the TOPIC_DELETION_DISABLED error proposed in KIP-322
// and introduced in Kafka 2.1.0. Prior, the request timed out.
DeleteTopicsResponse => from DeleteTopicsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32 // v1+
  // TopicErrorCodes is contains the error codes for each topic requested
  // for deletion (or no error code).
  TopicErrorCodes: [=>]
    // Topic is the topic requested for deletion.
    Topic: string
    // ErrorCode is the error code returned for an individual topic in
    // deletion request.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a topic.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_DELETION_DISABLED is returned for deletion requests version 3+
    // and brokers >= 2.1.0. INVALID_REQUEST is issued for request versions
    // 0-2 against brokers >= 2.1.0. Otherwise, the request hangs until it
    // times out.
    ErrorCode: int16

DeleteRecordsRequest => key 21, max version 1
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      Offset: int64
  Timeout: int32

DeleteRecordsResponse => from DeleteRecordsRequest
  ThrottleTimeMs: int32
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      LowWatermark: int64
      ErrorCode: int16

InitProducerIDRequest => key 22, max version 2
  TransactionalID: nullable-string
  TransactionTimeoutMs: int32

InitProducerIDResponse => from InitProducerIDRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // CLUSTER_AUTHORIZATION_FAILED if idempotent and not authed
  //
  // transactional errors:
  // TRANSACTIONAL_ID_AUTHORIZATION_FAILED if transactional and not authed
  // INVALID_REQUEST if transactional id is an empty, non-null string
  // INVALID_TRANSACTION_TIMEOUT if timeout equal to over over transaction.max.timeout.ms or under 0
  // COORDINATOR_LOAD_IN_PROGRESS
  // NOT_COORDINATOR
  // COORDINATOR_NOT_AVAILABLE
  // CONCURRENT_TRANSACTIONS
  ErrorCode: int16
  // the generated producer ID
  ProducerID: int64
  // the current producer epoch
  ProducerEpoch: int16

OffsetForLeaderEpochRequest => key 23, max version 2
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      CurrentLeaderEpoch: int32 // v2+
      LeaderEpoch: int32

OffsetForLeaderEpochResponse => from OffsetForLeaderEpochRequest
  ThrottleTimeMs: int32
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      ErrorCode: int16
      Partition: int32
      LeaderEpoch: int32
      EndOffset: int64

AddPartitionsToTxnRequest => key 24, max version 1
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  Topics: [=>]
    Topic: string
    Partitions: [int32]

AddPartitionsToTxnResponse => from AddPartitionsToTxnRequest
  ThrottleTimeMs: int32
  Errors: [=>]
    Topic: string
    PartitionErrors: [=>]
      Partition: int32
      ErrorCode: int16

AddOffsetsToTxnRequest => key 25, max version 1
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  GroupID: string

AddOffsetsToTxnResponse => from AddOffsetsToTxnRequest
  ThrottleTimeMs: int32
  ErrorCode: int16

EndTxnRequest => key 26, max version 1
  TransactionalID: string
  ProducerID: int64
  ProducerEpoch: int16
  TransactionalResult: bool

EndTxnResponse => from EndTxnRequest
  ThrottleTimeMs: int32
  ErrorCode: int16

WriteTxnMarkersRequest => key 27, max version 0
  TransactionMarkers: [=>]
    ProducerID: int64
    ProducerEpoch: int16
    TransactionResult: bool
    Topics: [=>]
      Topic: string
      Partitions: [int32]
    CoordinatorEpoch: int32

WriteTxnMarkersResponse => from WriteTxnMarkersRequest
  TransactionMarkers: [=>]
    ProducerID: int64
    Topics: [=>]
      Topic: string
      Partitions: [=>]
        Partition: int32
        ErrorCode: int16

TxnOffsetCommitRequest => key 28, max version 2
  TransactionalID: string
  GroupID: string
  ProducerID: int64
  ProducerEpoch: int16
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      Offset: int64
      LeaderEpoch: int32 // v2+
      Metadata: nullable-string

TxnOffsetCommitResponse => from TxnOffsetCommitRequest
  ThrottleTimeMs: int32
  Topics: [=>]
    Topic: string
    Partitions: [=>]
      Partition: int32
      ErrorCode: int16

// DescribeACLsRequest describes ACLs. Unfortunately, there exists little
// official documentation on this.
DescribeACLsRequest => key 29, max version 1, admin
  ResourceType: int8
  ResourceName: nullable-string
  ResourcePatternTypeFilter: int8
  Principal: nullable-string
  Host: nullable-string
  Operation: int8
  PermissionType: int8

DescribeACLsResponse => from DescribeACLsRequest
  ThrottleTimeMs: int32
  // ErrorCode is the error code returned on request failure.
  //
  // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not authorized
  // to describe the cluster.
  //
  // SECURITY_DISABLED is returned if there is no authorizer configured on the
  // broker.
  ErrorCode: int16
  ErrorMessage: nullable-string
  Resources: [=>]
    ResourceType: int8
    ResourceName: string
    ResourcePatternType: int8 // v1+
    ACLs: [=>]
      // Principal is who this ACL applies to.
      Principal: string
      // Host is on which host this ACL applies.
      Host: string
      // Operation is a type of operation this ACL applies to.
      //
      // UNKNOWN (0) is an operation that we do not understand (old client).
      //
      // ANY (1) mathches any ACL operation in a filter.
      //
      // ALL (2) (implies everything)
      //
      // READ (3) (implies DESCRIBE)
      //
      // WRITE (4) (implies DESCRIBE)
      //
      // CREATE (5)
      //
      // DELETE (6) (implies DESCRIBE)
      //
      // ALTER (7) (implies DESCRIBE)
      //
      // DESCRIBE (8)
      //
      // CLUSTER_ACTION (9)
      //
      // DESCRIBE_CONFIGS (10)
      //
      // ALTER_CONFIGS (11) (implies DESCRIBE_CONFIGS)
      //
      // IDEMPOTENT_WRITE (12)
      Operation: int8
      // PermissionType is how this ACL is applied.
      //
      // UNKNOWN is a permission type we do not understand (old client).
      //
      // ANY allows anything.
      //
      // DENY disallows access.
      //
      // ALLOW allows access.
      PermissionType: int8

CreateACLsRequest => key 30, max version 1, admin
  Creations: [=>]
    ResourceType: int8
    ResourceName: string
    ResourcePatternType: int8 // v1+
    Principal: string
    Host: string
    Operation: int8
    PermissionType: int8

CreateACLsResponse => from CreateACLsRequest
  ThrottleTimeMs: int32
  CreationResponses: [=>]
    ErrorCode: int16
    ErrorMessage: nullable-string

DeleteACLsRequest => key 31, max version 1, admin
  Filters: [=>]
    ResourceType: int8
    ResourceName: nullable-string
    ResourcePatternTypeFilter: int8 // v1+
    Principal: nullable-string
    Host: nullable-string
    Operation: int8
    PermissionType: int8

DeleteACLsResponse => from DeleteACLsRequest
  ThrottleTimeMs: int32
  FilterResponses: [=>]
    ErrorCode: int16
    ErrorMessage: nullable-string
    MatchingACLs: [=>]
      ErrorCode: int16
      ErrorMessage: nullable-string
      ResourceType: int8
      ResourceName: string
      ResourcePatternType: int8 // v1+
      Principal: string
      Host: string
      Operation: int8
      PermissionType: int8

// DescribeConfigsRequest issues a request to describe configs that Kafka
// currently has. These are the key/value pairs that one uses to configure
// brokers and topics.
DescribeConfigsRequest => key 32, max version 2, admin
  // Resources is a list of resources to describe.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to describe.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to describe.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // returns all broker configs, but only the dynamic configuration values.
    // If a specific ID, this returns all broker config values.
    ResourceName: string
    // ConfigNames is a list of config entries to return. Null requests all.
    ConfigNames: nullable[string]
  // IncludeSynonyms signifies whether to return config entry synonyms for
  // all config entries.
  IncludeSynonyms: bool // v1+

// DescribeConfigsResponse is returned from a DescribeConfigsRequest.
DescribeConfigsResponse => from DescribeConfigsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Resources are responses for each resource in the describe config request.
  Resources: [=>]
    // ErrorCode is the error code returned for describing configs.
    //
    // INVALID_REQUEST is returned if asking to descibe an invalid resource
    // type.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to describe broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to describe topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    ErrorCode: int16
    // ErrorMessage is an informative message if the describe config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of described config.
    ResourceType: int8
    // ResourceName is the name corresponding to the describe config request.
    ResourceName: string
    // ConfigEntries contains information about key/value config pairs for
    // the requested resource.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a key this entry corresponds to (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is the value for this config key. If the key is sensitive,
      // the value will be null.
      ConfigValue: nullable-string
      // ReadOnly signifies whether this is not a dynamic config option.
      ReadOnly: bool
      // IsDefault is whether this is a default config option. This has been
      // replaced in favor of ConfigSource.
      IsDefault: bool // v0-v0
      // ConfigSource is where this config entry is from. Note that if there
      // are no config synonyms, the source is DEFAULT_CONFIG. The values of
      // this enum are as follows.
      //
      // UNKNOWN (0): unknown; e.g. an altar request was issued with no source set
      //
      // DYNAMIC_TOPIC_CONFIG (1): dynamic topic config for a specific topic
      //
      // DYNAMIC_BROKER_CONFIG (2): dynamic broker config for a specific broker
      //
      // DYNAMIC_DEFAULT_BROKER_CONFIG (3): dynamic broker config used as the default for all brokers in a cluster
      //
      // STATIC_BROKER_CONFIG (4): static broker config provided at start up
      //
      // DEFAULT_CONFIG (5): built-in default configuration for those that have defaults
      ConfigSource: int8 // v1+
      // IsSensitive signifies whether this is a sensitive config key, which
      // is either a password or an unknown type.
      IsSensitive: bool
      // ConfigSynonyms contains config key/value pairs that can be used in
      // place of this config entry, in order of preference.
      ConfigSynonyms: [=>] // v1+
        ConfigName: string
        ConfigValue: nullable-string
        ConfigSource: int8

// AlterConfigsRequest issues a request to alter either topic or broker
// configs.
AlterConfigsRequest => key 33, max version 1, admin
  // Resources is an array of configs to alter.
  Resources: [=>]
    // ResourceType is an enum corresponding to the type of config to alter.
    // The only two valid values are 2 (for topic) and 4 (for broker).
    ResourceType: int8
    // ResourceName is the name of config to alter.
    //
    // If the requested type is a topic, this corresponds to a topic name.
    //
    // If the requested type if a broker, this should either be empty or be
    // the ID of the broker this request is issued to. If it is empty, this
    // updates all broker configs. If a specific ID, this updates just the
    // broker. Using a specific ID also ensures that brokers reload config
    // or secret files even if the file path has not changed. Lastly, password
    // config options can only be defined on a per broker basis.
    ResourceName: string
    // ConfigEntries contains key/value config pairs to set on the resource.
    ConfigEntries: [=>ConfigEntry]
      // ConfigName is a key to set (e.g. segment.bytes).
      ConfigName: string
      // ConfigValue is a value to set for the key (e.g. 10).
      ConfigValue: nullable-string
  // ValidateOnly validates the request but does not apply it.
  ValidateOnly: bool

// AlterConfigsResponse is returned from an AlterConfigsRequest.
AlterConfigsResponse => from AlterConfigsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Resources are responses for each resource in the alter request.
  Resources: [=>]
    // ErrorCode is the error code returned for altering configs.
    //
    // CLUSTER_AUTHORIZATION_FAILED is returned if asking to alter broker
    // configs but the client is not authorized to do so.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if asking to alter topic
    // configs but the client is not authorized to do so.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the requested topic was invalid.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the requested topic.
    //
    // INVALID_REQUEST is returned if the requested config is invalid or if
    // asking Kafka to describe an invalid resource.
    ErrorCode: int16
    // ErrorMessage is an informative message if the alter config failed.
    ErrorMessage: nullable-string
    // ResourceType is the enum corresponding to the type of altered config.
    ResourceType: int8
    // ResourceName is the name corresponding to the alter config request.
    ResourceName: string

// AlterReplicaLogDirsRequest requests for log directories to be moved
// within Kafka.
//
// This is primarily useful for moving directories between disks.
AlterReplicaLogDirsRequest => key 34, max version 1, admin
  // LogDirs contains absolute paths of where you want things to end up.
  LogDirs: [=>]
    // LogDir is an absolute path where everything listed below should
    // end up.
    LogDir: string
    // Topics contains topics to move to the above log directory.
    Topics: [=>]
      // Topic is a topic to move.
      Topic: string
      // Partitions contains partitions for the topic to move.
      Partitions: [int32]

// AlterReplicaLogDirsResponse is returned from an AlterReplicaLogDirsRequest.
AlterReplicaLogDirsResponse => from AlterReplicaLogDirsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // Topics contains responses to each topic that had partitions requested
  // for moving.
  Topics: [=>]
    // Topic is the topic this array slot corresponds to.
    Topic: string
    // Partitions contains responses to each partition that was requested
    // to move.
    Partitions: [=>]
      // Partition is the partition this array slot corresponds to.
      Partition: int32
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to alter replica dirs.
      //
      // LOG_DIR_NOT_FOUND is returned when the requested log directory
      // is not in the broker config.
      //
      // KAFKA_STORAGE_EXCEPTION is returned when destination directory or
      // requested replica is offline.
      //
      // REPLICA_NOT_AVAILABLE is returned if the replica does not exist
      // yet.
      ErrorCode: int16

// DescribeLogDirsRequest requests directory information for topic partitions.
// This request was added in support of KIP-113.
DescribeLogDirsRequest => key 35, max version 1, admin
  // Topics is an array of topics to describe the log dirs of. If this is
  // empty, the response includes all topics and all of their partitions.
  Topics: nullable[=>]
    // Topic is a topic to describe the log dir of.
    Topic: string
    // Partitions contains topic partitions to describe the log dirs of.
    Partitions: [int32]

// DescribeLogDirsResponse is returned from a DescribeLogDirsRequest.
DescribeLogDirsResponse => from DescribeLogDirsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // LogDirs pairs log directories with the topics and partitions that are
  // stored in those directores.
  LogDirs: [=>]
    // ErrorCode is the error code returned for descrbing log dirs.
    //
    // KAFKA_STORAGE_ERROR is returned if the log directoy is offline.
    ErrorCode: int16
    // LogDir is the absolute path of a log directory.
    LogDir: string
    // Topics is an array of topics within a log directory.
    Topics: [=>]
      // Topic is the name of a Kafka topic.
      Topic: string
      // Partitions is the set of queried partitions for a topic that are
      // within a log directory.
      Partitions: [=>]
        // Partition is a partition ID.
        Partition: int32
        // Size is the total size of the log sements of this partition, in bytes.
        Size: int64
        // OffsetLag is how far behind the log end offset is compared to
        // the partition's high watermark (if this is the current log for
        // the partition) or compared to the current replica's log end
        // offset (if this is the future log for the patition).
        //
        // The math is,
        //
        // if IsFuture, localLogEndOffset - futurelogEndOffset.
        //
        // otherwise, max(localHighWatermark - logEndOffset, 0).
        OffsetLag: int64
        // IsFuture is true if this replica was created by an
        // AlterReplicaLogDirsRequest and will replace the current log of the
        // replica in the future.
        IsFuture: bool

SASLAuthenticateRequest => key 36, max version 1
  SASLAuthBytes: bytes

SASLAuthenticateResponse => from SASLAuthenticateRequest
  ErrorCode: int16
  ErrorMessage: nullable-string
  SASLAuthBytes: bytes
  SessionLifetimeMs: int64 // v1+

// CreatePartitionsRequest creates additional partitions for topics.
CreatePartitionsRequest => key 37, max version 1, admin
  // TopicPartitions paris topics with their partition creation requests.
  TopicPartitions: [=>]
    // Topic is a topic for which to create additional partitions for.
    Topic: string
    // NewPartitions contains the total number of partitions a topic must
    // have after this request, and the assignment of which brokers should
    // own new partitions and replicas.
    NewPartitions: =>
      // Count is the final count of partitions this topic must have. This
      // must be greater than the current number of partitions.
      Count: int32
      // Assignment is a two-level array, the first corresponding to new
      // partitions, the second contining broker IDs for where new partition
      // replicas should live.
      //
      // The second level, the replicas, cannot have duplicate broker IDs
      // (i.e. you cannot replicate a single partition twice on the same
      // broker). Additionally, the number of replicas must match the current
      // number of replicas per partition on the topic.
      //
      // The first level's length must be equal to the delta of Count and
      // the current number of partitions.
      Assignment: [[int32]]
  // Timeout is how long to allow for this request.
  Timeout: int32
  // ValidateOnly is makes this request a dry-run; everything is validated but
  // no partitions are actually created.
  ValidateOnly: bool

// CreatePartitionsResponse is returned from a CreatePartitionsRequest.
CreatePartitionsResponse => from CreatePartitionsRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // TopicErrors is an the array of requested topics with partition creations
  // and their creation errors.
  TopicErrors: [=>]
    // Topic is the topic that partitions were requested to be made for.
    Topic: string
    // ErrorCode is the error code returned for each topic in the request.
    //
    // NOT_CONTROLLER is returned if the request was not issued to a Kafka
    // controller.
    //
    // TOPIC_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to create partitions for a topic.
    //
    // INVALID_REQUEST is returned for duplicate topics in the request.
    //
    // INVALID_TOPIC_EXCEPTION is returned if the topic is queued for deletion.
    //
    // REASSIGNMENT_IN_PROGRESS is returned if the request was issued while
    // partitions were being reassigned.
    //
    // UNKNOWN_TOPIC_OR_PARTITION is returned if the broker does not know of
    // the topic for which to create partitions.
    //
    // INVALID_PARTITIONS is returned if the request would drop the total
    // count of partitions down, or if the request would not add any more
    // partitions, or if the request uses unknown brokers, or if the request
    // assigns a different number of brokers than the increase in the
    // partition count.
    ErrorCode: int16
    // ErrorMessage is an informative message if the topic creation failed.
    ErrorMessage: nullable-string

CreateDelegationTokenRequest => key 38, max version 1, admin
  Renewers: [=>]
    PrincipalType: string
    Name: string
  MaxLifetime: int64

CreateDelegationTokenResponse => from CreateDelegationTokenRequest
  ErrorCode: int16
  Owner: =>
    PrincipalType: string
    Name: string
  IssueTimestamp: int64
  ExpiryTimestamp: int64
  MaxTimestamp: int64
  TokenID: string
  HMAC: bytes
  ThrottleTimeMs: int32

RenewDelegationTokenRequest => key 39, max version 1, admin
  HMAC: bytes
  RenewTimePeriod: int64

RenewDelegationTokenResponse => from RenewDelegationTokenRequest
  ErrorCode: int16
  ExpiryTimestamp: int64
  ThrottleTimeMs: int32

ExpireDelegationTokenRequest => key 40, max version 1, admin
  HMAC: bytes
  ExpiryTimePeriod: int64

ExpireDelegationTokenResponse => from ExpireDelegationTokenRequest
  ErrorCode: int16
  ExpiryTimestamp: int64
  ThrottleTimeMs: int32

DescribeDelegationTokenRequest => key 41, max version 1, admin
  Owners: [=>]
    PrincipalType: string
    Name: string

DescribeDelegationTokenResponnse => from DescribeDelegationTokenRequest
  ErrorCode: int16
  TokenDetails: [=>]
    Owner: =>
      PrincipalType: string
      Name: string
    IssueTimestamp: int64
    ExpiryTimestamp: int64
    MaxTimestamp: int64
    TokenID: string
    HMAC: bytes
    Renewers: [=>]
      PrincipalType: string
      Name: string
  ThrottleTimeMs: int32

// DeleteGroupsRequest deletes consumer groups. This request was added for
// Kafka 1.1.0 corresponding to the removal of RetentionTime from
// OffsetCommitRequest. See KIP-229 for more details.
DeleteGroupsRequests => key 42, max version 1, admin
  // Groups is a list of groups to delete.
  Groups: [string]

// DeleteGroupsResponse is returned from a DeleteGroupsRequest.
DeleteGroupsResponse => from DeleteGroupsRequests
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after this request.
  // For Kafka < 2.0.0, the throttle is applied before issuing a response.
  // For Kafka >= 2.0.0, the throttle is applied after issuing a response.
  ThrottleTimeMs: int32
  // GroupErrorCodes are the responses to each group requested for deletion.
  GroupErrorCodes: [=>]
    // GroupID is a group ID requested for deletion.
    GroupID: string
    // ErrorCode is the error code returned for this group's deletion request.
    //
    // GROUP_AUTHORIZATION_FAILED is returned if the client is not authorized
    // to delete a group.
    //
    // INVALID_GROUP_ID is returned if the requested group ID is invalid.
    //
    // COORDINATOR_NOT_AVAILABLE is returned if the coordinator for this
    // group is not yet active.
    //
    // GROUP_ID_NOT_FOUND is returned if the group ID does not exist.
    //
    // NON_EMPTY_GROUP is returned if attempting to delete a group that is
    // not in the empty state.
    ErrorCode: int16

// ElectPreferredLeadersRequest begins a leader election for all given topic
// partitions. This request was added in Kafka 2.2.0 to replace the zookeeper
// only option of triggering leader elections before. See KIP-183 for more
// details.
ElectPreferredLeadersRequest => key 43, max version 0, admin
  // TopicPartitions is an array of topics and corresponding partitions to
  // trigger leader elections for.
  TopicPartitions: [=>]
    // Topic is a topic to trigger leader elections for (but only for the
    // partitions below).
    Topic: string
    // Partitions is an array of partitions in a topic to trigger leader
    // elections for. If null, this triggers elections for all partitions.
    Partitions: nullable[int32]
  // TimeoutMs is how long to wait for the response. This limits how long to
  // wait since responses are not sent until election results are complete.
  TimeoutMs: int32

ElectPreferredLeadersResponse => from ElectPreferredLeadersRequest
  // ThrottleTimeMs is how long of a throttle Kafka will apply to the client
  // after responding to this request.
  ThrottleTimeMs: int32
  // ReplicaElectionResults is the leader election results for each requested
  // topic / partition.
  ReplicaElectionResults: [=>]
    // Topic is topic for the given partition results below.
    Topic: string
    // PartitionResults contains election results for a topic's partitions.
    PartitionResults: [=>]
      // PartitionID is the partition for this result.
      PartitionID: int32
      // ErrorCode is the error code returned for this topic/partition leader
      // election.
      //
      // CLUSTER_AUTHORIZATION_FAILED is returned if the client is not
      // authorized to trigger leader elections.
      //
      // NOT_CONTROLLER is returned if the request was not issued to a Kafka
      // controller.
      //
      // UNKNOWN_TOPIC_OR_PARTITION is returned if the topic/partition does
      // not exist on any broker in the cluster (this is slightly different
      // from the usual meaning of a single broker not knowing of the topic
      // partition).
      //
      // PREFERRED_LEADER_NOT_AVAILABLE is returned if the preferred leader
      // could not be elected (for example, the preferred leader was not in
      // the ISR).
      ErrorCode: int16
      // ErrorMessage is an informative message if the leader election failed.
      ErrorMessage: nullable-string
